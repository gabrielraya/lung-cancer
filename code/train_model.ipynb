{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Neural Image Compression # \n",
    "\n",
    "Using local Data to test functionality with a few WSIs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Imports ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Import NIC to python path\n",
    "import sys\n",
    "nic_dir = '/mnt/netcache/pathology/projects/pathology-lung-cancer-weak-growth-pattern-prediction/code/neural-image-compression-private'\n",
    "sys.path.append(nic_dir +'/source')\n",
    "    \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "from tqdm import tqdm\n",
    "import os, shutil\n",
    "from os.path import join, dirname, exists\n",
    "import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Data ##\n",
    "\n",
    "To demonstrate the functionality of NIC, we will need a set of whole-slide images (WSIs) with their respective slide-level labels. In this case, we will use the WSIs that can be found using the following pattern:\n",
    "\n",
    "These data was already reorganized, it is, all the tiff files are contained in one folder for each class. \n",
    "\n",
    "These are a small version of the TCGA dataset:\n",
    "\n",
    "`/mnt/netcache/pathology/archives/lung/TCGA_LUAD/images_diagnostic`\n",
    "\n",
    "`/mnt/netcache/pathology/archives/lung/TCGA_LUSC/images_diagnostic`\n",
    "\n",
    "\n",
    "\n",
    "The data we are going to use is only the **diagnostic** data and no the **tissue** data. The mask are already given, but we will have to implementa script to create this masks that filter out the background.\n",
    "\n",
    "Mask can be found at :\n",
    "\n",
    "`/mnt/netcache/pathology/archives/lung/TCGA_LUAD/tissue_masks_diagnostic`\n",
    "\n",
    "`/mnt/netcache/pathology/archives/lung/TCGA_LUSC/tissue_masks_diagnostic`\n",
    "\n",
    "\n",
    "Because there is no slide-level csv file, we have to create one, this will be created after once we get the featurized wsi. FIle should be located at  from:\n",
    "\n",
    "`E:\\pathology-weakly-supervised-lung-cancer-growth-pattern-prediction\\data\\slide_original_list_tcga.csv`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates csv from original data\n",
    "\n",
    "# project and data directories\n",
    "root_dir=  '/mnt/netcache/pathology/projects/pathology-weakly-supervised-lung-cancer-growth-pattern-prediction'\n",
    "data_dir = r'/mnt/netcache/pathology/archives/lung'\n",
    "\n",
    "# wsi directories\n",
    "dir_luad_wsi = os.path.join(data_dir, 'TCGA_LUAD', 'wsi_diagnostic_tif')\n",
    "dir_lusc_wsi = os.path.join(data_dir, 'TCGA_LUSC', 'wsi_diagnostic_tif')\n",
    "dir_luad_wsi_mask = os.path.join(data_dir, 'TCGA_LUAD', 'tissue_masks_diagnostic')\n",
    "dir_lusc_wsi_mask = os.path.join(data_dir, 'TCGA_LUSC', 'tissue_masks_diagnostic')\n",
    "\n",
    "# compressed image directories\n",
    "vectorized_luad_dir = join(root_dir, 'results', 'tcga_luad', 'vectorized')\n",
    "vectorized_lusc_dir = join(root_dir, 'results', 'tcga_lusc', 'vectorized')\n",
    "featurized_luad_dir = join(root_dir, 'results', 'tcga_luad', 'featurized', 'no_augmentations')\n",
    "featurized_lusc_dir = join(root_dir, 'results', 'tcga_lusc', 'featurized', 'no_augmentations')\n",
    "\n",
    "# results directory \n",
    "result_dir = join(root_dir, 'results', 'model')  # store the results from trained model\n",
    "gradcam_dir = join(result_dir, 'gradcam')        # store gradcam results\n",
    "\n",
    "# Set paths\n",
    "model_path = './neural-image-compression-private/models/encoders_patches_pathology/encoder_bigan.h5'\n",
    "csv_train = os.path.join(root_dir, 'data', 'train_slide_list_tcga.csv')\n",
    "csv_val = os.path.join(root_dir, 'data', 'validation_slide_list_tcga.csv')\n",
    "csv_test = os.path.join(root_dir, 'data', 'test_slide_list_tcga.csv')\n",
    "\n",
    "# csv paths\n",
    "csv_path_wsi =  os.path.join(root_dir, 'data', 'slide_original_list_tcga.csv')\n",
    "\n",
    "cache_dir = None  # used to store local copies of files during I/O operations (useful in cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Preprocessing\n",
    "\n",
    "We need to create a csv file to point out the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating main csv data files from original data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<?, ?it/s]\n",
      "100%|██████████| 10/10 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Csv file sucessfully exported!\n",
      "Files were read with shapes: (20, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>slide_id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TCGA-05-4244-01Z-00-DX1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TCGA-05-4245-01Z-00-DX1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TCGA-05-4249-01Z-00-DX1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TCGA-05-4250-01Z-00-DX1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TCGA-05-4382-01Z-00-DX1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  slide_id  label\n",
       "0  TCGA-05-4244-01Z-00-DX1      1\n",
       "1  TCGA-05-4245-01Z-00-DX1      1\n",
       "2  TCGA-05-4249-01Z-00-DX1      1\n",
       "3  TCGA-05-4250-01Z-00-DX1      1\n",
       "4  TCGA-05-4382-01Z-00-DX1      1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from preprocessing import create_csv\n",
    "\n",
    "print('Creating main csv data files from original data...')\n",
    "create_csv(dir_luad_wsi, dir_lusc_wsi, csv_path_wsi, '.tif')\n",
    "\n",
    "# read files to check shapes\n",
    "df = pd.read_csv(csv_path_wsi)\n",
    "print(f'Files were read with shapes: {df.shape}')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Encoder network ##\n",
    "\n",
    "To perform NIC, we will need an encoder network to transform small image patches into embedding vectors. According to the paper, BiGAN produces the best unsupervised encoder and it is the one we will train here.\n",
    "\n",
    "Alternatively, a collection of pretrained encoders (the one used in the NIC paper) can be found in \n",
    "\n",
    "`./models/encoders_patches_pathology/*.h5`\n",
    "\n",
    "Remember that these pretrained encoders accept 128x128x3 patches taken at 0.5 um/px resolution (often level 1), except for the BiGAN model that takes 64x64x3 at 1 um/px (often level 2).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to train the BiGAN model, we will first extract patches from the slides in the `encoder` partition. We will sample 10K patches per slide, producing ~260K patches in total. We select 96x96 patches to perform crop augmentation during training later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%% \n"
    }
   },
   "outputs": [],
   "source": [
    "# # Dont run this we, will train later the encoder but not now. \n",
    "\n",
    "# from source.extract_patches import create_patch_dataset\n",
    "\n",
    "# patches_npy_path = join(root_dir, 'results', 'patches', 'training.npy')\n",
    "\n",
    "# # Extracts patches from whole-slide images and store them in a numpy array file\n",
    "# create_patch_dataset(\n",
    "#     input_dir=slide_dir,\n",
    "#     csv_path=csv_path,\n",
    "#     partition_tag='encoder',\n",
    "#     output_path=patches_npy_path,\n",
    "#     image_level=2,\n",
    "#     patch_size=96,\n",
    "#     n_patches_per_image=10000,\n",
    "#     cache_dir=join(cache_dir, 'patches')\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have extracted the patches, we can proceed to train the BiGAN model. We will use the hyper-parameters described in the NIC paper. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from source.train_bigan_model import BiganModel\n",
    "\n",
    "# model_bigan_dir = join(root_dir, 'results', 'encoders', 'bigan', 'rotterdam1_96_noaug', '0.0001')\n",
    "\n",
    "# # Trains BiGAN\n",
    "# bigan = BiganModel(\n",
    "#     latent_dim=128,\n",
    "#     n_filters=128,\n",
    "#     lr=0.0001,\n",
    "#     patch_size=64,\n",
    "# )\n",
    "# bigan.train(\n",
    "#     x_path=patches_npy_path,\n",
    "#     output_dir=model_bigan_dir,\n",
    "#     epochs=400000,\n",
    "#     batch_size=64,\n",
    "#     sample_interval=1000,\n",
    "#     save_models_on_epoch=True\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beware that training this model is highly unstable, thus it can fail or collapse with ease. If this happens, restart the training. Selecting a checkpoint model is a manual procedure: check the generated images and loss values and avoid abnormal results. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Compress images ##\n",
    "\n",
    "Once we have a trained encoder, we can proceed with the WSI compression. I recommend running several `IDLE` instances of the following code in the cluster to speed up the lenghty process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before the actual compression, we need to vectorize the WSIs. This process extracts all non-background patches from the slide and store them in numpy array format for quick access. In this case, we will read 64x64 patches at 1 um/px resolution (level 2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already existing file TCGA-05-4244-01Z-00-DX1 - 9 images left\n",
      "Already existing file TCGA-05-4245-01Z-00-DX1 - 8 images left\n",
      "Already existing file TCGA-05-4249-01Z-00-DX1 - 7 images left\n",
      "Already existing file TCGA-05-4250-01Z-00-DX1 - 6 images left\n",
      "Already existing file TCGA-05-4382-01Z-00-DX1 - 5 images left\n",
      "Already existing file TCGA-05-4395-01Z-00-DX1 - 4 images left\n",
      "Already existing file TCGA-05-4396-01Z-00-DX1 - 3 images left\n",
      "Already existing file TCGA-05-4397-01Z-00-DX1 - 2 images left\n",
      "Already existing file TCGA-05-4398-01Z-00-DX1 - 1 images left\n",
      "Already existing file TCGA-4B-A93V-01Z-00-DX1 - 0 images left\n",
      "Finish Processing All images!\n"
     ]
    }
   ],
   "source": [
    "# Vectorize LUAD WSIs\n",
    "from vectorize_wsi import vectorize_images\n",
    "\n",
    "vectorize_images(\n",
    "    input_dir=dir_luad_wsi,\n",
    "    mask_dir=dir_luad_wsi_mask, \n",
    "    output_dir=vectorized_luad_dir, \n",
    "    cache_dir=cache_dir, \n",
    "    image_level=2, \n",
    "    patch_size=128\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already existing file TCGA-33-4538-01Z-00-DX3 - 9 images left\n",
      "Already existing file TCGA-52-7812-01Z-00-DX1 - 8 images left\n",
      "Already existing file TCGA-60-2721-01Z-00-DX1 - 7 images left\n",
      "Already existing file TCGA-77-8007-01Z-00-DX1 - 6 images left\n",
      "Already existing file TCGA-77-8009-01Z-00-DX1 - 5 images left\n",
      "Already existing file TCGA-77-8139-01Z-00-DX1 - 4 images left\n",
      "Already existing file TCGA-77-8143-01Z-00-DX1 - 3 images left\n",
      "Already existing file TCGA-77-A5G1-01Z-00-DX1 - 2 images left\n",
      "Already existing file TCGA-NK-A5CR-01Z-00-DX1 - 1 images left\n",
      "Already existing file TCGA-NK-A5D1-01Z-00-DX1 - 0 images left\n",
      "Finish Processing All images!\n"
     ]
    }
   ],
   "source": [
    "# Vectorize LUSC WSIs\n",
    "\n",
    "vectorize_images(\n",
    "    input_dir=dir_lusc_wsi,\n",
    "    mask_dir=dir_lusc_wsi_mask, \n",
    "    output_dir=vectorized_lusc_dir, \n",
    "    cache_dir=cache_dir, \n",
    "    image_level=2, \n",
    "    patch_size=128\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can compress the WSIs. Each WSI (vectorized file) will be processed 8 times due to WSI-level augmentation (rotation and flip). We will use an existing pretrained encoder from the NIC paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Users\\Gabriel\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "Already existing file TCGA-05-4244-01Z-00-DX1_{item} - 9 images left\n",
      "Already existing file TCGA-05-4245-01Z-00-DX1_{item} - 8 images left\n",
      "Already existing file TCGA-05-4249-01Z-00-DX1_{item} - 7 images left\n",
      "Already existing file TCGA-05-4250-01Z-00-DX1_{item} - 6 images left\n",
      "Already existing file TCGA-05-4382-01Z-00-DX1_{item} - 5 images left\n",
      "Already existing file TCGA-05-4395-01Z-00-DX1_{item} - 4 images left\n",
      "Already existing file TCGA-05-4396-01Z-00-DX1_{item} - 3 images left\n",
      "Already existing file TCGA-05-4397-01Z-00-DX1_{item} - 2 images left\n",
      "Already existing file TCGA-05-4398-01Z-00-DX1_{item} - 1 images left\n",
      "Already existing file TCGA-4B-A93V-01Z-00-DX1_{item} - 0 images left\n",
      "Finish Processing All images!\n"
     ]
    }
   ],
   "source": [
    "# Featurize images\n",
    "from featurize_wsi import featurize_images\n",
    "\n",
    "# Featurize LUAD data\n",
    "featurize_images(\n",
    "    input_dir=vectorized_luad_dir,\n",
    "    model_path=model_path, \n",
    "    output_dir=featurized_luad_dir, \n",
    "    batch_size=32\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already existing file TCGA-33-4538-01Z-00-DX3_{item} - 9 images left\n",
      "Already existing file TCGA-52-7812-01Z-00-DX1_{item} - 8 images left\n",
      "Already existing file TCGA-60-2721-01Z-00-DX1_{item} - 7 images left\n",
      "Already existing file TCGA-77-8007-01Z-00-DX1_{item} - 6 images left\n",
      "Already existing file TCGA-77-8009-01Z-00-DX1_{item} - 5 images left\n",
      "Already existing file TCGA-77-8139-01Z-00-DX1_{item} - 4 images left\n",
      "Already existing file TCGA-77-8143-01Z-00-DX1_{item} - 3 images left\n",
      "Already existing file TCGA-77-A5G1-01Z-00-DX1_{item} - 2 images left\n",
      "Already existing file TCGA-NK-A5CR-01Z-00-DX1_{item} - 1 images left\n",
      "Already existing file TCGA-NK-A5D1-01Z-00-DX1_{item} - 0 images left\n",
      "Finish Processing All images!\n"
     ]
    }
   ],
   "source": [
    "# Featurize LUSC data\n",
    "featurize_images(\n",
    "    input_dir=vectorized_lusc_dir,\n",
    "    model_path=model_path, \n",
    "    output_dir=featurized_lusc_dir, \n",
    "    batch_size=32\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train CNN on compressed images ##\n",
    "\n",
    "Once we have compressed the WSIs, we can proceed with the CNN classifier. In this example, we will train a classifier targeting the binary label `HGP_SL` found in the CSV file. We will be training 4 models using cross-validation: in each fold, we will use 2 data partitions for training, 1 for validation and 1 for testing. At the end of model training, we perform inference on the test set, compute metrics, and run GradCAM on the images.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_training import train_wsi_classifier, eval_model, compute_metrics\n",
    "from utils import check_file_exists\n",
    "\n",
    "def train_model(featurized_dir, csv_path, fold_n, output_dir, cache_dir, batch_size=16, epochs=32,\n",
    "                images_dir=None, vectorized_dir=None, lr=1e-2, patience=4, delete_folder=False,\n",
    "                occlusion_augmentation=False, elastic_augmentation=False, shuffle_augmentation=None):\n",
    "    \"\"\"\n",
    "    Trains a CNN using compressed whole-slide images.\n",
    "\n",
    "    :param featurized_dir: folder containing the compressed (featurized) images.\n",
    "    :param csv_path: list of slides with labels.\n",
    "    :param fold_n: fold determining which data partitions to use for training, validation and testing.\n",
    "    :param output_dir: destination folder to store results.\n",
    "    :param cache_dir: folder to store compressed images temporarily for fast access.\n",
    "    :param batch_size: number of samples to train with in one-go.\n",
    "    :return: nothing.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Delete folder and subfolders if exists\n",
    "    if delete_folder: \n",
    "        if exists(result_dir):  shutil.rmtree(result_dir)\n",
    "            \n",
    "    # Train CNN\n",
    "    train_wsi_classifier(\n",
    "        data_dir=featurized_dir,\n",
    "        csv_path=csv_path,\n",
    "        partitions=None,\n",
    "        crop_size=400,\n",
    "        output_dir=output_dir,\n",
    "        output_units=2,\n",
    "        cache_dir=cache_dir,\n",
    "        n_epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        lr=lr,\n",
    "        code_size=128,\n",
    "        workers=1,\n",
    "        train_step_multiplier=1,\n",
    "        val_step_multiplier=0.5,\n",
    "        keep_data_training=1,\n",
    "        keep_data_validation=1,\n",
    "        patience=patience,\n",
    "        occlusion_augmentation=occlusion_augmentation,\n",
    "        elastic_augmentation=elastic_augmentation,\n",
    "        shuffle_augmentation=shuffle_augmentation\n",
    "    )  \n",
    "\n",
    "    # Evaluate CNN \n",
    "    \n",
    "    # Get compressed wsi directories with csv test file\n",
    "    data_config = featurized_dir\n",
    "    data_config['csv_path'] = csv_path['csv_test']\n",
    "    \n",
    "    eval_model(\n",
    "        model_path=join(output_dir, 'checkpoint.h5'),\n",
    "        data_config=data_config,\n",
    "        crop_size=400,\n",
    "        output_path=join(output_dir, 'eval', 'preds.csv'),\n",
    "        cache_dir=None,\n",
    "        batch_size=batch_size,\n",
    "        keep_data=1\n",
    "    )\n",
    "\n",
    "    # Metrics\n",
    "    try:\n",
    "        compute_metrics(\n",
    "            input_path=join(output_dir, 'eval', 'preds.csv'),\n",
    "            output_dir=join(output_dir, 'eval')\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print('Failed to compute metrics. Exception: {e}'.format(e=e), flush=True)\n",
    "\n",
    "#     # Apply GradCAM analysis to CNN\n",
    "#     gradcam_on_dataset(\n",
    "#         featurized_dir=featurized_dir,\n",
    "#         csv_path=csv_path,\n",
    "#         model_path=join(output_dir, 'checkpoint.h5'),\n",
    "#         partitions=folds[fold_n]['test'],\n",
    "#         layer_name='separable_conv2d_1',\n",
    "#         output_unit=1,\n",
    "#         custom_objects=None,\n",
    "#         cache_dir=cache_dir,\n",
    "#         images_dir=images_dir,\n",
    "#         vectorized_dir=vectorized_dir\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading training set ...\n",
      "FeaturizedWsiGenerator data config: {'data_dir_luad': 'E:\\\\pathology-weakly-supervised-lung-cancer-growth-pattern-prediction\\\\results\\\\tcga_luad\\\\featurized', 'data_dir_lusc': 'E:\\\\pathology-weakly-supervised-lung-cancer-growth-pattern-prediction\\\\results\\\\tcga_lusc\\\\featurized', 'csv_path': 'E:\\\\pathology-weakly-supervised-lung-cancer-growth-pattern-prediction\\\\data\\\\train_slide_list_tcga.csv'}\n",
      "FeaturizedWsiGenerator using 11 samples and 3 batches, distributed in 4 positive and 7 negative samples.\n",
      "Loading validation set ...\n",
      "FeaturizedWsiSequence data config: {'data_dir_luad': 'E:\\\\pathology-weakly-supervised-lung-cancer-growth-pattern-prediction\\\\results\\\\tcga_luad\\\\featurized', 'data_dir_lusc': 'E:\\\\pathology-weakly-supervised-lung-cancer-growth-pattern-prediction\\\\results\\\\tcga_lusc\\\\featurized', 'csv_path': 'E:\\\\pathology-weakly-supervised-lung-cancer-growth-pattern-prediction\\\\data\\\\validation_slide_list_tcga.csv'}\n",
      "FeaturizedWsiSequence using 5 samples and 2 batches, distributed in 4 positive and 1 negative samples.\n",
      "Building model ...\n",
      "Training model ...\n",
      "Training model in directory: E:\\pathology-weakly-supervised-lung-cancer-growth-pattern-prediction\\results\\model with content 0\n",
      "Training model from scratch False False...\n",
      "WARNING:tensorflow:From D:\\Users\\Gabriel\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, 400, 400, 128)     0         \n",
      "_________________________________________________________________\n",
      "separable_conv2d_1 (Separabl (None, 199, 199, 128)     17664     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 199, 199, 128)     512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 199, 199, 128)     0         \n",
      "_________________________________________________________________\n",
      "spatial_dropout2d_1 (Spatial (None, 199, 199, 128)     0         \n",
      "_________________________________________________________________\n",
      "separable_conv2d_2 (Separabl (None, 99, 99, 128)       17664     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 99, 99, 128)       512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 99, 99, 128)       0         \n",
      "_________________________________________________________________\n",
      "spatial_dropout2d_2 (Spatial (None, 99, 99, 128)       0         \n",
      "_________________________________________________________________\n",
      "separable_conv2d_3 (Separabl (None, 49, 49, 128)       17664     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 49, 49, 128)       512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 49, 49, 128)       0         \n",
      "_________________________________________________________________\n",
      "spatial_dropout2d_3 (Spatial (None, 49, 49, 128)       0         \n",
      "_________________________________________________________________\n",
      "separable_conv2d_4 (Separabl (None, 24, 24, 128)       17664     \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 24, 24, 128)       512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 24, 24, 128)       0         \n",
      "_________________________________________________________________\n",
      "spatial_dropout2d_4 (Spatial (None, 24, 24, 128)       0         \n",
      "_________________________________________________________________\n",
      "separable_conv2d_5 (Separabl (None, 11, 11, 128)       17664     \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 11, 11, 128)       512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)    (None, 11, 11, 128)       0         \n",
      "_________________________________________________________________\n",
      "spatial_dropout2d_5 (Spatial (None, 11, 11, 128)       0         \n",
      "_________________________________________________________________\n",
      "separable_conv2d_6 (Separabl (None, 5, 5, 128)         17664     \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 5, 5, 128)         512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)    (None, 5, 5, 128)         0         \n",
      "_________________________________________________________________\n",
      "spatial_dropout2d_6 (Spatial (None, 5, 5, 128)         0         \n",
      "_________________________________________________________________\n",
      "separable_conv2d_7 (Separabl (None, 3, 3, 128)         17664     \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 3, 3, 128)         512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)    (None, 3, 3, 128)         0         \n",
      "_________________________________________________________________\n",
      "spatial_dropout2d_7 (Spatial (None, 3, 3, 128)         0         \n",
      "_________________________________________________________________\n",
      "separable_conv2d_8 (Separabl (None, 1, 1, 128)         17664     \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 1, 1, 128)         512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)    (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "spatial_dropout2d_8 (Spatial (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_9 (LeakyReLU)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 258       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 162,690\n",
      "Trainable params: 160,386\n",
      "Non-trainable params: 2,304\n",
      "_________________________________________________________________\n",
      "Epoch 1/2\n",
      "3/3 [==============================] - ETA: 22s - loss: 0.9636 - categorical_accuracy: 0.250 - ETA: 8s - loss: 0.6357 - categorical_accuracy: 0.500 - 27s 9s/step - loss: 0.4400 - categorical_accuracy: 0.6667 - val_loss: 0.7155 - val_categorical_accuracy: 0.5000\n",
      "Epoch 00000: val_loss improved from inf to 0.71547, saving model to E:\\pathology-weakly-supervised-lung-cancer-growth-pattern-prediction\\results\\model\\checkpoint.h5\n",
      "Epoch 00000: saving model to E:\\pathology-weakly-supervised-lung-cancer-growth-pattern-prediction\\results\\model\\last_epoch.h5\n",
      "Epoch 2/2\n",
      "3/3 [==============================] - ETA: 12s - loss: 0.0166 - categorical_accuracy: 1.000 - ETA: 6s - loss: 0.0380 - categorical_accuracy: 1.000 - 22s 7s/step - loss: 0.0303 - categorical_accuracy: 1.0000 - val_loss: 0.7441 - val_categorical_accuracy: 0.5000\n",
      "Epoch 00001: val_loss did not improve (current: 0.74407, best: 0.71547, monitor_op: <ufunc 'less'>, best_op: <function ModelCheckpoint.__init__.<locals>.<lambda> at 0x00000281AD38B400>)\n",
      "Epoch 00001: saving model to E:\\pathology-weakly-supervised-lung-cancer-growth-pattern-prediction\\results\\model\\last_epoch.h5\n",
      "Evaluating model in directory: E:\\pathology-weakly-supervised-lung-cancer-growth-pattern-prediction\\results\\model\\eval with content 0\n",
      "Loading test set ...\n",
      "FeaturizedWsiSequence data config: {'data_dir_luad': 'E:\\\\pathology-weakly-supervised-lung-cancer-growth-pattern-prediction\\\\results\\\\tcga_luad\\\\featurized', 'data_dir_lusc': 'E:\\\\pathology-weakly-supervised-lung-cancer-growth-pattern-prediction\\\\results\\\\tcga_lusc\\\\featurized', 'csv_path': 'E:\\\\pathology-weakly-supervised-lung-cancer-growth-pattern-prediction\\\\data\\\\test_slide_list_tcga.csv'}\n",
      "FeaturizedWsiSequence using 4 samples and 1 batches, distributed in 4 positive and 4 negative samples.\n",
      "Predicting batch 1/1 ...\n"
     ]
    }
   ],
   "source": [
    "# Train CNN\n",
    "\n",
    "#selected_fold = 0\n",
    "\n",
    "featurized_dir = {'data_dir_luad': featurized_luad_dir, 'data_dir_lusc': featurized_lusc_dir}\n",
    "csv_path = {'csv_train': csv_train, 'csv_val': csv_val, 'csv_test': csv_test}\n",
    "\n",
    "train_model(\n",
    "    featurized_dir=featurized_dir,\n",
    "    csv_path=csv_path,\n",
    "    fold_n=0, \n",
    "    output_dir=result_dir,\n",
    "    cache_dir=None,\n",
    "    batch_size =4,\n",
    "    epochs=2,\n",
    "    delete_folder=True,\n",
    "    occlusion_augmentation=False,\n",
    "    lr=1e-2,\n",
    "    patience=4,\n",
    "    elastic_augmentation=False,\n",
    "    images_dir=None,  # required for GradCAM\n",
    "    vectorized_dir=None,  # required for GradCAM\n",
    "    shuffle_augmentation=None\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aplying GradCam\n",
    "\n",
    "Here we get the folder separetely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:00<00:00, 29980.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Csv file sucessfully exported!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>slide_id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TCGA-05-4244-01Z-00-DX1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TCGA-05-4245-01Z-00-DX1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TCGA-05-4249-01Z-00-DX1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TCGA-05-4250-01Z-00-DX1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TCGA-05-4382-01Z-00-DX1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>TCGA-05-4395-01Z-00-DX1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>TCGA-05-4396-01Z-00-DX1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>TCGA-05-4397-01Z-00-DX1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>TCGA-05-4398-01Z-00-DX1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>TCGA-4B-A93V-01Z-00-DX1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  slide_id  label\n",
       "0  TCGA-05-4244-01Z-00-DX1      1\n",
       "1  TCGA-05-4245-01Z-00-DX1      1\n",
       "2  TCGA-05-4249-01Z-00-DX1      1\n",
       "3  TCGA-05-4250-01Z-00-DX1      1\n",
       "4  TCGA-05-4382-01Z-00-DX1      1\n",
       "5  TCGA-05-4395-01Z-00-DX1      1\n",
       "6  TCGA-05-4396-01Z-00-DX1      1\n",
       "7  TCGA-05-4397-01Z-00-DX1      1\n",
       "8  TCGA-05-4398-01Z-00-DX1      1\n",
       "9  TCGA-4B-A93V-01Z-00-DX1      1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_csv(data_dir, csv_path, ext='.png'):\n",
    "    \"\"\"\n",
    "    Creates csv file from data folder\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data_dir : data folder\n",
    "\n",
    "    Output\n",
    "    ----------\n",
    "    csv file with labels as 1 and slide names\n",
    "\n",
    "    Example: create_csv(featurized_luad_dir, csv_path)\n",
    "    -----\n",
    "    \"\"\"\n",
    "\n",
    "    files_class_1 = sorted([(os.path.basename(file)).split('.')[0] for file in tqdm(os.listdir(data_dir)) if file.endswith(ext)])\n",
    "    labels1 = np.ones(len(files_class_1), dtype=np.int8)\n",
    "    df1 = pd.DataFrame(list(zip(files_class_1, labels1)), columns=['slide_id', 'label'])\n",
    "    df1.to_csv(csv_path, index=None, header=True)\n",
    "    print('Csv file sucessfully exported!')\n",
    "\n",
    "csv_path_luad_feat = join(data_dir, 'slide_list_featurized_luad.csv')\n",
    "create_csv(featurized_luad_dir, csv_path_luad_feat)\n",
    "pd.read_csv(csv_path_luad_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for layer in model.layers:\n",
    "#     print(layer.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradCAM in directory: E:\\pathology-weakly-supervised-lung-cancer-growth-pattern-prediction\\results\\model\\gradcam with content 0\n"
     ]
    }
   ],
   "source": [
    "from gradcam_wsi import grad_cam_fn, gradcam_on_features, overlay_gradcam_heatmap\n",
    "from gradcam_wsi import image_crop_from_wsi, overlay_gradcam_heatmap_bicolor\n",
    "from nic.util_fns import cache_file\n",
    "from data_processing import read_data\n",
    "from keras import backend as K\n",
    "\n",
    "\n",
    "csv_path = 'E:/pathology-weakly-supervised-lung-cancer-growth-pattern-prediction/data/slide_list_featurized_luad.csv'\n",
    "model_path = join(result_dir, 'checkpoint.h5')\n",
    "\n",
    "#############################\n",
    "#This section will be adapted once gradcam is in a unified function\n",
    "#############################\n",
    "# GradCam for LUAD compressed images for now!!! This has to be modified to get for the whole dataset\n",
    "images_dir =  dir_luad_wsi \n",
    "predict_two_output = True \n",
    "output_dir = join(result_dir, 'gradcam') if gradcam_dir is None else gradcam_dir\n",
    "vectorized_dir = vectorized_luad_dir\n",
    "#############################\n",
    "\n",
    "\n",
    "\n",
    "#############################\n",
    "# Function starts\n",
    "#############################\n",
    "\n",
    "if not exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "    \n",
    "print('GradCAM in directory: {d} with content {c}'.format(\n",
    "        d=output_dir,\n",
    "        c=os.system(\"ls \" + output_dir)\n",
    "    ), flush=True)\n",
    "\n",
    "# List features\n",
    "data_config = {'data_dir_luad': featurized_luad_dir, 'data_dir_lusc': featurized_lusc_dir, 'csv_path': csv_path}\n",
    "image_ids, paths, dm_paths, labels, features_ids = read_data(data_config, custom_augmentations=None)\n",
    "\n",
    "# Load model\n",
    "K.set_learning_phase(0)  # required to avoid bug \"You must feed a value for placeholder tensor 'batch_normalization_1/keras_learning_phase' with dtype bool\"\n",
    "model = keras.models.load_model(model_path, custom_objects=None)\n",
    "\n",
    "# get firt layer name \n",
    "layer_name=model.layers[1].name\n",
    "\n",
    "# Load gradient function\n",
    "gradient_function_0 = grad_cam_fn(model, 0, layer_name)\n",
    "\n",
    "if predict_two_output:\n",
    "    gradient_function_1 = grad_cam_fn(model, 1, layer_name)\n",
    "else:\n",
    "    gradient_function_1 = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing GradCAM on TCGA-05-4382-0 ... 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\Gabriel\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\scipy\\ndimage\\interpolation.py:611: UserWarning: From scipy 0.13.0, the output shape of zoom() is calculated with round() instead of int() - for these inputs the size of the returned array has changed.\n",
      "  \"the returned array has changed.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing GradCAM on TCGA-4B-A93V-0 ... 2/10\n",
      "Computing GradCAM on TCGA-05-4395-0 ... 3/10\n",
      "Computing GradCAM on TCGA-05-4244-0 ... 4/10\n",
      "Computing GradCAM on TCGA-05-4250-0 ... 5/10\n",
      "Computing GradCAM on TCGA-05-4397-0 ... 6/10\n",
      "Computing GradCAM on TCGA-05-4396-0 ... 7/10\n",
      "Computing GradCAM on TCGA-05-4249-0 ... 8/10\n",
      "Computing GradCAM on TCGA-05-4245-0 ... 9/10\n",
      "Computing GradCAM on TCGA-05-4398-0 ... 10/10\n"
     ]
    }
   ],
   "source": [
    "# Analyze features\n",
    "for i, (image_id, path, dm_path, label, features_id) in enumerate(zip(image_ids, paths, dm_paths, labels, features_ids)):\n",
    "\n",
    "    try:\n",
    "        print('Computing GradCAM on {filename} ... {i}/{n}'.format(\n",
    "                filename=features_id, i=i+1, n=len(image_ids)), flush=True)\n",
    "\n",
    "        output_npy_path0, output_png_path0 = gradcam_on_features(\n",
    "            features_path=cache_file(path, cache_dir, overwrite=False),\n",
    "            distance_map_path=cache_file(dm_path, cache_dir, overwrite=False),\n",
    "            gradient_function=gradient_function_0,\n",
    "            output_npy_path=join(output_dir, features_id + '_{unit}_{preds}_gradcam.npy'.format(unit=0, preds='{preds:0.3f}')),\n",
    "            output_png_path=join(output_dir, features_id + '_{unit}_{preds}_gradcam.png'.format(unit=0, preds='{preds:0.3f}')),\n",
    "        )\n",
    "\n",
    "        if predict_two_output:\n",
    "            output_npy_path1, output_png_path1 = gradcam_on_features(\n",
    "                features_path=cache_file(path, cache_dir, overwrite=False),\n",
    "                distance_map_path=cache_file(dm_path, cache_dir, overwrite=False),\n",
    "                gradient_function=gradient_function_1,\n",
    "                output_npy_path=join(output_dir, features_id + '_{unit}_{preds}_gradcam.npy'.format(unit=1, preds='{preds:0.3f}')),\n",
    "                output_png_path=join(output_dir, features_id + '_{unit}_{preds}_gradcam.png'.format(unit=1, preds='{preds:0.3f}')),\n",
    "            )\n",
    "        \n",
    "        if (images_dir is not None) and (vectorized_dir is not None):\n",
    "                image_crop_from_wsi(\n",
    "                    wsi_path=join(images_dir,  image_id + '.tif'),\n",
    "                    vectorized_im_shape_path=join(vectorized_dir, image_id + '_im_shape.npy'),\n",
    "                    distance_map_path=cache_file(dm_path, cache_dir, overwrite=False),\n",
    "                    output_npy_path=join(output_dir, features_id + '_image.npy'),\n",
    "                    output_png_path=join(output_dir, features_id + '_image.png'),\n",
    "                    crop_size=400\n",
    "                )\n",
    "        \n",
    "        overlay_gradcam_heatmap(\n",
    "                    gradcam_npy_path=output_npy_path0,\n",
    "                    image_npy_path=join(output_dir, features_id + '_image.npy'),\n",
    "                    output_png_path=join(output_dir, features_id + '_{unit}_heatmap.png'.format(unit=0))\n",
    "                )\n",
    "        \n",
    "        if predict_two_output:\n",
    "                    overlay_gradcam_heatmap(\n",
    "                        gradcam_npy_path=output_npy_path1,\n",
    "                        image_npy_path=join(output_dir, features_id + '_image.npy'),\n",
    "                        output_png_path=join(output_dir, features_id + '_{unit}_heatmap.png'.format(unit=1))\n",
    "                    )\n",
    "\n",
    "                    overlay_gradcam_heatmap_bicolor(\n",
    "                        gradcam_npy_path1=output_npy_path0,\n",
    "                        gradcam_npy_path2=output_npy_path1,\n",
    "                        image_npy_path=join(output_dir, features_id + '_image.npy'),\n",
    "                        output_png_path=join(output_dir, features_id + '_both_heatmap.png')\n",
    "                    )\n",
    "        \n",
    "    except Exception as e:\n",
    "        print('Failed to compute GradCAM on {f}. Exception: {e}'.format(f=path, e=e), flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_gradcam(gradcam_images):\n",
    "    %matplotlib inline\n",
    "    rows = 3; columns = 5;\n",
    "    fig, axs = plt.subplots(rows,columns,figsize=(20,8))\n",
    "    axs = axs.ravel()\n",
    "    n_images = rows * columns\n",
    "\n",
    "    for idx in range(n_images):\n",
    "        img = plt.imread(gradcam_images[idx])\n",
    "        if idx == 0: print(f'Images shape: {img.shape}')\n",
    "        axs[idx].imshow(img)\n",
    "        prefix = os.path.basename(gradcam_images[idx]).split('_')[0]\n",
    "        subfix = os.path.basename(gradcam_images[idx]).split('_')[-1]\n",
    "        axs[idx].set_title(prefix + '_' + subfix)\n",
    "        axs[idx].set_xlabel(prefix + subfix)\n",
    "        axs[idx].get_xaxis().set_visible(False)\n",
    "        axs[idx].get_yaxis().set_visible(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images shape: (400, 400, 4)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABGQAAAHUCAYAAAB8hv4XAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nOzdd7xcd33n/9dn5lb1LlnFlm3ZMu7YNDdw1gYTgmNKyEJMbIpjSA+k/EInCWFD2GyWTYH1wuIQSujVMbBUd4x775bVbfVypVtm5vv745yRjq5us3U1M9J9PR+PeejOnHO+853yme/oPd9zTqSUkCRJkiRJUuOUmt0BSZIkSZKkicZARpIkSZIkqcEMZCRJkiRJkhrMQEaSJEmSJKnBDGQkSZIkSZIazEBGkiRJkiSpwQxkNGYR8bOIuKLZ/ZAOFRGxNCJSRLQ1uy+SGssxU3r2HDel1mRtHjyjBjIRsbNwqUXE7sL1S/N1jo+Ir0bExojYFhH3RMS7I6KcL++IiA9GxMMR0RMRayLi2oh4xRD397OI2BIRnWPo2wUR8VBE7IqIn0bEUYVlH46IgUH9P2YMbXbkba4u3DYvIr4UEWvzx3djRLx4mO0/m79Zlw2xbFZEbIiIG0bpQ2dE/N+I2B4R6yPi3aP1WxOLdWldRsTVEfGRZvZB+7M2rU21JmvT2nTcbE3WprU50Wtz1EAmpTSlfgFWAhcXbvtCRBwL/AJYBZySUpoOvAF4ATA1b+ZrwCXAZcBM4GjgE8CvFe8rIpYC5wEJ+PWR+hURc4BvAB8AZgG3AV8etNqXi/1PKT0x2uMF/hx4ZtBtU4BfAmfm9/VvwDURMWVQn84Fjh2h7Y8BD46hDx8GjgOOAn4F+IuIeOUYthuzMN08pFmXwGFYlzr0WZvAYVibjpmHPmsTOAxrU4c+axOwNie2lNKYL8AK4MJBt30euGaEbS4EdgOLx9D+B4Ebgf8BfG+Uda8Ebipcn5zfzwn59Q8Dn3+Wj+9osjfxrwKrR1l3O3Bm4XobcCdwKlmRLxu0/lnAzcBbgRtGaXsN8IrC9b8B/mMM/b8MeArYRPbhsef1yp+Pr+Wv13bgCuBFeZ+2AuuAfwY6Cu29HHgI2JYv+zlwRWH57+TP1w7gAeCM/Pa/BB4v3P7awjZvyV/jf8zv9wng7Pz2VWQfUJeP8h58T97uFuCzQFe+7HxgNfCneTvrgLcWtp0NfDd//L8EPjLaa3EoXKzL1q1LYGl+v5eTfcnYCLyvsLxUqJdNwFeAWYXlXwXW5zV4HXBS4XkeAPqBncB3C++FPwfuAXqAzwDzgWvzevwRMHO09vNlVwOfAv5fvu3PgaOGeZz12ntv/hhXAJcOautfgGvytn4BHFtY/grg4bwf/8qgz5pD9YK12bK1ma/nmDkBx8zC82JtptarTRw3i205biZrs3Dd2jxMa3M8jiFzIdmXlpGW/yKltHqEdeouA76QXy6KiPkjrHsScHf9Skqph+wNcFJhnYsjYnNE3B8RvzuG+/8nsid/90grRcTpQAfwWOHmdwHXpZTuGWL9MtkL9wdkb+SR2p4JLKTw2PK/Txp6iz3bnUj2ol8KHAFMBxYNWu0SstdqBtlzXM37PYesiC8Afi9vbw7wdeD9+fLHgXMK9/cGsg+iy4BpZCnzpnzx42Tp83Tgr4DPR8QRhX68mKy4ZgNfBP4DeCGwDHgz8M+DE+FBLgUuIkuIj8/7WLeg8NjfDvxL/pxC9hr05Otcnl8OV9Zlpql1WXAusJysxj4YEc/Lb/8j4DXAy/L2t+R9qruW7BeMecAdZK8BKaWr8r//PmW/yFxc2Ob1ZP8xPB64OG/jvWR1XMrvc8T2Cy4lG6TnAHcNsbxoQb7eIrLauioilheWv4ns82Am2Wv0t7Dns+ZrZP9pnE02iJ09wv0c6qzNjGOmY2arsTYzjpuOm63G2sxYm4drbY5DajkAvHKEbT5NIXEjm4a1lSw16i3cfm7e1pz8+kPAu0Zo9zPA3w267UbgLfnfJ5K9Gcr5E7EOeNMI7b0W+H4xGRtmvWnAvcB7CrctyV+M6fn1fVJLsgL6ZP73WxghtczbSuS/YOW3vRxYMcpr80HgS4Xrk8iSxuKvfdeN0safAN/M/74MuKWwLMjSwivy6z8A/niM75u7gEsKj//RwrJT8sc7v3DbJuD0Ed6D7yxcfxXweOF12w20FZY/A7wkfx8MAMsLyw6LX/usy5auy6X5dosLt90KvDH/+0HggsKyI/Lnu22ItmbkbdUfz9XAR4Z4LxRT/K/XH2N+/Q+Bbw3T16HaL75HppD9h3TJENueD1SAyYXbvgJ8oNDWpwvLXgU8lP99GXBzYVmQ/fJ/uP7SZ222Rm06Zk7QMbPwvFibrVmbS3HcrLfluJmszfw2a/Mwrs3xmCGzKX/Cx7Q8pbQ5pTSDbB+54sGULgd+mFLamF//Yn4bEXFk8YBJ+fKdZG/YomlkU4dIKT2QUlqbUqqmlG4i24/wN/L23lto71MRMRn4e7IXdlgR0U02ffeWlNJ/Kyz6n8Bfp5S2DbHNQrL07n3DtPmpQl/emz+u+mPZ73GNYCHZCw5ASmkXe399q1tVvBLZAbK+lx/MaTvwUbI0cKj20qDtl5ClxEM9pssi4q6I2BoRW4GTC+0CPF34e3fe/uDbRvq1r9iPp/K+1m1KKVUK13flbc0lm+pX3Haf5+MwY122Rl3WrS/8XX9PQrbv7jcLtfIg2QAxPyLKEfF3EfF4Xp8r8m2KtTSUwbU0ZG2Nsf3iZ8BOYDP71lvRlpT9elQ3uDaHew6G+qwZy69chyprszVq0zEz45i5l7XZGrVZ57jpuFlnbVqbcBjX5ngcpO5HZNOJPjvM8h8DfxgRi9MwU8nyN99vAuWIqD/ATmBGRJyWUrqb/b9s3E9h+mz+Rj82v30oiSylIqX0UbIvUvVtTydL/a6PCMimiE3P+/KSlNKKyI7E/S2yfe7eMajtC4BzI+LvC7fdHBF/TPYiHQE8kLfdDXTnbS9KKb0TeOeg52MdcBrZfm7kfw/3uOrWkU0fq7fRTTZVavBzUPRJsn0R35RS2hERf0L+QZK3t6TQXhSvk73Z9juoVGRHH/8/ZM/JzSmlakTcRf7cj5NiP44E1o5hmw1kaedi4JEh2jncWJetUZejWQW8LaV04+AFEfHbZLtMXEg2sEwnm/5Zr6XB9fxs/dYo7cO+nwFTyH51Gq7eZkbE5MIAdiRw3xj6sY6sLuv3E8XrhyFrszVq0zFzZBNtzARrE1qjNkfjuOm4OZi1aW0e0rU5HjNkPgScHREfj4gF+Z0vi4jPR8SMlNIPgZ8C34qIF0d2qq92simxda8hS9BOBE7PL88Drieb+jOUbwInR8TrI6KLbPrxPSmlh/I+XBIRMyPzIrLk8NvDtHUf2YtUv+8ryBK404FVeX+/RpbEXZZSqg3a/niyN3J9e8j2c/sm2f5sSwvLPkj2he70lFJ1mP58Dnh/3v8TyA4EePUw69Z9jWw/xrMjooNsv7bRvtBNJTtg1M78for7Pl4DnBQRr4vs7BJ/RLY/Xd2ngT+LiDPz53hZ/sVyMllRbQCIiLeS/do3nn4/IhZHxCyy/QgHH/F8P/lz/Q3gwxExKX+8w723DgfWZWvU5Wg+BfxtXjtExNyIuCRfNhXoI/vlZxKFgT33NDDq6RVHMFr7AK+KiHPzz5S/IdtHe6Rfyf8qfy+dB7ya7ABro7kGOCUiXpN/1vw++37WHG6szdaoTcfMEUzAMROsTWiN2hyN46bjprWZsTb3OqRr84ADmZTS42QHt1sK3B8R28j28bqNvVOfXgd8j+wo2VuBJ8kOrFM/vdblwGdTSitTSuvrF7KzFFwaQ5xuMqW0gSwt/VuyBOzFwBsLq7yRbF+7HWRvuo+llP5tmMdQGXS/m4Fafr1Ktl/gq8mOmrw19k77Oi/f/plB2wNsTCntTin1DVq2DRgorDeUD5FNbX6K7MjMH08pfX+E9Ukp3U82De4/yNK5HWT7gveNsNmfkSWKO8h+odvzJS2fzvcG4O/I3tzHke03WV/+VbLn/ov59t8iO5L2A8A/kB3l+2my/d33S0rHKrIpf9cOuvmLwA/JzjbxBNl+7WPxB2SJ6Xrg34EvMfLzc8iyLlujLsfgE8B3gB9GxA7gFrLnDLLn5ymyX0oeyJcVfQY4MbKpod96Dvc9WvuQ1dqHyJ77M8neHwBEdgC7Swvrrid7zdeSHSjtnfUvLSMpfNb8PdlnzYlk71Nr09p0zHyWHDOfO2uzNWpzDBw3HTetzYy1udchXZuR0oHOEFIrimwq1lbguJTSk83uz3iJiBVkB0b60Ti09TFgQUrp8lFXliaYiLia7IBz7x/DuueTnfrxgKdMR0SJbH/bS1NKPz3Q9qSxcMwcU1uOmdIIHDel1tTqtTkeuyypRUTExfnU4snAfyc7QveK5vaqdUTECRFxamFq4dvJpvpJaqKIuCgiZkS2//R7yXYdGerXDWncOGaOzDFTal2Om1Jrei61aSBzCImISwtT2IqX+kGYLiGbWrWWbLr0G5NToIqmku0T30N2+rJ/YPh9PaUxGUNdanRnkU2d3Ui2T/RrUkq7m9slHeocMw+YY6YOCsfNceG4qXFnbY6LZ12b7rIkSZIkSZLUYM6QkSRJkiRJarD9jijdbB3l7tTdPr3Z3VCTbO97emNKaW6z+6H9TZkyI82evbDZ3VCTrFz5oLXZoto7Jqeu7pnN7oaaZOf2NdZmi5o+Z2ZasNRxc6J65PYHrM0WNXn61DRz3pxmd0NNsuaxFS1Vmy0XyHS3T+esI4c7HbwOdz949ONPNbsPGtrs2Qt53/s+1+xuqEne8Y4XWpstqqt7Jmee9YfN7oaa5Oc/+Etrs0UtWLqQq2778ugr6rB0fpxibbaomfPm8Af/+FfN7oaa5D0XX95StekuS5IkSZIkSQ1mICNJkiRJktRgBjKSJEmSJEkNZiAjSZIkSZLUYAYykiRJkiRJDWYgI0mSJEmS1GAGMpIkSZIkSQ1mICNJkiRJktRgBjKSJEmSJEkNZiAjSZIkSZLUYAYykiRJkiRJDWYgI0mSJEmS1GAGMpIkSZIkSQ1mICNJkiRJktRgBjKSJEmSJEkNZiAjSZIkSZLUYAYykiRJkiRJDWYgI0mSJEmS1GAGMpIkSZIkSQ1mICNJkiRJktRgBjKSJEmSJEkNZiAjSZIkSZLUYAYykiRJkiRJDWYgI0mSJEmS1GAGMpIkSZIkSQ1mICNJkiRJktRgBjKSJEmSJEkNZiAjSZIkSZLUYAYykiRJkiRJDWYgI0mSJEmS1GAGMpIkSZIkSQ1mICNJkiRJktRgBjKSJEmSJEkNZiAjSZIkSZLUYAYykiRJkiRJDWYgI0mSJEmS1GAGMpIkSZIkSQ1mICNJkiRJktRgBjKSJEmSJEkNZiAjSZIkSZLUYAYykiRJkiRJDWYgI0mSJEmS1GAGMpIkSZIkSQ1mICNJkiRJktRgBjKSJEmSJEkNZiAjSWNw5ZUvaHYXJEmSpANyzhnLmt0FFRjISNIoDGMkSZJ0qDOMaT1tze6AJLWqehBz1VW37XO9qL5MkiRJakX1IObGOx7b53pRfZkay0BGkoYxOIgxfJEkSdKhZnAQY/jSOgxkJOkAFGfNGNhIkiTpUFScNWNg0zgGMpI0TpxJI0nSXi/j5H2u/5z7mtQTSUVz+47Z5/qGzif2ue5MmsYxkJGkgpGOE+MxZCRJGruhApiXcbLBjNQAIx0n5pyz9l12PMt45ObafsGMDj7PsiRJIygGLldddZsBjCRJkg45xdkuN97xmLNfWoQzZCSJbPbL4PBlOIYykiTta/DuSQDXcS8lEkGNRIka4ewY6SA754xl+4Qtj9xcA2Aue3dT2tD5BEFw0x2PA5BI0NnYfipjINNiopZIpWh2N6QJa/iwpf5xWRv0716Dd2kyuJEarJbAMVRquKHCGIA2KnTSTye99NFFHx1UaCMRe7YzoJEOjhvveGy/Y8UAECVKUaYcQVupTKVWoZoStbT3u+1fvvoyrl970z5t6eAwkGkhUUuktjJRqe65zXBGarYSMDW/tJMFMX3A7vzf3j1rDg5g6rNuBs++kTQ+UkCkvf9Wu8qUe6uGMlIDDRfGAExjO8fwJJNu74cTYVX3EaxkCZX8vyCGMdLBs38YE1Bug3I7nZ2TmNY5hZkd09jRt52dfTvZ3rczmykD/N33PrfPlvVZN4Nn3+jAeQyZFhC1BOUyqWcXu4+eSdrRA7t2k3p2QcmXSDoYhjpA777qQcxiWHQcAxdMY/LlO5j31k2U3zIZTj0OJp8MzMFsW2qCWiK1BaX+GpVJZVLAqouCtl0VknmM1DTXcS+3cht9fVs5pucUegf6efTWPvgGLHlyHd300kaFMjUi/8+fpOduqIP37isLYjZMWsX2Wc8wee5Ujp5zOtNmTWLh/CNZPP945s5aQnt7JxElAgfRRvJ/+y0gdbZTe3wFqy5fxsZTO1jzW8fxwEeW8ODfHEVa9wxEZKGNpAZqA6YD86ieuIudv/wO/2XN15l11b/z2vg6c5//KLwU4ChgMkOFMs6OkQ6SWqLWWWLSwxsp7xqga0MfnRt3M++WYNbHV9GxrT/bfUlSw72UUyj3buUrf34TTz9U4WvvO5Ojf6PGwDm97Di6iwptdNNLN7spFQKZkWbaSDoAEVDuYG75dLrKJZ768VrmVbvovWk2lfIz9LGZgbYBauV22svttJXL+4Qyc/uOcXbMQeTPus1WKtG3cBr9zzuTzi2JniOCP37rt+lN7dy7YzE/++uTKe8Ojv3rO4mjFhMDFXdjksZBPSwpXt/XZOhYwMAJu1j3s59wxubr+eVb2xnY2s0d33iCxVc8xfLfeCE3vOTX4ZajgbXAZqDSwEchTUxRg0krtrPt+fOY9vA2YqAGJZj+aA/b3zaLmJYdS6bcV6XaWW52d6UJpW9gGz995zQ2bXqalf98N6dtns4//cU5LDy1nUt+dym1rsc5lsfpo4MnOJZzOaPZXZYOafWwpHh9H6U2onsybZ3wxLULmNnWx8rbNrK8bzKrrmmnNqvK0S84gg09W5hcm0p1oI9tu7cya/dRDX4kE5MzZJqtVqNnQTvbjyyz+eRE39wqO2pdfPJbv8ruajuTlm5n2hPwyEdPJ7bvzHZjCgMZ6WDYG9CUgLkMHLeL6+5/mBct30D73GnMWlKmnQFqnVDZXuO2z9zPtnQXA2f2w6IjgSVkObcfrdLBVBqoUetoY8pT+ZhYAmoQ1Rqpq51di7pJAWvP7qbWFs6WkQ6CoWa09PZu459+/5e86PwSXSfOZ8G8Nh6q9VLth76o8KFLV7P67hWsHZjMeo7gJYPCmJdxsjNlpAM0t++YQkAT0N5JuT3xy++u5cRT2uhYOJ3Jk4NVA31UBhJRhp98fju9m3oYKA/Q2xbMqp0IUcq2z9s8b+HZTXtMhzP/19BEUUuwaSubTwp6z9rJ0d8ZYN4twQ9//6V0nLiNWx49hq7vTqd/WjD7nqD3eYt46H1Hw5Zt7sIkHXRt3PX9x5g7r5tnZi7iyFeewK55ic6Xd9D+X/pZPWU26zrbePzOjXQ9r4eBk3dBeTYGMtLBlUpB2/ZeYiA7eO/uhVPyvyEGqkSlRufGfrrW7GTxj3fQubGX1GZNSo3wrY9cz7Llk+lfPI03/86RbFmXqC2fRNfMHrY+3MnkV/+EO+8c4Jje81nec0qzuytNDBHcfe1jzJ3fwc4pHZz04uls3lhl16w2ess9rHmqRs+im1mzqp/57Scwv205dHYD4USABvAbSpPFtCnMfBCO+l8lSpUaqRx8/OpP0fm96Rz/T71UO2DG4xV2LgmeuDSYc3sJ5s12tyXpoNvJ9DkdPHNTH/2Ln883vjODRzu3seBt3az643fxn1sv4faVr+MlL5nJin+/hpU//iocAVDGj1bp4IqBKj3HToNaonvNDlJ7majU2HXUNDa8eBYrL+qmNqmdqNYo7+ilbbe7EkrjqX666vq/13Ev13EvC39tEk8+upEXvGAO3/zgaq5/YB0vuaidK/7hdF74K//O2Tes5mUvmcQH3nYP/+N3r232w5AOO+ctPJsNnU/s+XdD5xNsiAeYdHywasUWZs7t5Kdf3sDdKzcz/ZgK086Zwe75TzK/7XiOWzaDG7+xgTu+9yjtHR2GMQ3iMWSaKJWCoMyse7ex8fnTSW0w547tvHfFa9m1ICht28W8XwD3PUo6/QXQX2Lq6n4onBZb0sFQo1brZ1JpLkuW9/PAVx/lhQueJj3dTtvyM7n/c9M5IUpsq/Rx6z0dzDl2GUvPOhG+ADBA8Tgyg49VU79N0nNT7qvyzFmzmfuLLVSnd5EGagBEpUbP/DKzHthFtXMSpb4Kpac38+D7l3Lc53dTbS95OmzpIAgSZaosqa1i0zFrmXblUj7/Rw8x/wSYt7qb037lJO74/ja6z19O19HPcO//ns+Sd6zmypesozJwFbe2v5AKbbwUZ8xI4y2AqR2TKC+qUenewe1ffZrFx3SwcUUbM49ewE+vXU/3UTvp27aLbTcsYtKpT3HqyYvp2bGaTR2rqKUac/uOBuAzX7+Bc87a94xOHuT3wBnItICdx0zNqiXB2g/U6N8wm9mPVKnOmUrb6k1s/o0z6DpjM4v+5yTaN+wiKlVnyEgHQTEoKZXaqO7YAUvK/OqJG5nSXybOuIzvrlzKkbvaaG9vY9rCNhZVF5CeqVH+wiTgQaB/zPch6dkr9dfYcQzMerCT8s6+bHekGqT2Mp3bEwPTOph/01aoJla87Vhm354YmNJuGCMdJImgSpmNpbk8tLLGMbcuYMHbJ7Npd5nXvf40nnl0FWdeOIfOrrdRmbmLE0+tsqK0ms5tk+mZ0kmJRIm0Z8aNpAP3ma/fAJ2QSPRW+9n69E5mbj6RZS+fAdHGiacu4uEH1zB38QBtlWVUuweYeW43u7u66e+Bat9OgkQAGzqfYG7fMfvdh2HM+DCQaQG9M0pUOyC1Bb27O1j47x10Pb2T0q5+Uncns25YDdcnUlcfUUuGMVJD1Fj4/Hnctn4Nd961mbMuPIZ7eo9l6qqptLfvALZSLpco78iPJsozQN+wrRnESOOjf1o7x352Pb3HzKbc0w8RVGZ0UO0s07VxIBtLj5hCubfK3LsGKPfVqLUF4aHXpIMmEZzBSzjxpK186d8e48bHVvKOd59Cb2kTC2fPpLNrKgBt7ZNoA3YznzVzSvQwhQpt1PIDhxrKSONveu/RzFzUxcMP7uDO/k2cc8Eint65mXJnmTQwAJV+ygT0V6hEH9srGxgY6KOWEik/NX0xlDGIGV8GMk2WyiVm37uTo/7lMe7819NZ+PkOSpVE9FWhWoOUoH3vy2QYI42fYkhy5ZUvGBSa9JA2zOBFZx1J75Yd3L97GW03ttG+tRt4Ctidr7cj/7eWX/a1f7uSDkSpmuhfMpOOTbtJ7WWoJtq29pFmdpHywzdFLVHrKBHVRCobxkjj7efct+fvYoBSKwdv/tiJ3Pf1x+hakij1TqOza8Z+2+9kKr10U6VEddBx14ptSxqbekhSPwX2IzfX9s5qKVfor1Q4/dXz2PHwNjazi56+CuVaGwz0QS0/HEatQn/spkIvtVTbE8bUHX9WyTDmIDCQabaUKG/awWPvOZHa0TD5gWfYeN5Cuh/ugXKZVApDGOkgKR7bpX6sl73hSQ8dvRsZ+PEcOqYfx9Yf1pg2Zwu0rycLY+rhy/4hjKSDq9pRIrrb2basmylrB4hKIrXtP1YaxEgH1+AZLZM6p3N96Sae/19vZcW6aRw98w1DbpcFMR2N6qZ02Nt7mus8lDkrC2UAqFVp6xvgKX7JvOWzWL++l+7+OZRL5TyMyQfLlEiphkcrbSxPBdICUinoenIT8699isr86cz58VOk9jaDGKmpKsB22tvXw9ZtzD2ij872PrLdkkYPYephj7NjpPEXCSpT2ql2Qvv2fvpmtUHN9EVqtpu4k5ntA3TuChYf0cX9XQ9zE3dyHfc680VqllRjU/lhuqJMqZKYMaWdXd1Psan9MTZ0Ps6GzidG3Lwe9jg75uBwhkyLSKUgOjsob9oJnf5iIDXCUGdA2lcv0Et7RzG73jeMGXl7SQdL1BJTV1YYmNJO+46qB+2VmqgetpQps5Op3D/zBQzQzgBt+SF7Y5/16qfLljQ+6rsqDVYPWyIF/QO9bK4OUEs1qrUEhV2SNnQ+wTlnLOPtCy/j+rU3NarbwkCmpaRSENWaM2OkJhr6mC/Dz4hxBozUPKVqgpLHiJGaqRisVClRo51+2gH2BDEjbSPp4Dj+rBIb7sj+TiSqKVGtDv+d9sY7HnMWTBMYyLQYwxipsQYHKs8mYBltdoxhjSRpohkuhJF0cA0OU55NuDLU7Jrn2paeHQMZScqNFKAMPgDwgbQlSdLhZrTTVTsrRmqcYoCy52xLube//tw9f3/m6zeMegwZw5iDy0BGksaRQYwkaSIafCpsAxipNRQDl7l9x+xzjJiRwhiDmMYwkJGkQYbaFakYtHgGJUmShmcYI7WGoXZFKgYtnkGp+TzttSQN4i5JkiRJOtSNJWgxjGkuZ8hI0hBGClwMYyRJknQoGClwMYxpPgMZSRqDZ3tQX0mSJKnVFHdjMpBpPgMZSRqBx4uRJEnSoc7jxbQmAxlJGoFBjCRJkg51BjGtyYP6SpIkSZIkNZiBjCRJkiRJUoMZyEiSJEmSJDWYgYwkSZIkSVKDGchIkiRJkiQ1mIGMJEmSJElSgxnISJIkSZIkNZiBjCRJkiRJUoMZyEiSJEmSJDWYgYwkSZIkSVKDGchIkiRJkiQ1mIGMJEmSJElSgxnISJIkSZIkNZiBjCRJkiRJUoMZyEiSJEmSJDWYgYwkSZIkSVKDGchIkiRJkiQ1mIGMJEmSJElSgxnISJIkSZIkNZiBjCRJkiRJUoMZyEiSJEmSJDWYgYwkSZIkSVKDGchIkiRJkiQ1mIGMJEmSJElSgxnISJIkSZIkNZiBjCRJkiRJUoMZyEiSJEmSJDWYgYwkSZIkSVKDGchIkiRJkiQ1mIGMJEmSJElSgxnISJIkSZIkNZiBjCRJkh/aMxsAACAASURBVCRJUoMZyEiSJEmSJDWYgYwkSZIkSVKDGchIkiRJkiQ1mIGMJEmSJElSgxnISJIkSZIkNZiBjCRJkiRJUoMZyEiSJEmSJDWYgYwkSZIkSVKDGchIkiRJkiQ1mIGMJEmSJElSgxnISJIkSZIkNZiBjCRJkiRJUoMZyEiSJEmSJDWYgYwkSZIkSVKDGchIkiRJkiQ1WKSUmt2HfUTEBuCpZvdDTXNUSmluszuh/VmbE5612aKszQnP2mxR1uaEZ222KGtzwmup2my5QEaSJEmSJOlw5y5LkiRJkiRJDWYgI0mSJEmS1GAGMpIkSZIkSQ1mICNJkiRJktRgBjKSJEmSJEkNZiAjSZIkSZLUYAYykiRJkiRJDWYgI0mSJEmS1GAGMpIkSZIkSQ1mIDMBRMSREbEzIsrN7ouk8RURP4uIK5rdD+lQEhFLIyJFRFuz+yKpsRw3pWfPcfPgOaBAJv9Pfv1Si4jdheuX5uscHxFfjYiNEbEtIu6JiHfXw4GI6IiID0bEwxHRExFrIuLaiHjFEPf3s4jYEhGdY+jbBRHxUETsioifRsRRhWUfjoiBQf0/ZgxtduRtri7cNi8ivhQRa/PHd2NEvHiY7T+bv5GXDbFsVkRsiIgbRulDZ0T834jYHhHrI+Ldo/U7pbQypTQlpVQdbV0dGqy9A6+9iLg6IvoH9WXY0PK51J4mHmvT2sz7/5Fm9kH7szatTbUma9PanOjj5gEFMvl/8qeklKYAK4GLC7d9ISKOBX4BrAJOSSlNB94AvACYmjfzNeAS4DJgJnA08Ang14r3FRFLgfOABPz6SP2KiDnAN4APALOA24AvD1rty8X+p5SeGMND/nPgmUG3TQF+CZyZ39e/AddExJRBfToXOHaEtj8GPDiGPnwYOA44CvgV4C8i4pVj2E6HEWsPGJ/a+/tBfRkptPwwB7n2wl8dDnnWJnAY1qYOfdYmcBjWpuPmoc/aBA7D2tSzkFIalwuwArhw0G2fB64ZYZsLgd3A4jG0/0HgRuB/AN8bZd0rgZsK1yfn93NCfv3DwOef5eM7miww+VVg9SjrbgfOLFxvA+4ETiX7AFg2aP2zgJuBtwI3jNL2GuAVhet/A/zHKNssze+3Lb/+M+AjwE3ATuC7wGzgC3nffwksLWz/CbIPwe3A7cB5hWXdZB8aW/Ln5y+Kzw+wEPg6sAF4EvijEfr5M+C/AbcC24BvA7MGPYbLyT6sNwLvG2s/DueLtffcag+4GvjIs+jHs669fL3LgKeATWSD+p7XK38+vpa/XtuBK4AXkX0ebAXWAf8MdBTaeznwUF4j/wz8HLiisPx38udrB/AAcEZ++18Cjxduf21hm7fkr/E/5vf7BHB2fvsqsi8Ol4/yHnxP3u4W4LNAV77sfGA18Kd5O+uAtxa2nU32GVT/7PkIo3wOHioXa7N1a5PRx5RSoWY2AV8hH4/y5V8F1ud1eB1wUuF5HgD6ycfXwnvhz4F7gB7gM8B84Nq8Jn8EzByt/cLz8yng/+Xb/hw4apjHWa+/9+aPcQVw6aC2/gW4Jm/rF8CxheWvAB7O+/GvDPq8OVQv1mbr1ma+nuOm46a12WK1ieNmsa1xHTcP9jFkLiT70Bxp+S9SSqtHWKfuMrLA4AvARRExf4R1TwLurl9JKfWQvTlOKqxzcURsjoj7I+J3x3D//0T2wuweaaWIOB3oAB4r3Pwu4LqU0j1DrF8me1H/gOxNPlLbM8kCjrsLN9/Nvo9rrN4I/DawiCxpvZlsMJhF9kHxocK6vwROz5d9EfhqRHTlyz5EVqDHkA14by70t0Q2YNyd388FwJ9ExEUj9Osy4G1kj7MC/K9By88FludtfTAinjdaPyYoay8zbO3lfi/vy+0R8foR2n5OtRcRJ5J9GF8KHAFMJ6uFokvIXqsZZM9xNe/3HLKw9gLg9/L25pAFnO/Plz8OnFO4vzeQfUG4DJhG9uvPpnzx42S/Ck0H/gr4fEQcUejHi8kGvdlkdf4fwAuBZWT19M+Df6kZ5FLgIrLPk+PzPtYtKDz2twP/kj+nkH3+9eTrXJ5fDmfWZqaptVkw3JjyR8BrgJfl7W8he6/WXUv26+I84A6y14CU0lX53/VfKi8ubPN6svHpeODivI33ktVyKb/PEdsvuJTsC/Qc4K4hlhctyNdbRFZfV0XE8sLyN5F9Jswke43+FvZ83nyN7D+Ns8m+YJ49wv0c6qzNjOOm42arsTYzjpuH67j5bJPLEVKzFeyfaA4Arxxhm09TSOPI/sO/lSxR6i3cfm7e1pz8+kPAu0Zo9zPA3w267UbgLfnfJ5K9Ucr5k7QOeNMI7b0W+H4xNRtmvWnAvcB7CrctyV+o6fn1wYnmu4BP5n+/hRES7rytRJ6g57e9HFgxxkSzOEOmmGj+A3Bt4frFwF0jtLcFOC3/+wngosKyK+rPD9lAtXLQtu8BPjtMuz8rvm7569Sfv071x7C4sPxW4I2j9eNwv1h7z7n2ziD7sGwDXkWWcp8zTPvPtfY+CHypcH1S/p4u/tJ33Sht/Anwzfzvy4BbCsuCLMW/Ir/+A+CPx/i+uQu4JP/7LcCjhWWn5I93fuG2TcDpI7wH31m4/irg8cLrtpv88ye/7RngJfn7YABYXlh2uP/SZ222Rm0uZeQx5UHggsKyI/Lnu22ItmbkbdUfz9UM+qWS/X9h+zr52J9f/0PgW8P0daj2i++RKWT/IV0yxLbnk/24Mblw21eADxTa+nRh2auAh/K/LwNuLiwLsl/+D9cZMtZma9Sm46bjprXZmrW5FMfNelvjOm4e7Bkym8hejDEtTyltTinNINt/rnigpcuBH6aUNubXv5jfRuw9g9DOiNiZL99J9mYumkb25iSl9EBKaW1KqZpSuolsl5zfyNt7b6G9T0XEZODvyV70YUVEN9lskFtSSv+tsOh/An+dUto2xDYLyZK99w3T5qcKfXlv/rjqj2W/x/UsPV34e/cQ1/ck+hHxpxHxYGQHmdpKltjPyRcvJHuj1RX/PgpYGBFb6xeyVHOkNLq4/VNAe+G+IJuKVrer0M+R+jERWXsj1F7elztSSptSSpWU0n+SJeWvy9scr9rb532ZUtrF3l/e6vZ5r0Z24LrvRXaQte3ARxmm3lL2aV/cfgnZrzf7iYjLIuKuQi2ezL61NfgzgJTSsJ8LQxhcuwsL1zellCqF6/XanUv25WEi1a612Rq1WTfcmHIU8M1CvTxI9uVtfkSUI+LvIuLxvEZX5NsU62koYxp3x9h+8XNgJ7CZfWuuaEvKftmtG1yfYxpX88+bsfwCfaiyNlujNh03M46be1mbrVGbdY6b4zxuHuxA5kdkU42G82PghRGxeLgV8jfmbwIvyz9o15PNKjktIk5Le88gVD8YFMD9wGmFNiaTTQe8f5i7SWQJFimljxbaeyfZ1KelwPX5fX8DOCLvy9K8/U7gW2T7471jUNsXAB8v9B3g5oj4LbJ9Xo8AHsiXfQJ4Ub5uOaX0zkJfPppS2kKWvp5WaP+0ER7XAYuI84D/j+w1mJl/wG0jf77y/hRfvyWFv1cBT6aUZhQuU1NKrxrhLovbH0mWrG4cZt2ikfoxEVl7I9feaH0Zr9rb532ZP6ezh7jfok+S/WpzXEppGlmIWay3Pe/tiAj2r7n9DvYW2VkB/g/ZrpGz8zq+r9DueBhcu2vHsM0Gsl8hJlLtWputUZujWQX86qDxqyultAb4LbJdJi4k+4Fiab5NvZ4G1/SzNVr7sO/nwBSyX4SHq7mZ+etdN9b6HPz5Fexbq4cba7M1atNxc2SOm/uzNkfui+NmpmXHzYMdyHwIODsiPh4RC/KOLYuIz0fEjJTSD4GfAt+KiBdHdhqwdrIpeXWvIUvXTiQ7jsnpwPOA68mmBQ3lm8DJEfH6yI518kHgnpTSQ3kfLomImZF5EdkslW8P09Z9ZC9g/b6vIEvnTgdW5f39GllKd1lKqTZo++PJ3uT17SHbJeibZPu6LS0s+yDZwZpOT8MfGftzwPvz/p9AdiCyq4dZdzxMJfvg3wC0RcQH2TdR/Qrwnrw/i8gGrrpbge0R8f9FRHeeXp4cES8c4f7eHBEnRsQk4K+Br43wXBSN1I+JyNobufaIiN+IiCkRUYrstIhvBr4zTF/gudXe18j2Lz47IjrI9jcd7cvcVLIDue3M76e4T/I1wEkR8brIzizxR2T7udZ9GviziDgzf46X5V8qJ5MNdhvyx/5Wsl/6xtPvR8TiiJhF9mV48JkI9pPX9jeAD0fEpPzxDvfeOlxYm61Rm6P5FPC3ef0QEXMj4pJ82VSgj+xX2Ulkv8YXPU12PLPnarT2AV4VEefmnyt/Q3b8hJF+Jf+r/L10HvBqsoMfjuYa4JSIeE3+efP77Pt5c7ixNlujNh03R+C4aW3iuDmUQ3vcTAdxn7/89uX5A9hENrPibrJ9O8v58k6y/UEfJZvys5osqLgoX/594B+GaPc3yaYL7bdfWr78QrK0fDfZsUmWFpZ9Ke/PznydYc/8M0S757PvWYReRvaBvStvr345b5jt99nnb9CytzD6WZY6gf9LNvA8Dbx7DH1eyv7HkCkeXf4jwNWDnrvH8r/LZPtQbidL/f6i+FqTDVj/Trav5oNkByR7vNDWwvz5Xk927JlbCtteCtxfWPdn7D3L0nayKXtzhnoMgx/HaP04nC9Ye8+p9sgG4W35e+1u8n1gx7P28u3eQnY0+vrZItbU+8gQR+gHXpo/NzvzPv41hc8F4JXAIwx/toh3kh1EbCfZF4Dn57f/Ldn0zI1kZxfYsx2DPnvIDkiYBvVrNXBu/vd72fe4UyvYe7aIrWRnPJs01Os2+D1LNv36GvaeLeJjwI+bXVfW5uFdm4w+ppSAd+e1tINsl4aP5sumkH3p3kE2jfmy4mMg+yX0rrwWvjXUe4HsrCEfLly/AvjRGNu/mr1ni9hJdjaJowtt3U++3z17zxbxPrLaXwn8dmHdqynstz/Ea1n8vPlXshMA/PZoz2+rXwa/HtZm69Rmvt1bcNx03LQ2W6o2cdyk0Na4jpuRbyiNi8iOMP7GlNLLnsO2PyMbZD/dzH5IB0tkUyS3kk2rfrLZ/RkvEbGCbED+0Ti09TFgQUrp8gPumHQYioiryb78vX8M655PNq4e8K5GkZ05cTXZl9afHmh70lg4bo6pLcdNaQStPm4e7F2WdJiLiCMi4px8itxy4E/Jp89NxH5Ig0XExfm04snAfyc7cv6K5vaqdUTECRFxamHK79uxdqWWEBEXRcSMyI5tUD8uxy1N7pYOc46bI3PclFrXcxk3DWQOExFxaRSODl64HLQD/uY6gP9NNkXsJ2TTxf71IN9nK/dDE8wYau8SsgOBrSWbkvnG5NTEoqlk+8P3kB0L6h8Yfh9sacyaOC4eTs4im3a+kex4Ba9JKe1ubpd0qHPcPGCOmzooHDfHxbMeN91lSZIkSZIkqcGcISNJkiRJktRgbc3uwGBz5sxJS5cubXY31CS33377xpTS3Gb3Q/vrKHen7vK00VfUYWn7wDPWZouaMmVGmj17YbO7oSZZufJBa7NFdbRPTl1dM5rdDTXJjp1rrc0WNXPO9LRo6fxmd0NNcv/tj7ZUbbZcILN06VJuu+22ZndDTRIRTzW7Dxpad3kaZy94U7O7oSb5/qpPWJstavbshbzvfZ9rdjfUJO94xwutzRbV1TWDFz7/95rdDTXJT65/v7XZohYtnc83bvNQkxPV8nh5S9WmuyxJkiRJkiQ1mIGMJEmSJElSgxnISJIkSZIkNZiBjCRJkiRJUoMZyEiSJEmSJDWYgYwkSZIkSVKDGchIkiRJkiQ1mIGMJEmSJElSgxnISJIkSZIkNZiBjCRJkiRJUoMZyEiSJEmSJDWYgYwkSZIkSVKDGchIkiRJkiQ1mIGMJEmSJElSgxnISJIkSZIkNZiBjCRJkiRJUoMZyEiSJEmSJDWYgYwkSZIkSVKDGchIkiRJkiQ1mIGMJEmSJElSgxnISJIkSZIkNZiBjCRJkiRJUoMZyEiSJEmSJDWYgYwkSZIkSVKDGchIkiRJkiQ1mIGMJEmSJElSgxnISJIkSZIkNZiBjCRJkiRJUoMZyEiSJEmSJDWYgYwkSZIkSVKDGchIkiRJkiQ1mIGMJEmSJElSgxnISJKkQ96VV76AK698QbO7IUmSNGYGMpIk6ZBWDGIMZiRJ0qGirdkdkCRJOhBXXXVbs7sgSZL0rDlDRpIkSZIkqcEMZCRJkiRJkhrMQEaSJEmSJKnBDGQkSdIhZ6wH7vUAv5Ik7et4LtznouYxkJEkSYc1QxlJkjJDBTCGMs3jWZYkSZIkSZoAHuFHze6CCpwhI0mSWt6BznJxlowkSWo1BjKSJKmljS1MKeHXGkmShlbcLamNCp300kE/QRpyHTWG31wk6dkol7KLpINuyCCmlv9bhVoFqkBlYCpUF1BlETCVseyR7YwZqQEiKPdVIaLZPZEmrsK4uaz/QqpAaaCfqdUddLGDyFcwjGkO/1chSc9GX392kdQU1dTP7T/cwmP3buCxezez4cFnKLXDdz9zO/fdupVqtYZfb6TWEJUaa8+bSrm30uyuSBNWNfXtGTdvuOYpSj8+ktRe49ufuZm7bn2aSqViGNNEHtRXksYiJahW2fKyowGYedPq7DZJDVUud3DmKzpYdvpcjn/+rPzWNi6+8lygG1gLDDSvg5L2KgWLv/c0taldQLnZvZEmpHK5kzNf0cky5rLs9Pqtx3L0la9pZreUM5CRpLGIgLY2Zt6wcu91SS1iG9BDNjOmn73zsyU1UwoYmD8tv+KPGFLrMCBtFQYykiSpJV111W1jXLNGFsQcjLYlHTDDGEkakjtZS9KzEeHsGKnBDE+kQ5hhjNQSHuFH47KOxpczZCRJUsurhzJXXvkCrrrqNq666rYxnSnJMEeSpIyBS+sxkJEkSS3P01RLkqTDjYGMJElqecWZLvVwZiyzX+ozaiRJEvuc4toZM83nMWQkSVJLO5DZMYYxkiRlimHMUNfVeAYykiSpJY3Hbkru6iRJ0vCO50KDmSZylyVJktSS6gfuLf5bv71utMDFGTKSpInMXZRam4GMJElqecMFK6MFLsXAxnBGkjRRjHXWi4FNcxnISJKkljJyiFICOoAyUAVq+W01oJL/K6nZIkGKZvdCUlEH/SysrWWg1M4WZrKYX99n+fFcaCjTYB5DpoVU+nez7r41fOUff8K2FZuoDOxudpck1aUE1Wr2r6Qm6gLmAQuB+cARwJL838n41UZqDZXucvZHmMpIraKDPjpurDH5gT6msa3Z3RF+a2kJlYHd9FZ6+Mm1K1m3qULXlHnc9pNt/Ojq9dz4oxXN7p40MbWVqc2YSvWIWaSBAdKOnVTWrSft2k3q629276TDymjHgdm7vES1Oo/KMdOpnt0Fz58L58+FN0+CV8+FWA5MZywTgD3YrzT+IkH7ph7an9nBTz73GTpWbKDWUSK1+V8OqVEG76o0UNlFf38PlcouFvJatj0IrIReuprTQe3DXZZaQLWWWPPkdsqPV7i/fw3TpnTTs3srG1dXOXnJIrZu2Un31HY62zqb3VVpYkiJ6pr1bPvOEnqvmUXn8ZPZdErwqTdcxZXf/R2O/fJu2ldtbHYvpQmoDWZPZf5LVtG1YQU7Ont5fnqC2Z/bRc+cGj/4r++B/1gEPAXsaHZnpYmlHLSt3QbtbdBW5qKFp1M+aQqdq7ZSm9xFdXJ7s3soTVixY4BHH6+ytW8Vc5dfwJaeDjZ9p8q8X99/XXdbaizj6hZw752rWHv/DpYs6mTmtLm0t3cyafF8lpw5lYdvWsMza7fx8C3PMOAuTFLDRHsbG+6fy8Jvr6RUgbl3Ja74+Vsp9QW1zrJTsKUG2uc4Mu1Qq+1gUmUDkzZvYUrnADvWVak+WWLutHVkuzS1Db2tpIOrVNqza2/p5BOgVoOy/92QGq04SyaATZV+dvXvZtOqLmL6ZJ6p9VMplZvXQe3hDJkWcOZpx3DPllVs3NhN5+xEdxpgygm9HPu8JfQ93cXd162mc2biP//Xk/zaHx9DW5vTy6SDLTra6dxcYvNVncz8083UJnWw8dSpVKbW2Lm4g87Hm91DaSJq4+m7ttPTt4KLTt/AtlV99Gys8cAt65ncPo2j3nU/G45cCCtnAduoH+C3HsoMPlhw8VTaksZJBKlUojq9i7aNO6FcIgaqgDNkpGZ45Avrue6O7bzuD5bR1ruDNSsq/ODbDzF7ygJOfcUMujum7reNs2Qax0Cmyfr6erj1e5spLa7R1tXProe3UZsymZPK3XSXykya38u2LRXSlg4u+J0j8Dd5qTGq27Yz7cka//aOz/Gmc/+M7cugMr1C5/p2OrdWSP39REeHB/mVDlAxFKkHJsWQZO/yNqCL9nPaeeWc1dz8qZUsmjmbgdkV5h49j7Zpk1i++3FuW/pyWDkTePJZ37+k5y5F7B0TS1De1pvNjkmJGKhAOaDqmCkdTPUgpThDpvOobs6a0sa//dPtnHzeUvr6+3nFq49nwfwZtG8rw9wmdljustRspRo8vvJxpnZNYuUv1rHsmHls6d/F0yUgssHtpBNgzil9TOnqouzsGOngSgna23jkky9k0ynBq7/4Z8y/fiPTHoMZ97Rz/PlP8PSLytkZlyQ1UAmYwvbSQ7BtI8+/YDrl+YlFc9rZ0l/lpru30tHTQ3VSX7M7Kk1IHRt6oK2cBTCVGuGZCaWWcNedj7G2bzuvfdMRdFQSpzyvi+27Brjmu2uoTO2hMtDT7C5OaAYyTdbePZlXv/5E5s1q56I3LWPesXD04sksWz4TItHWMYnlLz+Wl52/jLaO7mZ3V5oYIpizeCvHfXodA/MGWPG6uex6+U6qnXDfk4uoTE4QfnxKjVdhUmU5q6YcxVPzJ7O21MeatkRs3cHZ8yrcua1EeWMnUBlzi86OkcZHKhdmyKRE6myHWn3GjHO8pWY5ceaxlMpdPLJiEvf9ZAf33lbj7p88zfxpfdx9y3ra2ic3u4sTmrsstYAZi6fz5L07qB1R4qb/7OXXr1jocWKkZomAgQqzPzCFh393Nss+18vmExKTvjSJdWclYms7i39cJSZ1QbXW7N5KE0gF2Ma6H8D3/8t5zJw3nWeWP82mNf3MfOkNPG/RFDqOeBPlLwOspX78GEkNUioB1T0hzPbjpjLjtvWkrg5Sh//lkJrlwf4tTJ68mYUdx7PhzD7o/yRdp/Xw9Ko38ZvnHNvs7k14fjq2gLa2Tso9Pax9aDsvPX8SJWd3Sk1X3rCV5Z/YCimx4OEqtLcz7Y4SafNWYuZ0wxhpnIx9hkoN6OGM55Vg3VRYF8zun0lbKVh53xtYeX9i2cZtUF4B9I7pPp0dI42fypQOmN4JZLvcz/jlOtb+2mLm37qDWkfZ48dIDTDUgXhfd+VJe/5u6/8FJzy8iFX39LD+nJuJOL2R3dMQDGRaxDHnzuLI/m53S5JaTQS0t2fTsAcqWRhTqXraa+kgqJ/5aGQ9QB9Qoq1cgVTjyDNKEO2Uy0EWxhiYSk2Rhy5BoveYucy7fSfVrvy/Gx5PRmq6jnKJ/ue1seCEKXSU5tBWnjTkep5hqXEMZFqIYYzUoupfIiOymTGGMdJBM9IZlzI1oB+Acrl42/7HjRnqDErOipEaozRQo9ZWMoiRmmDwmZb2KHexhmWjbqvG8aiUkiSppY0+a2ZohjFSExnESE01XLCSiD2X4jqP8CPDmCZwhowkSWo5xZkyg4OU5xLQGMZIkiYaA5bWZyAjSZJa1ngEKYYxkiSxZzemwTNj1DwGMpIk6bBkECNJ0l6GL63HQEaSJLW84m5KBi2SJOlw4EF9JUlSy7vqqtsMYiRJ0mHFQEaSJB0yDGUkSdLhwl2WJEnSIWekMy0Z2kiSpEOBgYwkSTrkGLpIkqRDnbssSZIkSZIkNZiBjCRJkiRJUoMZyEiSJEmSJDWYgYwkSZIkSVKDGchIkiRJkiQ1mIGMJEmSJElSgxnISJIkSZIkNZiBjCRJkiRJUoMZyEiSJEmSJDWYgYwk6f9v787D5Ljqe42/p7unZ9c6o92WLMsL3rGNAa9sMcTBmECSCwEMSbgON7nhJuRCwhIChCUbZIEErtmcQEICZnGIwYADxmAw2Ja3GNtYtmVbkiVLskaj2ae7z/2jqqXSaDZt1SPN+3meeWa6q7r69PLrqvn2OackSZIk5cxARpIkSZIkKWcGMpIkSZIkSTkzkJEkSZIkScqZgYwkSZIkSVLODGQkSZIkSZJyZiAjSZIkSZKUMwMZSZIkSZKknBnISJIkSZIk5cxARpIkSZIkKWcGMpIkSZIkSTkzkJEkSZIkScqZgYwkSZIkSVLODGQkSZIkSZJyZiAjSZIkSZKUMwMZSZIkSZKknBnISJIkSZIk5cxARpIkSZIkKWcGMpIkSZIkSTkzkJEkSZIkScqZgYwkSZIkSVLODGQkSZIkSZJyZiAjSZIkSZKUMwMZSZIkSZKknBnISJIkSZIk5cxARpIkSZIkKWcGMpIkSZIkSTkzkJEkSZIkScqZgYwkSZIkSVLODGQkSZIkSZJyZiAjSZIkSZKUMwMZSZIkSZKknBnISJIkSZIk5cxARpIkSZIkKWcGMpIkSZIkSTkzkJEkSZIkScqZgYwkSZIkSVLODGQkSZIkSZJyZiAjSZIkSZKUsxBjbHQb9hJC2Ao81uh2qGFWxhi7G90I7cvanPWszRnK2pz1rM0Zytqc9azNGcranPVmVG3OuEBGkiRJkiTpaOeQJUmSJEmSpJwZyEiSJEmSJOXMQEaSJEmSJClnBjKSJEmSJEk5M5CRJEmSJEnKmYGMJEmSJElSzgxkJEmSJEmScmYgI0mSJEmSlDMDmaNACGFVCCGGEEqNbouk6QshHBtC6AshFBvdFkmHVgjhphDCGxvdDulI4jGtNHvN1v3mNyt1cAAAIABJREFUpIFM+o9C/acWQhjMXH5Nus6JIYQvhRC2hRB2hhDuCSG8pf4PRgihHEJ4dwjhwRBCfwhhYwjhmyGES8e5v5tCCDtCCM1TNTyE8MIQwgMhhIEQwvdCCCszy94TQhgd0/7V09hmOd3mhsx1i0IIXwghbEof3y0hhGdPcPvPpjuRNZnrrgkhjIxpy4T/fIUQmkMInwkh9IYQNocQ3jJVuw+ntP3vb2QbtP+s3SOjdmOMj8cYO2KM1anW1ZHB2jsktbc8hHBdCOHpEMKGEMKbpmjDjNpvamayNq3N4DHtjGRtWpuz3aSBTPqPQkeMsQN4HLg8c92/hBCOB34CPAGcHmOcC/wqcC7QmW7mWuAK4EpgPnAc8HfAL2XvK4SwCrgIiMDLJmtXCKEL+ArwJ8AC4Hbg38es9u/Z9scYH5lsm6m3Ak+Nua4DuA04J72vfwKuDyF0jGnThcDxE2z3L8e0ZbJ/vt4DnACsBJ4PvC2E8JJptF3azdoFrF01gLUHHHztfR54FFhM8pg/GEJ4/iRteA+HufaC39Yf8axN4CisTR35rE3gKKxN95v7IcY4rR9gPfCiMdd9Hrh+ktu8CBgEVkxj++8GbgE+AvznFOteBfwoc7k9vZ+T08vvAT4/3ceW3uY44H7gF4ENU6zbC5yTuVwC7gTOICnwNZll1wDv3492bAQuzVz+M+DfprjNqvR+X0/yQbYNeGdmeQH4Y+BhYDvwRWBBZvmXgM3ATuBm4NTM8zwKjAB9wNcz74W3AvcA/cCnST4AvgnsAm4E5k+1/czz8wngO+ltvw+snOBxPg/YALwjfYzrgdeM2dY/ANen2/oJcHxm+aXAg2k7/jG9rzfuz/vkSPyxdo+I2i2ll28C3g/8qF5zwELgX9K23wasytz+70gOUHqBO4CLMstaSXboO9Ln523Z5wdYBnwZ2EqyE3/zJO28CfgQ8NO0fq4j/Qxh6s+fSdtxNP9Ye/tfeyQHpRHozqx7NfC5Sba937WXrncl8BjJfvFPsq9X+nxcm75evcAbgfOAHwM9wJPAx4ByZnu/ADyQ1sjHGLOPAf5n+nztAn4GnJ1eX98/16//5cxt3pC+xn+T3u8jwPnp9U+QHNS/for34NvT7e4APgu0pMueR7JP/cN0O08Cv5G57UKSz6D6Z8/7gR82uq4OxQ/W5oytTTymzW5r1h3TYm3O2NpM13O/eRj2mwc7h8yL0id+suU/iTFumGSduitJ/un4F+DFIYTFk6x7KnB3/UKMsZ/kRTk1s87labet+0II/2sa9/9Rkg/FwclWCiGcBZSBdZmr/wC4OcZ4zwQ3+520LXeEEF45ybbnk/yTdHfm6rvZ+3FN5kLgJOCFwLtDCM9Ir38z8HLgknT7O0g+5Ou+SZKSLgLWkrwGxBivTv+u9xK4PHObV5IU0YnA5ek23gF0kews3zzV9jNeQ/JB0AXcNc7yrCXpestJdtZXhxBOyix/NfBeknR8HfAB2J1yX0tSYAtJdmLnT3I/RztrNzFTajfrVcDrSN7jx5PsyD5L8o3J/cCfZta9DTgrXfavwJdCCC3psj8lObBdTVKrr820t0Cyw7g7vZ8XAr8fQnjxJO26EvhNksdZAf5+zPKJPn8mbMcsZe0lJqq9MOZ3/e/TJtj2AdVeCOEUkn9iXgMsBeaS1ELWFSSv1TyS57iatrsLeC7Je/130u11kQSc70qXPwxckLm/XyU5WL0SmEPyzez2dPHDJN/YziXZf30+hLA0045nk/yzuJCkzv8NeBawhqSePjb2W9QxXgO8mOTz5MS0jXVLMo/9t4B/SJ9TSI4T+tN1Xp/+HM2szURDazPDY1qPaeuszYT7zaN1v3mQieUo8JJJbvMpMmkbyT8NPSQp2FDm+gvTbXWllx8A/mCS7X4a+PMx190CvCH9+xSSN1qR5APqSeDVk2zvl4EbssnXBOvNAe4F3p657hiSYpmbXh77LfvZJG+GEnAZSZJ3wQTbPya9fcuY5HD9FK/NqvR2KzLX/RR4Vfr3/cALM8uWps93aZxtzUu3VX881zCmlwD7pvhfBj6eufx7wNcmaOt428++RzpIiveYcW77PJJ/BNsz130R+JPMtj6VWXYZ8EDck+j+OLMskKSkR/y3CVP9YO3CzK/dbA+Z7DeBHwa+mbl8OXDXJNvbAZyZ/v0I8OLMsjfWnx+SHdXjY277duCzE2z3puzrlr5OI+nrVH8ME33+TNiOo/3H2jvg2vshyUFrS1qHTwMPTrD9A629dwNfyFxuS9/T2W/6bp5iG78PfDX9+0rg1syyQPIt2hvTy98C/s803zd3AVekf78BeCiz7PT08S7OXLcdOGuS9+CbMpcvAx7OvG6DZI4FSL7xe076PhgFTsosO9p7yFibM6M2V+ExbX1bs+6YFmsTZm5tut88TPvNg+0hs53kg3Bay2OMT8cY55GMj8tOpPR64Nsxxm3p5X9Nr8uehaQvhNCXLu8jebNmzSH5h4kY489ijJtijNUY449IuvX/Srq9d2S294kQQjvwlyQfuBMKIbSSfKN8a4zxQ5lFfwu8L8a4c7zbxRjXxhi3xxgrMcZvkKSFr0i3+YlMW96RPq76Y9nncU3D5szfAyQ7AkjGB341hNATQugh2ZlVgcUhhGII4c9DCA+HEHpJ3oSQJJWT2ZL5e3Ccyx0A09z+E/U/Yox9JB8iyya43x0xSajrHhuz7kTPwbIx9xNJin62snZnVu1mTau20nb8YQjh/pBMANdDktjXa2uv9/yYv1cCy+qfCelt30HSTXsi2ds/BjSxdx1Pq/bG/D0bWXtT1B7JN1PHkbxXPk5SexvSbR6q2hu7TxhgzzdvdXu9V0MyqeR/hmQCxF7gg0xQb+k+Jnv7Y0i+0dtHCOHKEMJdmVo8jb1ra+xnADHGCT8XxjG2drP7zO0xxkrmcr12u0nC6NlUu9bmzKjNOo9pPaatszZnRm2630wc8v3mwQYyN5J085vIfwHPCiGsmGiF9I33a8Al6Yu1maRr05khhDPjnrOQ1Cd7ArgPODOzjXaSLkX3TXA3kbQbV4zxg5ntvYmk2+Eq4AfpfX8FWJq2ZVW6/WbgayTj7X57zLZfCPxVpu0APw4h/Po02vKmTFs+GGPcQZKunplZ/8xJHtd0PQH8YoxxXuanJca4Efh1ku5lLyL5Z25Vept6t7d4kPc91fYhKbjkyqT72AJg0wTbm5++3nXHTrJu1pPA7vdhCCFkL89C1u6RUbsTCiFcBPwRyWswPz342Mme2trrPU+mzkg+Ex4d85nQGWO8bJK7zN7+WJJvAbZNsG7WZO2Yjay9KWovxvhYjPGlMcbuGOOzSXqq/TRddqhqb+w+oTW9n7HPQdbHSb5RPSHGOIckxMzWW3ZfFti35vaZiDEkZ+z4JPC/gYVpHf83e+8jD9bY2p3OPnMrybf3s6l2rc2ZUZtT8Zh29h3TWpszozbdb07ugPebBxvI/Clwfgjhr0IISwBCCGtCCJ8PIcyLMX4b+B7wtRDCs0Nymq8mkm49dS8nSbZPIZkL4SzgGcAPSLoyjeerwGkhhFeGZL6EdwP3xBgfSNtwRQhhfkicRzL287oJtvXfJE9W/b7fSJKqnQU8kbb3WpIk7coYY23M7U8keRPXbw/JsIKvpm35lRBCRwihEJJTr70W+I8J2gLwz8C70vafTDKZ0TWTrD8dnwA+kL6BCSF0hxCuSJd1AsMkCWcbSXKZtYVk7ocDNdX2AS4LIVwYQiiTjLv9SYxxskTxvel76SLgpSQTrE3leuD0EMLLQzLr9++SjO+brazdI6N2J9NJ8sG/FSiFEN7N3t92fBF4e9qe5SQ7rrqfAr0hhD8KIbSG5Fu/00IIz5rk/l4bQjglhNAGvA+4Nk7vdN2TtWM2svamrr1nhBA608f+WpLJKz8yQVvgwGrvWpKx/+en+573MvXBXCfJRH196f1k5wu4Hjg1hPCKdB/zZvbex3wK+L8hhHPS53hNuk9uJzmA3Zo+9t9ggnH/B+F3QwgrQggLSA6Gx54lZB9pbX8FeE8IoS19vBO9t44W1ubMqM2peEw7+45prc2ZUZvuNydxUPvNeBBj+tLrTyL58NhO8u3s3STjw4rp8maSMWUPkXTp2UAyIdaL0+U3AB8eZ7u/RtJVb58xoenyF5EkboMk8xusyiz7QtqevnSdCc8eMs52n8feZyK5hORFH0i3V/+5aILbjx3T94P0eelNn5tXTXH/zcBn0vW3AG+ZRptXkZmHIr3uJvaMwSsAbyGZ9GsXSfevD6bLOkg+PHaRdMm6MvsYSBLdu0jGYn5tvPcCyWza78lcfiNw4zS3fw17ZqTvI5mx/rjMtu4jHdvLnpmt30nyzfzjwOsy615DZmzwOK/lS4Cfs2dG+h9nb3+0/ox9vazdmVu7ZOo2vfx+4Joxz9269O8iyfjmXpJvGd6Wfa1JdlifI6nd+0kmJHs4s61l6fO9mWTumVszt30NcF9m3ZvYc5alXpLutF3jPYaxj2OqdhzNP1h7B1p7v09yoNVPMi7+3ENde+nt3kCyH6mfLWJjvY2Mc/YM4OL0uekj+Xx4H5mx4ey9jxnvbBFvItkP95EcnD8zvf4DJMMatpEcQO++XdrG7H2sIe3ZnbluA3Bh+vc72HveqfXsOVtED8kZz9rGe93GvmdJul9fz56zRfwF8F+Nritr8+iuTTymJbOtWXdMO/b1sDZnTm2mt3sD7jcP+X4zpDeWGiKEcA3JG/td01j3eSSFftDdMkNylpkNJDvG7x3s9qSZLiSz/78qxnjJAdz2JpLa+1Qj2yEdLiEZWtBD0q360Ua351AJIawnOUi98RBs6y+AJTHG1x90w6SjkMe0mk3cb05rW9Pabx7skCXpiBFCeHEIYV5IxmjWxzDe2uBmSYdFCGFpCOGCkAy5Ogn4Q9KurbOxHdJYIYTL027F7cBfk5zVYn1jWzVzhBBODiGckemO/1tYu9KM4DGtGsH95uQOdL9pIHOECCG8JmRm/878HLZJQ49CzyXp2rqNZNzly2OMg41tko52DazdMvD/SLpWf5ekm/U/Hub7nMnt0Cwzjdq7gmSivk0kQxleFe02nNVJMh6+n2QuqA8z8fwI0rR5THtIeEyrQ8795kE7oP2mQ5YkSZIkSZJyZg8ZSZIkSZKknJUa3YCxOubOiQsWdze6GWqQJx56ZFuM0TfADNTV1RVXrVrV6GaoQe644w5rc4YqF1tja2luo5uhBukd2WJtzlAdHfPiwoXLGt0MNcjjj99vbc5QTeX22NI6v9HNUIP09W6cUbU54wKZBYu7eetHP9ToZqhB3vyS//FYo9ug8a1atYrbb7+90c1Qg4QQrM0ZqrU0l/NXvLbRzVCD3PDIh63NGWrhwmW8853/3OhmqEF++7efZW3OUC2t8zn7/N9rdDPUIDff8MczqjYdsiRJkiRJkpQzAxlJkiRJkqScGchIkiRJkiTlzEBGkiRJkiQpZwYykiRJkiRJOTOQkSRJkiRJypmBjCRJkiRJUs4MZCRJkiRJknJmICNJkiRJkpQzAxlJkiRJkqScGchIkiRJkiTlzEBGkiRJkiQpZwYykiRJkiRJOTOQkSRJkiRJypmBjCRJkiRJUs4MZCRJkiRJknJmICNJkiRJkpQzAxlJkiRJkqScGchIkiRJkiTlzEBGkiRJkiQpZwYykiRJkiRJOTOQkSRJkiRJypmBjCRJkiRJUs4MZCRJkiRJknJmICNJkiRJkpQzAxlJkiRJkqScGchIkiRJkiTlzEBGkiRJkiQpZwYykiRJkiRJOTOQkSRJkiRJypmBjCRJkiRJUs4MZCRJkiRJknJmIDNDXXD2Gi44e02jmyFJkiRJkg4DA5kZKBvEGMxIkiRJknT0KTW6AdrXLWvXNboJkiRJkiTpMLKHjCRJkiRJUs4MZCRJkiRJknJmICNJkiRJkpQzA5kZIjtxb1vfsr1+JlpPkiRJkiQdmQxkZpixAcx41xnKSJIkSZJ0ZPMsSzPMQMemRjdBkiRJkiQdZvaQaZCD7eViLxlJkiRJko5cBjINMF6Ycnb32bv/LoRAMRQphuJe64w3nEmSJEmSJB15DGRyNG6vlpj+rkJrzzJqADRRbmqj0NxCKBSBMGUYY48ZSZIkSZKOHAYyDVaLFR772QDr7t3Kunufpu/2EhRq3H3Lw2xcv5NarUpb//JGN1Oade64Ywt3/vAJ7v7xZqqjw3zqbd+mxijX/Pl9fO/6BxrdPEmSJElHOCf1bbBCocTKU0qsOaubEx5ekFzZ38RZZ62GQhGGBoFKQ9sozUbnnLN499+xNswbPnQx1dEKr/2/x1MqtTSwZZIkSZKOBgYyM1GlAtUqECDW2DOuSVIjhEJz8mFZnGpNSZJmj6uuOnevy1dfffu0lkmSEgYyObpl7bpprhkh7l8IM/1tS5IkSQdvbMiSDWHGC2DGhjSTbUuSZgMDmQa4Ze26fSbhXbt17ZS3G+jYBDh5ryRJkmaGeshy9dW3TxjQ1K83dJGkvRnINEi9R8sFZ6/hlrXrkpDm4qnCljX2hJEkSVJDjdfT5aqrzp1wyNLYYEaSlDCQaRBPUy1JkiRJ0uxlINMg2Z4u9XDmlrXraOtbtvv6ZIjS3uo9aiRJkqS8TDU/zHTWmWwOmbHsTSNpNig0ugGz0US9Y7JhzHiXwcl7JUmSlK/9CVIkSdNnIJOjAxmm1Na3bK9gxqFOkiRJkiQd+RyylKP62ZWyv9v6lnHnzQNAMkRp4sBlz7AmSZIkKS+Tnd56f9bbn2FIYycJlqSjkYFMg9x58wBtTD0kaeycMtnAxnBGkiRJh0s9FBk7N8x0g5LprDfdcEeSjkYGMjmYPEQJEAoQAsVCibamVmqxxnBlhHLvIiDuXnO8OWUkSZqVYoQQDv26koB9e6iMH5CUgHL6dyVzXRGoArXMsvryvWdMmM4EwZOtJ0lHMueQabRCAZqaodxCsamZBe2LmdvWRXNzGxSLgAeQkqRZLsa9fyDZf469Psbxb28YI+2XqcOQAkkQMw9YRTK0fgnQBSwFVqa/l6e/5wBtQAvQCcxNf7en17Uw1b8lTiwsHTqxEIgF940zgT1kDoPJTk3d1reMZ17cls4bE6iWSpQ722luLhHj6SyYX6RaGGWwd5ThoXkw0Au1CsTauNubzn1K2n+VyiDEZEdVamppcGukWSpGYqkIPb2EUok4NETo6IAQ2HTFsSz5zF0U5s4hjo5CsUgol6GpRCwEQi1CrUZsKiWBTIyEStXeMtJBK5AEKt1w/By6X7iJNgZ4bP0aeCJdtBAYakl+jwJ3LoRNJB1mVpDkM6PAILAZGAJ4CNiZ+6ORjkoh1A9jk4sRmnaOMLKgTCwEtp9SotoCi28bhUiyz8zevJpcLg5VqbQbGRxOPruNFALF1nYWd7Qw0Fekf2QXlWozS0ttNI8cx+ZFBbZvGoWRfqgmgczZ3WezduvaBjdcmgVi5KGfb6OlMkxruZX+WjOtjNC3c4gTz1/d6NZJR78QYLQCrc088RsnMbikxiUX/DePvnsppf4K1GDHL59BrRTYevEonfeVaX+yxtx1/YzMb6bSVmCko0DL01WG5xZp7qnStr6HMDjc6EcmzWjZoUr1Xil7esiUgeVw1kI4bZQr2r5E7a+f5Ec/fJRnv7OLp04+k55HRqjFZSwq7WLjB77GeS89lrkXHkN/sUYLwyzYsZPSrhL3fvdxFiyaw0cfnMOq1z2f2nePo6XUz56hTZL2W0i+kChvH4Q0VAm1GiNdbRQqNZq3DhFGaxzzaBWAXSfNpXNdL8OL2ykOVqmVCxRGagx1l6kVYftpzSy+rUJhdPLOATpwDllqgPpZlSDpcT0UahSoEPtbKLe3MFio0VQu0dpSglIT2Zfp01/+YQNaLM0+D/3H03QX2il0lqm0tNJUrbF9a5W2YxY3umnS0S9G4o6dbHvBsYQdvSz56SDz7ws89KFTqDUFhrrKdN03yILbttL9rUdoXV+m655h5t3fy0OvbmfzeWWat42w/YxApbXAwOICA4tK1FrKU9+3pAkUgGYoL2TpeU/wC203svie7Xz6unUsX7GYRafMo7N7DrfdU+K6r0Ru/dEIJ57Wyo5HNjN448N0fPcxFn5/J3Fjgb67+nn0iwNsWVvhslcVGOpZT2HUf0ukgxELgXLPMLVS0iu01lIixMjo/FZK/aMUn+phYEUbQ0vaKGzvYdt58+lfXCQ2FWne0k+lvUR5az/FwVE6HtnFnJ/3suD+GqWBaqMf2lHNHjKNFAJbb+vjyVjh8iuOYaRllJ07K6x7cAsdzXPpvqSNckuZkZEyVEepT/B7580D455xyWFL0qEz98ROtj3Ww9LjFlFtrfG1r++ipbyDi5qaGV1SoKmptdFNlI5O6TCl/gtPYHhe4GcfOIb2n5cZWFZj2Q8CTbuqtG4fIIxUoFZjy+WrOe5zG6jNbefB35zLwrsCzbuSg8cTrtnOjrMWEIvQdetWwqjfvEsHpwRzYHXlVjZc/QN6v9XJmhObOOe0Nr73eBNfW1vjyZ0r2fjkdl7+umVs+mkzv/DM+YzeX+ThbzzJdfetZ9kfrKb32NNY+LEubvz76zj2+I+w8bttrOJJ9kwC7CS+0v5qGqgQKjVaN/YRm4oUKjXCaJVaKVAIgfvfspyXXXg7P790Dg9/fDkh9HHsh5NxTbFQIBag2t5MYbRKLBWotjYRalBtLuwzpEmHjlH0IZYNRS44e83uy7esXcedNw/wzIvbkhVDAQpFOle086wz53LPDzcyOFKjWq1y5llLOOc5XXRTprmlCZqm/41eNqSRdOAqwxXWbamwfudT3PCNx5l/7A6Wr2plkBrukqTDKARCpUrH2g0sur2fldcGCNC1NvDUOQUKI1WGF7cTH9vIpsuW0v3THvpOX8KmF8xnzb8P0vp0la1nFShv6iH0D1ItBzofrzK0ch4MjzT60UlHsBrQD9t6+d76y3j4ilfT8fftnHhCYMex2+h9aAuLeh7gZc+5n394Xx8jN9zJro1Fnrx3iHu/+yS1FR2seW4Xxz1nNXfcN8SO7Z1c8b7Xcd0ne7nvi09SChWygcx4rrrqXCf3lSZQaS1BNTK8uJ0wmsyZVmsrU+4ZJhYDx3ynxkMvX8LG157M6t/ZxOo/2kX/8lZCpUZhaITiUI1HX95Goaef7ad3UhwYIVQjwQPfw8oeMo1UKPH09h4G55c549w57NheY8XSJnY9XeW+e3s48ZIW2FZJwhtJuRou9XPWc5opVgK7Tp5HHK4ysH6QG9eu55daV7HybHvISIdNCNBUoumJ7RQG53LsbZvZ9OsnseQnFaotRarlAuvfehbHfWELT166mMW37CTU2tjwgnZatkUW316lNqeN0D/E06dFTvrbDVS751FdMp/ijv6Jz8Ykiauvvn2cuWPqRoBHKH+3ixGeyX8teS7bfmkbpZZNdN97O69Y/jA9Nz/O6JOB0S0VTn31M9ix5THKq8oMPLaDSi9Uv30f733RIopbKvzTtY9z0fMv5Y7No1SKW2nK/dFKR5EYGV7cRmmwQt/qObSv7yM2BUKE4nCV9kd3svmyY1j+rw+x7i0ncux3hmndMszg8naG5xYZmleg43EYWr2QHadFuu6MNPdUkiFQOmwMZBopRhY2LWDXaOChTYHtP++jp7+NXRt7WLS4mfsf6Kdabofq9LtYO2RJOjQ2rtvFrTdvYenyNha0dHLyxe08VQ48d+kcdjUbxkiHXQhQKlLcsQvmdLL8S48wcvwS+o5pYfMlNU765E7u/+P5HP+5IQaXt9NzQonl3x9keGETG15R4aSPADt2cuI5Q4we003xnnUUFncbxkgHrQI8DfTD5gV07GijsHw1lRNGCItrHH/JVnb1zmXnHQv4/I1LOOHYNk5e8RDPOLeN//j4D+n98WqOP6OTW294ipXPXsL1P66wbFmktamV5LRLifF6wjiMSZpCjFRaS5QGqgwvbqPcMwyjNSgFai0llnx7E+s/sYjVr7qD8IzVhGrkqXPbWP7Np6h1trD5/Dk09Y7Q+UiZDZfOY9HtToR/uBnINEqMUB3lga1bWViMLGxZysbmHp7a9QS7CtvpXH88zziui4FtAzA6BA6SkHJU45nnLmPpikU8+OBmep8aoVjo5Cdf38HcBfC6F/odnpSrGKG5THnD0yx4tMLcdQsZXNbOKX+2BUYrNBcLNPV103tcCwt/spXjP9nJpufPozAyj8o34dgNj/PQu85gzV8/SOjs8LTX0kEbSX8GaRluh0fmEnecy81DJxGXFCg0V/nGDVvoWlJm3T1dLH/vqXzuyz/jpX9zOhse2sEXN9RY+rKlXH9nB0sW15jX1w4DPbu37rAk6SDUv3iIkeH5zRCgedsQIQRqc9robB3mwX88k+5bSgx2BY753DpGT1hGqW+EhfcNUxgcZcEDw5S39jO4onP3KbB1eBjIHGKT9VAZ6NgE1Od4iVCrcPoZZSg0QaGfriWPs6JjCduf6GZb56Ns21ChWK1BbfLxtPX7tHeMdGhURodpW9HCyqWR405fzVPrBolt8MwXLOK8C+dQaHYYoZSbenhS/91Uoritl45tvclpsYGRY7sob9lFXNXMg2/qYuX1oyy9aSeFXQNUuzqJLWXWfGaLYYw0TdlhSzDe6a/rKsBOYBfs2EzTjlagGWjhV85tZ2QoUisdx4MPDND9skG++UCB7fedR0/PKN1Lmyg+HOjsGqKpdRjoz+fBSbNIfTLe0XnNxEKy/2v9u8jKEgzPjSz/Xi9Dpx/DUFcTxeFmNj4vcOI1BZp6hhha2mEYkwMDmcOofuajSVWraeASKDbV2DW0g+ZFgYXVIsVd9TBm70JIgh1Jh0spPYNSUwlohiWnFggElq5qg1CgVGppbAOl2SwbqDQlhzHl9VuhWKD7O4/RsWkZLXc+yq6LT6BdRLr+AAAEu0lEQVTz3gGKTyf/5IXRimGMtB+y4cvUQ4VqJD1mKiTDjgpAgXJLCzBAcVMLQ+WTmBcKfP/rj3PWqZ3c+W/bWLFolMJFNaDMVBP6SjpwMbCn50wIhEqk9alRhha10bJ1kFgq0LK5nxPXB0YXtDDY3URzT9VhvjkwkDnMsmdc2n25A9r6lqVrxN1v9AD0j+4ZO1uu7X3O99965YV89FtfHHf7kg6fUsk5Y6QZrVjYPRFw67ptMKeTOXdvIbY2w8ioYYx0iGV7z+wd1tSDmboBoIemDZ2woRkocMUlCxmqDnLpr0ExDFFuKgFDU96n88dIh0j6v2csBkItMtzVCjESSwVGFrRQ3jHsRL45MpBpgPqpsPeEMuMb6Ni0e52Bjk2GMZIkjSc7rCkzzDf0D+69XNIBGTuny/6FIzWSYU3pcN9CiZZCIb1+739FnMhXaoA0oBnqbiXUIkNdLcmpru0dkwsDmZxke8rU/64PPdozrGnf4U1nd58NwNqta8fdniRJysiGLwYx0iExNhSZzqS7+wYp9bB0hCSc2XeIUn3uGkMYKX/1+Wbqv5UPZ6bM2WRBytndZ+8OYOrWbl1rGCNJkqQj1r4BjvPFSBIYyMwo44UvWbesXWcYI0mSpIY6kB4sE/WqueqqcyeZk0aSjm4OWWqQ7NmXDFkkSZJ0JJkqOJluyFJfNvGptSXp6GUPmQaxt4skSZK0h2GMpNnGHjINZigjSZKko810JwKur2cYI2k2MpCZIbJDmMYytJEkSdKRYLyhR5OdlcmhSpJmMwOZGcLQRZIkSUe68YIYwxZJGp+BjCRJkqRDziBGkibnpL6SJEmSJEk5M5CRJEmSJEnKmYGMJEmSJElSzgxkJEmSJEmScmYgI0mSJEmSlDMDGUmSJEmSpJwZyEiSJEmSJOXMQEaSJEmSJClnBjKSJEmSJEk5M5CRJEmSJEnKmYGMJEmSJElSzgxkJEmSJEmScmYgI0mSJEmSlDMDGUmSJEmSpJwZyEiSJEmSJOXMQEaSJEmSJClnBjKSJEmSJEk5M5CRJEmSJEnKmYGMJEmSJElSzgxkJEmSJEmScmYgI0mSJEmSlDMDGUmSJEmSpJwZyEiSJEmSJOXMQEaSJEmSJClnBjKSJEmSJEk5M5CRJEmSJEnKmYGMJEmSJElSzgxkJEmSJEmScmYgI0mSJEmSlDMDGUmSJEmSpJwZyEiSJEmSJOXMQEaSJEmSJClnBjKSJEmSJEk5M5CRJEmSJEnKmYGMJEmSJElSzgxkJEmSJEmScmYgI0mSJEmSlDMDGUmSJEmSpJwZyEiSJEmSJOXMQEaSJEmSJClnBjKSJEmSJEk5M5CRJEmSJEnKmYGMJEmSJElSzgxkJEmSJEmScmYgI0mSJEmSlDMDGUmSJEmSpJwZyEiSJEmSJOUsxBgb3Ya9hBC2Ao81uh1qmJUxxu5GN0L7sjZnPWtzhrI2Zz1rc4ayNmc9a3OGsjZnvRlVmzMukJEkSZIkSTraOWRJkiRJkiQpZwYykiRJkiRJOTOQkSRJkiRJypmBjCRJkiRJUs4MZCRJkiRJknJmICNJkiRJkpQzAxlJkiRJkqScGchIkiRJkiTlzEBGkiRJkiQpZ/8fq//cYqAF/0MAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 1440x576 with 15 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "layer_name=model.layers[1].name\n",
    "model_path = join(result_dir, 'checkpoint.h5')\n",
    "predict_two_output = True \n",
    "\n",
    "# Get gradcam images\n",
    "gradcam_images = sorted([os.path.join(gradcam_dir, f) for f in os.listdir(gradcam_dir) if f.endswith('.png')])\n",
    "\n",
    "# Plot images\n",
    "plot_gradcam(gradcam_images)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
