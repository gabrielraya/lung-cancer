{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Neural Image Compression # \n",
    "\n",
    "Using local Data to test functionality with a few WSIs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Imports ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Import NIC to python path\n",
    "import sys\n",
    "nic_dir = '/mnt/netcache/pathology/projects/pathology-weakly-supervised-lung-cancer-growth-pattern-prediction/code/neural-image-compression-private'\n",
    "sys.path.append(nic_dir +'/source')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "from tqdm import tqdm\n",
    "import os, shutil\n",
    "from os.path import join, dirname, exists\n",
    "import keras\n",
    "from gradcam_wsi import gradcam_on_dataset\n",
    "from preprocessing import data_to_csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Data ##\n",
    "\n",
    "To demonstrate the functionality of NIC, we will need a set of whole-slide images (WSIs) with their respective slide-level labels. In this case, we will use the WSIs that can be found using the following pattern:\n",
    "\n",
    "These data was already reorganized, it is, all the tiff files are contained in one folder for each class. \n",
    "\n",
    "These are a small version of the TCGA dataset:\n",
    "\n",
    "`/mnt/netcache/pathology/projects/data/tcga_luad/images_diagnostic`\n",
    "\n",
    "`/mnt/netcache/pathology/projects/data/tcga_lusc/images_diagnostic`\n",
    "\n",
    "The data we are going to use is only the **diagnostic** data and no the **tissue** data. The mask are already given, but we will have to implementa script to create this masks that filter out the background.\n",
    "\n",
    "\n",
    "Because there is no slide-level csv file, we have to create one, this will be created after once we get the featurized wsi. FIle should be located at  from:\n",
    "\n",
    "`/mnt/netcache/pathology/projects/data/slide_original_list_tcga.csv`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates csv from original data\n",
    "\n",
    "# project and data directories\n",
    "root_dir=  '/mnt/netcache/pathology/projects/pathology-weakly-supervised-lung-cancer-growth-pattern-prediction'\n",
    "data_dir = '/mnt/netcache/pathology/projects/pathology-weakly-supervised-lung-cancer-growth-pattern-prediction/data'\n",
    "\n",
    "# wsi directories\n",
    "dir_luad_wsi = os.path.join(data_dir, 'tcga_luad', 'wsi_diagnostic_tif')\n",
    "dir_lusc_wsi = os.path.join(data_dir, 'tcga_lusc', 'wsi_diagnostic_tif')\n",
    "dir_luad_wsi_mask = os.path.join(data_dir, 'tcga_luad', 'tissue_masks_diagnostic')\n",
    "dir_lusc_wsi_mask = os.path.join(data_dir, 'tcga_lusc', 'tissue_masks_diagnostic')\n",
    "\n",
    "# compressed image directories\n",
    "vectorized_luad_dir = join(root_dir, 'results', 'mini_tcga', 'tcga_luad', 'vectorized')\n",
    "vectorized_lusc_dir = join(root_dir, 'results', 'mini_tcga', 'tcga_lusc', 'vectorized')\n",
    "featurized_luad_dir = join(root_dir, 'results', 'mini_tcga', 'tcga_luad', 'featurized')\n",
    "featurized_lusc_dir = join(root_dir, 'results', 'mini_tcga', 'tcga_lusc', 'featurized')\n",
    "\n",
    "# results directory \n",
    "result_dir = join(root_dir, 'results', 'models', 'baseline_model')  # store the results from trained model\n",
    "gradcam_dir = join(result_dir, 'gradcam')        # store gradcam results\n",
    "\n",
    "# Set paths\n",
    "model_path = './neural-image-compression-private/models/encoders_patches_pathology/encoder_bigan.h5'\n",
    "csv_train = os.path.join(data_dir, 'train_slide_list_tcga.csv')\n",
    "csv_val = os.path.join(data_dir, 'validation_slide_list_tcga.csv')\n",
    "csv_test = os.path.join(data_dir, 'test_slide_list_tcga.csv')\n",
    "\n",
    "# csv paths\n",
    "csv_path_wsi =  os.path.join(root_dir,'data/slide_original_list_tcga.csv')\n",
    "csv_path_compressed_wsi = os.path.join(root_dir, 'data', 'slide_compressed_list_tcga.csv')\n",
    "\n",
    "cache_dir = '/home/user/'  # used to store local copies of files during I/O operations (useful in cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Preprocessing\n",
    "\n",
    "We need to create a csv file to point out the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 10583.66it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 10597.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating main csv data files from original data...\n",
      "Csv file sucessfully exported!\n",
      "Files were read with shapes: (20, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of                    slide_id  label\n",
       "0   TCGA-05-4244-01Z-00-DX1      1\n",
       "1   TCGA-05-4245-01Z-00-DX1      1\n",
       "2   TCGA-05-4249-01Z-00-DX1      1\n",
       "3   TCGA-05-4250-01Z-00-DX1      1\n",
       "4   TCGA-05-4382-01Z-00-DX1      1\n",
       "5   TCGA-05-4395-01Z-00-DX1      1\n",
       "6   TCGA-05-4396-01Z-00-DX1      1\n",
       "7   TCGA-05-4397-01Z-00-DX1      1\n",
       "8   TCGA-05-4398-01Z-00-DX1      1\n",
       "9   TCGA-4B-A93V-01Z-00-DX1      1\n",
       "10  TCGA-33-4538-01Z-00-DX3      0\n",
       "11  TCGA-52-7812-01Z-00-DX1      0\n",
       "12  TCGA-60-2721-01Z-00-DX1      0\n",
       "13  TCGA-77-8007-01Z-00-DX1      0\n",
       "14  TCGA-77-8009-01Z-00-DX1      0\n",
       "15  TCGA-77-8139-01Z-00-DX1      0\n",
       "16  TCGA-77-8143-01Z-00-DX1      0\n",
       "17  TCGA-77-A5G1-01Z-00-DX1      0\n",
       "18  TCGA-NK-A5CR-01Z-00-DX1      0\n",
       "19  TCGA-NK-A5D1-01Z-00-DX1      0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from preprocessing import create_csv\n",
    "\n",
    "print('Creating main csv data files from original data...')\n",
    "create_csv(dir_luad_wsi, dir_lusc_wsi, csv_path_wsi, '.tif')\n",
    "\n",
    "# read files to check shapes\n",
    "df = pd.read_csv(csv_path_wsi)\n",
    "print(f'Files were read with shapes: {df.shape}')\n",
    "df.head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Encoder network ##\n",
    "\n",
    "To perform NIC, we will need an encoder network to transform small image patches into embedding vectors. According to the paper, BiGAN produces the best unsupervised encoder and it is the one we will train here.\n",
    "\n",
    "Alternatively, a collection of pretrained encoders (the one used in the NIC paper) can be found in \n",
    "\n",
    "`./models/encoders_patches_pathology/*.h5`\n",
    "\n",
    "Remember that these pretrained encoders accept 128x128x3 patches taken at 0.5 um/px resolution (often level 1), except for the BiGAN model that takes 64x64x3 at 1 um/px (often level 2).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to train the BiGAN model, we will first extract patches from the slides in the `encoder` partition. We will sample 10K patches per slide, producing ~260K patches in total. We select 96x96 patches to perform crop augmentation during training later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "pycharm": {
     "name": "#%% \n"
    }
   },
   "outputs": [],
   "source": [
    "# # Dont run this we, will train later the encoder but not now. \n",
    "\n",
    "# from source.extract_patches import create_patch_dataset\n",
    "\n",
    "# patches_npy_path = join(root_dir, 'results', 'patches', 'training.npy')\n",
    "\n",
    "# # Extracts patches from whole-slide images and store them in a numpy array file\n",
    "# create_patch_dataset(\n",
    "#     input_dir=slide_dir,\n",
    "#     csv_path=csv_path,\n",
    "#     partition_tag='encoder',\n",
    "#     output_path=patches_npy_path,\n",
    "#     image_level=2,\n",
    "#     patch_size=96,\n",
    "#     n_patches_per_image=10000,\n",
    "#     cache_dir=join(cache_dir, 'patches')\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have extracted the patches, we can proceed to train the BiGAN model. We will use the hyper-parameters described in the NIC paper. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from source.train_bigan_model import BiganModel\n",
    "\n",
    "# model_bigan_dir = join(root_dir, 'results', 'encoders', 'bigan', 'rotterdam1_96_noaug', '0.0001')\n",
    "\n",
    "# # Trains BiGAN\n",
    "# bigan = BiganModel(\n",
    "#     latent_dim=128,\n",
    "#     n_filters=128,\n",
    "#     lr=0.0001,\n",
    "#     patch_size=64,\n",
    "# )\n",
    "# bigan.train(\n",
    "#     x_path=patches_npy_path,\n",
    "#     output_dir=model_bigan_dir,\n",
    "#     epochs=400000,\n",
    "#     batch_size=64,\n",
    "#     sample_interval=1000,\n",
    "#     save_models_on_epoch=True\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beware that training this model is highly unstable, thus it can fail or collapse with ease. If this happens, restart the training. Selecting a checkpoint model is a manual procedure: check the generated images and loss values and avoid abnormal results. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Compress images ##\n",
    "\n",
    "Once we have a trained encoder, we can proceed with the WSI compression. I recommend running several `IDLE` instances of the following code in the cluster to speed up the lenghty process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before the actual compression, we need to vectorize the WSIs. This process extracts all non-background patches from the slide and store them in numpy array format for quick access. In this case, we will read 64x64 patches at 1 um/px resolution (level 2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already existing file TCGA-05-4244-01Z-00-DX1 - 9 images left\n",
      "Already existing file TCGA-05-4245-01Z-00-DX1 - 8 images left\n",
      "Already existing file TCGA-05-4249-01Z-00-DX1 - 7 images left\n",
      "Already existing file TCGA-05-4250-01Z-00-DX1 - 6 images left\n",
      "Already existing file TCGA-05-4382-01Z-00-DX1 - 5 images left\n",
      "Already existing file TCGA-05-4395-01Z-00-DX1 - 4 images left\n",
      "Already existing file TCGA-05-4396-01Z-00-DX1 - 3 images left\n",
      "Already existing file TCGA-05-4397-01Z-00-DX1 - 2 images left\n",
      "Already existing file TCGA-05-4398-01Z-00-DX1 - 1 images left\n",
      "Already existing file TCGA-4B-A93V-01Z-00-DX1 - 0 images left\n",
      "Finish Processing All images!\n"
     ]
    }
   ],
   "source": [
    "# Vectorize LUAD WSIs\n",
    "from vectorize_wsi import vectorize_images\n",
    "\n",
    "vectorize_images(\n",
    "    input_dir=dir_luad_wsi,\n",
    "    mask_dir=dir_luad_wsi_mask, \n",
    "    output_dir=vectorized_luad_dir, \n",
    "    cache_dir=cache_dir, \n",
    "    image_level=2, \n",
    "    patch_size=128\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already existing file TCGA-33-4538-01Z-00-DX3 - 9 images left\n",
      "Already existing file TCGA-52-7812-01Z-00-DX1 - 8 images left\n",
      "Already existing file TCGA-60-2721-01Z-00-DX1 - 7 images left\n",
      "Already existing file TCGA-77-8007-01Z-00-DX1 - 6 images left\n",
      "Already existing file TCGA-77-8009-01Z-00-DX1 - 5 images left\n",
      "Already existing file TCGA-77-8139-01Z-00-DX1 - 4 images left\n",
      "Already existing file TCGA-77-8143-01Z-00-DX1 - 3 images left\n",
      "Already existing file TCGA-77-A5G1-01Z-00-DX1 - 2 images left\n",
      "Already existing file TCGA-NK-A5CR-01Z-00-DX1 - 1 images left\n",
      "Already existing file TCGA-NK-A5D1-01Z-00-DX1 - 0 images left\n",
      "Finish Processing All images!\n"
     ]
    }
   ],
   "source": [
    "# Vectorize LUSC WSIs\n",
    "\n",
    "vectorize_images(\n",
    "    input_dir=dir_lusc_wsi,\n",
    "    mask_dir=dir_lusc_wsi_mask, \n",
    "    output_dir=vectorized_lusc_dir, \n",
    "    cache_dir=cache_dir, \n",
    "    image_level=2, \n",
    "    patch_size=128\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can compress the WSIs. Each WSI (vectorized file) will be processed 8 times due to WSI-level augmentation (rotation and flip). We will use an existing pretrained encoder from the NIC paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already existing file TCGA-05-4244-01Z-00-DX1_{item} - 9 images left\n",
      "Already existing file TCGA-05-4245-01Z-00-DX1_{item} - 8 images left\n",
      "Already existing file TCGA-05-4249-01Z-00-DX1_{item} - 7 images left\n",
      "Already existing file TCGA-05-4250-01Z-00-DX1_{item} - 6 images left\n",
      "Already existing file TCGA-05-4382-01Z-00-DX1_{item} - 5 images left\n",
      "Already existing file TCGA-05-4395-01Z-00-DX1_{item} - 4 images left\n",
      "Already existing file TCGA-05-4396-01Z-00-DX1_{item} - 3 images left\n",
      "Already existing file TCGA-05-4397-01Z-00-DX1_{item} - 2 images left\n",
      "Already existing file TCGA-05-4398-01Z-00-DX1_{item} - 1 images left\n",
      "Already existing file TCGA-4B-A93V-01Z-00-DX1_{item} - 0 images left\n",
      "Finish Processing All images!\n"
     ]
    }
   ],
   "source": [
    "# Featurize images\n",
    "from featurize_wsi import featurize_images\n",
    "\n",
    "# Featurize LUAD data\n",
    "featurize_images(\n",
    "    input_dir=vectorized_luad_dir,\n",
    "    model_path=model_path, \n",
    "    output_dir=featurized_luad_dir, \n",
    "    batch_size=32\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already existing file TCGA-33-4538-01Z-00-DX3_{item} - 9 images left\n",
      "Already existing file TCGA-52-7812-01Z-00-DX1_{item} - 8 images left\n",
      "Already existing file TCGA-60-2721-01Z-00-DX1_{item} - 7 images left\n",
      "Already existing file TCGA-77-8007-01Z-00-DX1_{item} - 6 images left\n",
      "Already existing file TCGA-77-8009-01Z-00-DX1_{item} - 5 images left\n",
      "Already existing file TCGA-77-8139-01Z-00-DX1_{item} - 4 images left\n",
      "Already existing file TCGA-77-8143-01Z-00-DX1_{item} - 3 images left\n",
      "Already existing file TCGA-77-A5G1-01Z-00-DX1_{item} - 2 images left\n",
      "Already existing file TCGA-NK-A5CR-01Z-00-DX1_{item} - 1 images left\n",
      "Already existing file TCGA-NK-A5D1-01Z-00-DX1_{item} - 0 images left\n",
      "Finish Processing All images!\n"
     ]
    }
   ],
   "source": [
    "# Featurize LUSC data\n",
    "featurize_images(\n",
    "    input_dir=vectorized_lusc_dir,\n",
    "    model_path=model_path, \n",
    "    output_dir=featurized_lusc_dir, \n",
    "    batch_size=32\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train CNN on compressed images ##\n",
    "\n",
    "Once we have compressed the WSIs, we can proceed with the CNN classifier. In this example, we will train a classifier targeting the binary label `HGP_SL` found in the CSV file. We will be training 4 models using cross-validation: in each fold, we will use 2 data partitions for training, 1 for validation and 1 for testing. At the end of model training, we perform inference on the test set, compute metrics, and run GradCAM on the images.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:00<00:00, 59353.36it/s]\n",
      "100%|██████████| 30/30 [00:00<00:00, 63040.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating compressed wsi csv file ...\n",
      "Csv file sucessfully exported!\n",
      "Creating split train/validation/test csv files with no augmentations ...\n",
      "Train/validation/test csv files sucessfully exported!\n",
      "Files were read with shapes: Training: (11, 2), Validation (5, 2), Testing (4, 2)\n",
      "Total files: Files were read with shapes: 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>slide_id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>TCGA-05-4382-01Z-00-DX1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>TCGA-05-4396-01Z-00-DX1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>TCGA-77-8139-01Z-00-DX1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>TCGA-77-8143-01Z-00-DX1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>TCGA-77-8009-01Z-00-DX1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>TCGA-60-2721-01Z-00-DX1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>TCGA-52-7812-01Z-00-DX1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>TCGA-77-8007-01Z-00-DX1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>TCGA-33-4538-01Z-00-DX3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>TCGA-05-4249-01Z-00-DX1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>TCGA-05-4250-01Z-00-DX1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   slide_id  label\n",
       "0   TCGA-05-4382-01Z-00-DX1      1\n",
       "1   TCGA-05-4396-01Z-00-DX1      1\n",
       "2   TCGA-77-8139-01Z-00-DX1      0\n",
       "3   TCGA-77-8143-01Z-00-DX1      0\n",
       "4   TCGA-77-8009-01Z-00-DX1      0\n",
       "5   TCGA-60-2721-01Z-00-DX1      0\n",
       "6   TCGA-52-7812-01Z-00-DX1      0\n",
       "7   TCGA-77-8007-01Z-00-DX1      0\n",
       "8   TCGA-33-4538-01Z-00-DX3      0\n",
       "9   TCGA-05-4249-01Z-00-DX1      1\n",
       "10  TCGA-05-4250-01Z-00-DX1      1"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split data\n",
    "from preprocessing import data_to_csv, create_csv, generate_csv_files\n",
    "\n",
    "featurized_dir = {'data_dir_luad': featurized_luad_dir, 'data_dir_lusc': featurized_lusc_dir}\n",
    "csv_path = {'csv_train': csv_train, 'csv_val': csv_val, 'csv_test': csv_test}\n",
    "\n",
    "\n",
    "# Create csv files \n",
    "print('Creating compressed wsi csv file ...')\n",
    "create_csv(featurized_luad_dir, featurized_lusc_dir, csv_path_compressed_wsi)\n",
    "\n",
    "print('Creating split train/validation/test csv files with no augmentations ...')\n",
    "generate_csv_files(csv_path_compressed_wsi, csv_train, csv_val, csv_test, test_size=0.2, validation_size = 0.3)\n",
    "\n",
    "# read files to check shapes\n",
    "df = pd.read_csv(csv_train);  df2 = pd.read_csv(csv_val);   df3 = pd.read_csv(csv_test)\n",
    "print(f'Files were read with shapes: Training: {df.shape}, Validation {df2.shape}, Testing {df3.shape}')\n",
    "print(f'Total files: Files were read with shapes: {df.shape[0]+df2.shape[0]+df3.shape[0]}')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_training import train_wsi_classifier, eval_model, compute_metrics\n",
    "from utils import check_file_exists\n",
    "\n",
    "def train_model(featurized_dir, csv_path, fold_n, output_dir, cache_dir, batch_size=16, epochs=32,\n",
    "                images_dir=None, vectorized_dir=None, lr=1e-2, patience=4, delete_folder=False,\n",
    "                occlusion_augmentation=False, elastic_augmentation=False, shuffle_augmentation=None):\n",
    "    \"\"\"\n",
    "    Trains a CNN using compressed whole-slide images.\n",
    "\n",
    "    :param featurized_dir: folder containing the compressed (featurized) images.\n",
    "    :param csv_path: list of slides with labels.\n",
    "    :param fold_n: fold determining which data partitions to use for training, validation and testing.\n",
    "    :param output_dir: destination folder to store results.\n",
    "    :param cache_dir: folder to store compressed images temporarily for fast access.\n",
    "    :param batch_size: number of samples to train with in one-go.\n",
    "    :return: nothing.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Delete folder and subfolders if exists\n",
    "    if delete_folder: \n",
    "        if exists(result_dir):  shutil.rmtree(result_dir)\n",
    "            \n",
    "    # Train CNN\n",
    "    train_wsi_classifier(\n",
    "        data_dir=featurized_dir,\n",
    "        csv_path=csv_path,\n",
    "        partitions=None,\n",
    "        crop_size=400,\n",
    "        output_dir=output_dir,\n",
    "        output_units=2,\n",
    "        cache_dir=cache_dir,\n",
    "        n_epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        lr=lr,\n",
    "        code_size=128,\n",
    "        workers=1,\n",
    "        train_step_multiplier=1,\n",
    "        val_step_multiplier=0.5,\n",
    "        keep_data_training=1,\n",
    "        keep_data_validation=1,\n",
    "        patience=patience,\n",
    "        occlusion_augmentation=occlusion_augmentation,\n",
    "        elastic_augmentation=elastic_augmentation,\n",
    "        shuffle_augmentation=shuffle_augmentation\n",
    "    )  \n",
    "\n",
    "    # Evaluate CNN \n",
    "    \n",
    "    # Get compressed wsi directories with csv test file\n",
    "    data_config = featurized_dir\n",
    "    data_config['csv_path'] = csv_path['csv_test']\n",
    "    \n",
    "    eval_model(\n",
    "        model_path=join(output_dir, 'checkpoint.h5'),\n",
    "        data_config=data_config,\n",
    "        crop_size=400,\n",
    "        output_path=join(output_dir, 'eval', 'preds.csv'),\n",
    "        cache_dir=None,\n",
    "        batch_size=batch_size,\n",
    "        keep_data=1\n",
    "    )\n",
    "\n",
    "    # Metrics\n",
    "    try:\n",
    "        compute_metrics(\n",
    "            input_path=join(output_dir, 'eval', 'preds.csv'),\n",
    "            output_dir=join(output_dir, 'eval')\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print('Failed to compute metrics. Exception: {e}'.format(e=e), flush=True)\n",
    "\n",
    "#     # Apply GradCAM analysis to CNN\n",
    "#     gradcam_on_dataset(\n",
    "#         featurized_dir=featurized_dir,\n",
    "#         csv_path=csv_path,\n",
    "#         model_path=join(output_dir, 'checkpoint.h5'),\n",
    "#         partitions=folds[fold_n]['test'],\n",
    "#         layer_name='separable_conv2d_1',\n",
    "#         output_unit=1,\n",
    "#         custom_objects=None,\n",
    "#         cache_dir=cache_dir,\n",
    "#         images_dir=images_dir,\n",
    "#         vectorized_dir=vectorized_dir\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading training set ...\n",
      "FeaturizedWsiGenerator data config: {'data_dir_luad': '/mnt/netcache/pathology/projects/pathology-weakly-supervised-lung-cancer-growth-pattern-prediction/results/mini_tcga/tcga_luad/featurized', 'data_dir_lusc': '/mnt/netcache/pathology/projects/pathology-weakly-supervised-lung-cancer-growth-pattern-prediction/results/mini_tcga/tcga_lusc/featurized', 'csv_path': '/mnt/netcache/pathology/projects/pathology-weakly-supervised-lung-cancer-growth-pattern-prediction/data/train_slide_list_tcga.csv'}\n",
      "FeaturizedWsiGenerator using 11 samples and 3 batches, distributed in 4 positive and 7 negative samples.\n",
      "Loading validation set ...\n",
      "FeaturizedWsiSequence data config: {'data_dir_luad': '/mnt/netcache/pathology/projects/pathology-weakly-supervised-lung-cancer-growth-pattern-prediction/results/mini_tcga/tcga_luad/featurized', 'data_dir_lusc': '/mnt/netcache/pathology/projects/pathology-weakly-supervised-lung-cancer-growth-pattern-prediction/results/mini_tcga/tcga_lusc/featurized', 'csv_path': '/mnt/netcache/pathology/projects/pathology-weakly-supervised-lung-cancer-growth-pattern-prediction/data/validation_slide_list_tcga.csv'}\n",
      "FeaturizedWsiSequence using 5 samples and 2 batches, distributed in 4 positive and 1 negative samples.\n",
      "Building model ...\n",
      "Training model ...\n",
      "Training model in directory: /mnt/netcache/pathology/projects/pathology-weakly-supervised-lung-cancer-growth-pattern-prediction/results/models/baseline_model with content 0\n",
      "Training model from scratch False False...\n",
      "Model: \"model_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_6 (InputLayer)         (None, 400, 400, 128)     0         \n",
      "_________________________________________________________________\n",
      "separable_conv2d_9 (Separabl (None, 199, 199, 128)     17664     \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 199, 199, 128)     512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_10 (LeakyReLU)   (None, 199, 199, 128)     0         \n",
      "_________________________________________________________________\n",
      "spatial_dropout2d_9 (Spatial (None, 199, 199, 128)     0         \n",
      "_________________________________________________________________\n",
      "separable_conv2d_10 (Separab (None, 99, 99, 128)       17664     \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 99, 99, 128)       512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_11 (LeakyReLU)   (None, 99, 99, 128)       0         \n",
      "_________________________________________________________________\n",
      "spatial_dropout2d_10 (Spatia (None, 99, 99, 128)       0         \n",
      "_________________________________________________________________\n",
      "separable_conv2d_11 (Separab (None, 49, 49, 128)       17664     \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 49, 49, 128)       512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_12 (LeakyReLU)   (None, 49, 49, 128)       0         \n",
      "_________________________________________________________________\n",
      "spatial_dropout2d_11 (Spatia (None, 49, 49, 128)       0         \n",
      "_________________________________________________________________\n",
      "separable_conv2d_12 (Separab (None, 24, 24, 128)       17664     \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 24, 24, 128)       512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_13 (LeakyReLU)   (None, 24, 24, 128)       0         \n",
      "_________________________________________________________________\n",
      "spatial_dropout2d_12 (Spatia (None, 24, 24, 128)       0         \n",
      "_________________________________________________________________\n",
      "separable_conv2d_13 (Separab (None, 11, 11, 128)       17664     \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 11, 11, 128)       512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_14 (LeakyReLU)   (None, 11, 11, 128)       0         \n",
      "_________________________________________________________________\n",
      "spatial_dropout2d_13 (Spatia (None, 11, 11, 128)       0         \n",
      "_________________________________________________________________\n",
      "separable_conv2d_14 (Separab (None, 5, 5, 128)         17664     \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 5, 5, 128)         512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_15 (LeakyReLU)   (None, 5, 5, 128)         0         \n",
      "_________________________________________________________________\n",
      "spatial_dropout2d_14 (Spatia (None, 5, 5, 128)         0         \n",
      "_________________________________________________________________\n",
      "separable_conv2d_15 (Separab (None, 3, 3, 128)         17664     \n",
      "_________________________________________________________________\n",
      "batch_normalization_16 (Batc (None, 3, 3, 128)         512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_16 (LeakyReLU)   (None, 3, 3, 128)         0         \n",
      "_________________________________________________________________\n",
      "spatial_dropout2d_15 (Spatia (None, 3, 3, 128)         0         \n",
      "_________________________________________________________________\n",
      "separable_conv2d_16 (Separab (None, 1, 1, 128)         17664     \n",
      "_________________________________________________________________\n",
      "batch_normalization_17 (Batc (None, 1, 1, 128)         512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_17 (LeakyReLU)   (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "spatial_dropout2d_16 (Spatia (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "batch_normalization_18 (Batc (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_18 (LeakyReLU)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 2)                 258       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 162,690\n",
      "Trainable params: 160,386\n",
      "Non-trainable params: 2,304\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "3/3 [==============================] - 24s 8s/step - loss: 0.7097 - categorical_accuracy: 0.5000 - val_loss: 0.7052 - val_categorical_accuracy: 0.5000\n",
      "Epoch 00000: val_loss improved from inf to 0.70519, saving model to /mnt/netcache/pathology/projects/pathology-weakly-supervised-lung-cancer-growth-pattern-prediction/results/models/baseline_model/checkpoint.h5\n",
      "Epoch 00000: saving model to /mnt/netcache/pathology/projects/pathology-weakly-supervised-lung-cancer-growth-pattern-prediction/results/models/baseline_model/last_epoch.h5\n",
      "Epoch 2/20\n",
      "3/3 [==============================] - 19s 6s/step - loss: 0.7062 - categorical_accuracy: 0.5000 - val_loss: 0.7015 - val_categorical_accuracy: 0.5000\n",
      "Epoch 00001: val_loss improved from 0.70519 to 0.70154, saving model to /mnt/netcache/pathology/projects/pathology-weakly-supervised-lung-cancer-growth-pattern-prediction/results/models/baseline_model/checkpoint.h5\n",
      "Epoch 00001: saving model to /mnt/netcache/pathology/projects/pathology-weakly-supervised-lung-cancer-growth-pattern-prediction/results/models/baseline_model/last_epoch.h5\n",
      "Epoch 3/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 26s 9s/step - loss: 0.7020 - categorical_accuracy: 0.5000 - val_loss: 0.6988 - val_categorical_accuracy: 0.5000\n",
      "Epoch 00002: val_loss improved from 0.70154 to 0.69885, saving model to /mnt/netcache/pathology/projects/pathology-weakly-supervised-lung-cancer-growth-pattern-prediction/results/models/baseline_model/checkpoint.h5\n",
      "Epoch 00002: saving model to /mnt/netcache/pathology/projects/pathology-weakly-supervised-lung-cancer-growth-pattern-prediction/results/models/baseline_model/last_epoch.h5\n",
      "Epoch 4/20\n",
      "3/3 [==============================] - 19s 6s/step - loss: 0.6990 - categorical_accuracy: 0.5000 - val_loss: 0.6982 - val_categorical_accuracy: 0.5000\n",
      "Epoch 00003: val_loss improved from 0.69885 to 0.69822, saving model to /mnt/netcache/pathology/projects/pathology-weakly-supervised-lung-cancer-growth-pattern-prediction/results/models/baseline_model/checkpoint.h5\n",
      "Epoch 00003: saving model to /mnt/netcache/pathology/projects/pathology-weakly-supervised-lung-cancer-growth-pattern-prediction/results/models/baseline_model/last_epoch.h5\n",
      "Epoch 5/20\n",
      "3/3 [==============================] - 20s 7s/step - loss: 0.6973 - categorical_accuracy: 0.5000 - val_loss: 0.6969 - val_categorical_accuracy: 0.5000\n",
      "Epoch 00004: val_loss improved from 0.69822 to 0.69686, saving model to /mnt/netcache/pathology/projects/pathology-weakly-supervised-lung-cancer-growth-pattern-prediction/results/models/baseline_model/checkpoint.h5\n",
      "Epoch 00004: saving model to /mnt/netcache/pathology/projects/pathology-weakly-supervised-lung-cancer-growth-pattern-prediction/results/models/baseline_model/last_epoch.h5\n",
      "Epoch 6/20\n",
      "3/3 [==============================] - 19s 6s/step - loss: 0.6966 - categorical_accuracy: 0.5000 - val_loss: 0.6957 - val_categorical_accuracy: 0.5000\n",
      "Epoch 00005: val_loss improved from 0.69686 to 0.69574, saving model to /mnt/netcache/pathology/projects/pathology-weakly-supervised-lung-cancer-growth-pattern-prediction/results/models/baseline_model/checkpoint.h5\n",
      "Epoch 00005: saving model to /mnt/netcache/pathology/projects/pathology-weakly-supervised-lung-cancer-growth-pattern-prediction/results/models/baseline_model/last_epoch.h5\n",
      "Epoch 7/20\n",
      "3/3 [==============================] - 21s 7s/step - loss: 0.6957 - categorical_accuracy: 0.5000 - val_loss: 0.6958 - val_categorical_accuracy: 0.5000\n",
      "Epoch 00006: val_loss did not improve (current: 0.69577, best: 0.69574, monitor_op: <ufunc 'less'>, best_op: <function ModelCheckpoint.__init__.<locals>.<lambda> at 0x7fc0de439950>)\n",
      "Epoch 00006: saving model to /mnt/netcache/pathology/projects/pathology-weakly-supervised-lung-cancer-growth-pattern-prediction/results/models/baseline_model/last_epoch.h5\n",
      "Epoch 8/20\n",
      "3/3 [==============================] - 19s 6s/step - loss: 0.6955 - categorical_accuracy: 0.5000 - val_loss: 0.6953 - val_categorical_accuracy: 0.5000\n",
      "Epoch 00007: val_loss improved from 0.69574 to 0.69528, saving model to /mnt/netcache/pathology/projects/pathology-weakly-supervised-lung-cancer-growth-pattern-prediction/results/models/baseline_model/checkpoint.h5\n",
      "Epoch 00007: saving model to /mnt/netcache/pathology/projects/pathology-weakly-supervised-lung-cancer-growth-pattern-prediction/results/models/baseline_model/last_epoch.h5\n",
      "Epoch 9/20\n",
      "3/3 [==============================] - 19s 6s/step - loss: 0.6953 - categorical_accuracy: 0.5000 - val_loss: 0.6953 - val_categorical_accuracy: 0.5000\n",
      "Epoch 00008: val_loss did not improve (current: 0.69532, best: 0.69528, monitor_op: <ufunc 'less'>, best_op: <function ModelCheckpoint.__init__.<locals>.<lambda> at 0x7fc0de439950>)\n",
      "Epoch 00008: saving model to /mnt/netcache/pathology/projects/pathology-weakly-supervised-lung-cancer-growth-pattern-prediction/results/models/baseline_model/last_epoch.h5\n",
      "Epoch 10/20\n",
      "3/3 [==============================] - 19s 6s/step - loss: 0.6952 - categorical_accuracy: 0.5000 - val_loss: 0.6951 - val_categorical_accuracy: 0.5000\n",
      "Epoch 00009: val_loss improved from 0.69528 to 0.69514, saving model to /mnt/netcache/pathology/projects/pathology-weakly-supervised-lung-cancer-growth-pattern-prediction/results/models/baseline_model/checkpoint.h5\n",
      "Epoch 00009: saving model to /mnt/netcache/pathology/projects/pathology-weakly-supervised-lung-cancer-growth-pattern-prediction/results/models/baseline_model/last_epoch.h5\n",
      "Epoch 11/20\n",
      "3/3 [==============================] - 21s 7s/step - loss: 0.6951 - categorical_accuracy: 0.5000 - val_loss: 0.6950 - val_categorical_accuracy: 0.5000\n",
      "Epoch 00010: val_loss improved from 0.69514 to 0.69504, saving model to /mnt/netcache/pathology/projects/pathology-weakly-supervised-lung-cancer-growth-pattern-prediction/results/models/baseline_model/checkpoint.h5\n",
      "Epoch 00010: saving model to /mnt/netcache/pathology/projects/pathology-weakly-supervised-lung-cancer-growth-pattern-prediction/results/models/baseline_model/last_epoch.h5\n",
      "Epoch 12/20\n",
      "3/3 [==============================] - 19s 6s/step - loss: 0.6950 - categorical_accuracy: 0.5000 - val_loss: 0.6949 - val_categorical_accuracy: 0.5000\n",
      "Epoch 00011: val_loss improved from 0.69504 to 0.69491, saving model to /mnt/netcache/pathology/projects/pathology-weakly-supervised-lung-cancer-growth-pattern-prediction/results/models/baseline_model/checkpoint.h5\n",
      "Epoch 00011: saving model to /mnt/netcache/pathology/projects/pathology-weakly-supervised-lung-cancer-growth-pattern-prediction/results/models/baseline_model/last_epoch.h5\n",
      "Epoch 13/20\n",
      "3/3 [==============================] - 21s 7s/step - loss: 0.6949 - categorical_accuracy: 0.5000 - val_loss: 0.6948 - val_categorical_accuracy: 0.5000\n",
      "Epoch 00012: val_loss improved from 0.69491 to 0.69475, saving model to /mnt/netcache/pathology/projects/pathology-weakly-supervised-lung-cancer-growth-pattern-prediction/results/models/baseline_model/checkpoint.h5\n",
      "Epoch 00012: saving model to /mnt/netcache/pathology/projects/pathology-weakly-supervised-lung-cancer-growth-pattern-prediction/results/models/baseline_model/last_epoch.h5\n",
      "Epoch 14/20\n",
      "3/3 [==============================] - 19s 6s/step - loss: 0.6947 - categorical_accuracy: 0.5000 - val_loss: 0.6947 - val_categorical_accuracy: 0.5000\n",
      "Epoch 00013: val_loss improved from 0.69475 to 0.69465, saving model to /mnt/netcache/pathology/projects/pathology-weakly-supervised-lung-cancer-growth-pattern-prediction/results/models/baseline_model/checkpoint.h5\n",
      "Epoch 00013: saving model to /mnt/netcache/pathology/projects/pathology-weakly-supervised-lung-cancer-growth-pattern-prediction/results/models/baseline_model/last_epoch.h5\n",
      "Epoch 15/20\n",
      "3/3 [==============================] - 22s 7s/step - loss: 0.6946 - categorical_accuracy: 0.5000 - val_loss: 0.6945 - val_categorical_accuracy: 0.5000\n",
      "Epoch 00014: val_loss improved from 0.69465 to 0.69452, saving model to /mnt/netcache/pathology/projects/pathology-weakly-supervised-lung-cancer-growth-pattern-prediction/results/models/baseline_model/checkpoint.h5\n",
      "Epoch 00014: saving model to /mnt/netcache/pathology/projects/pathology-weakly-supervised-lung-cancer-growth-pattern-prediction/results/models/baseline_model/last_epoch.h5\n",
      "Epoch 16/20\n",
      "3/3 [==============================] - 19s 6s/step - loss: 0.6945 - categorical_accuracy: 0.5000 - val_loss: 0.6944 - val_categorical_accuracy: 0.5000\n",
      "Epoch 00015: val_loss improved from 0.69452 to 0.69444, saving model to /mnt/netcache/pathology/projects/pathology-weakly-supervised-lung-cancer-growth-pattern-prediction/results/models/baseline_model/checkpoint.h5\n",
      "Epoch 00015: saving model to /mnt/netcache/pathology/projects/pathology-weakly-supervised-lung-cancer-growth-pattern-prediction/results/models/baseline_model/last_epoch.h5\n",
      "Epoch 17/20\n",
      "3/3 [==============================] - 19s 6s/step - loss: 0.6944 - categorical_accuracy: 0.5000 - val_loss: 0.6943 - val_categorical_accuracy: 0.5000\n",
      "Epoch 00016: val_loss improved from 0.69444 to 0.69435, saving model to /mnt/netcache/pathology/projects/pathology-weakly-supervised-lung-cancer-growth-pattern-prediction/results/models/baseline_model/checkpoint.h5\n",
      "Epoch 00016: saving model to /mnt/netcache/pathology/projects/pathology-weakly-supervised-lung-cancer-growth-pattern-prediction/results/models/baseline_model/last_epoch.h5\n",
      "Epoch 18/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 19s 6s/step - loss: 0.6943 - categorical_accuracy: 0.5000 - val_loss: 0.6943 - val_categorical_accuracy: 0.5000\n",
      "Epoch 00017: val_loss improved from 0.69435 to 0.69428, saving model to /mnt/netcache/pathology/projects/pathology-weakly-supervised-lung-cancer-growth-pattern-prediction/results/models/baseline_model/checkpoint.h5\n",
      "Epoch 00017: saving model to /mnt/netcache/pathology/projects/pathology-weakly-supervised-lung-cancer-growth-pattern-prediction/results/models/baseline_model/last_epoch.h5\n",
      "Epoch 19/20\n",
      "3/3 [==============================] - 21s 7s/step - loss: 0.6943 - categorical_accuracy: 0.5000 - val_loss: 0.6942 - val_categorical_accuracy: 0.5000\n",
      "Epoch 00018: val_loss improved from 0.69428 to 0.69423, saving model to /mnt/netcache/pathology/projects/pathology-weakly-supervised-lung-cancer-growth-pattern-prediction/results/models/baseline_model/checkpoint.h5\n",
      "Epoch 00018: saving model to /mnt/netcache/pathology/projects/pathology-weakly-supervised-lung-cancer-growth-pattern-prediction/results/models/baseline_model/last_epoch.h5\n",
      "Epoch 20/20\n",
      "3/3 [==============================] - 19s 6s/step - loss: 0.6942 - categorical_accuracy: 0.5000 - val_loss: 0.6942 - val_categorical_accuracy: 0.5000\n",
      "Epoch 00019: val_loss improved from 0.69423 to 0.69417, saving model to /mnt/netcache/pathology/projects/pathology-weakly-supervised-lung-cancer-growth-pattern-prediction/results/models/baseline_model/checkpoint.h5\n",
      "Epoch 00019: saving model to /mnt/netcache/pathology/projects/pathology-weakly-supervised-lung-cancer-growth-pattern-prediction/results/models/baseline_model/last_epoch.h5\n",
      "\n",
      "Epoch 00019: reducing learning rate to 0.003333333258827527.\n",
      "Evaluating model in directory: /mnt/netcache/pathology/projects/pathology-weakly-supervised-lung-cancer-growth-pattern-prediction/results/models/baseline_model/eval with content 0\n",
      "Loading test set ...\n",
      "FeaturizedWsiSequence data config: {'data_dir_luad': '/mnt/netcache/pathology/projects/pathology-weakly-supervised-lung-cancer-growth-pattern-prediction/results/mini_tcga/tcga_luad/featurized', 'data_dir_lusc': '/mnt/netcache/pathology/projects/pathology-weakly-supervised-lung-cancer-growth-pattern-prediction/results/mini_tcga/tcga_lusc/featurized', 'csv_path': '/mnt/netcache/pathology/projects/pathology-weakly-supervised-lung-cancer-growth-pattern-prediction/data/test_slide_list_tcga.csv'}\n",
      "FeaturizedWsiSequence using 4 samples and 1 batches, distributed in 4 positive and 4 negative samples.\n",
      "Predicting batch 1/1 ...\n"
     ]
    }
   ],
   "source": [
    "# Train CNN\n",
    "\n",
    "#selected_fold = 0\n",
    "\n",
    "featurized_dir = {'data_dir_luad': featurized_luad_dir, 'data_dir_lusc': featurized_lusc_dir}\n",
    "csv_path = {'csv_train': csv_train, 'csv_val': csv_val, 'csv_test': csv_test}\n",
    "\n",
    "train_model(\n",
    "    featurized_dir=featurized_dir,\n",
    "    csv_path=csv_path,\n",
    "    fold_n=0, \n",
    "    output_dir=result_dir,\n",
    "    cache_dir=None,\n",
    "    batch_size =4,\n",
    "    epochs=20,\n",
    "    delete_folder=True,\n",
    "    occlusion_augmentation=False,\n",
    "    lr=1e-2,\n",
    "    patience=4,\n",
    "    elastic_augmentation=False,\n",
    "    images_dir=None,  # required for GradCAM\n",
    "    vectorized_dir=None,  # required for GradCAM\n",
    "    shuffle_augmentation=None\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aplying GradCam\n",
    "\n",
    "Here we get the folder separetely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:00<00:00, 24193.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradCam will be apply to this dataset!\n",
      "Csv file sucessfully exported!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>slide_id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>TCGA-05-4244-01Z-00-DX1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>TCGA-05-4245-01Z-00-DX1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>TCGA-05-4249-01Z-00-DX1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>TCGA-05-4250-01Z-00-DX1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>TCGA-05-4382-01Z-00-DX1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>TCGA-05-4395-01Z-00-DX1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>TCGA-05-4396-01Z-00-DX1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>TCGA-05-4397-01Z-00-DX1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>TCGA-05-4398-01Z-00-DX1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>TCGA-4B-A93V-01Z-00-DX1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  slide_id  label\n",
       "0  TCGA-05-4244-01Z-00-DX1      1\n",
       "1  TCGA-05-4245-01Z-00-DX1      1\n",
       "2  TCGA-05-4249-01Z-00-DX1      1\n",
       "3  TCGA-05-4250-01Z-00-DX1      1\n",
       "4  TCGA-05-4382-01Z-00-DX1      1\n",
       "5  TCGA-05-4395-01Z-00-DX1      1\n",
       "6  TCGA-05-4396-01Z-00-DX1      1\n",
       "7  TCGA-05-4397-01Z-00-DX1      1\n",
       "8  TCGA-05-4398-01Z-00-DX1      1\n",
       "9  TCGA-4B-A93V-01Z-00-DX1      1"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('GradCam will be apply to this dataset!')\n",
    "csv_path_luad_feat = join(data_dir, 'slide_list_featurized_luad.csv')\n",
    "data_to_csv(featurized_luad_dir, csv_path_luad_feat)\n",
    "pd.read_csv(csv_path_luad_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradCAM in directory: /mnt/netcache/pathology/projects/pathology-weakly-supervised-lung-cancer-growth-pattern-prediction/results/models/baseline_model/gradcam with content 0\n",
      "Computing GradCAM on TCGA-05-4249-0 ... 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/scipy/ndimage/interpolation.py:611: UserWarning: From scipy 0.13.0, the output shape of zoom() is calculated with round() instead of int() - for these inputs the size of the returned array has changed.\n",
      "  \"the returned array has changed.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing GradCAM on TCGA-05-4397-0 ... 2/10\n",
      "Computing GradCAM on TCGA-4B-A93V-0 ... 3/10\n",
      "Computing GradCAM on TCGA-05-4250-0 ... 4/10\n",
      "Computing GradCAM on TCGA-05-4244-0 ... 5/10\n",
      "Computing GradCAM on TCGA-05-4398-0 ... 6/10\n",
      "Computing GradCAM on TCGA-05-4396-0 ... 7/10\n",
      "Computing GradCAM on TCGA-05-4382-0 ... 8/10\n",
      "Computing GradCAM on TCGA-05-4245-0 ... 9/10\n",
      "Computing GradCAM on TCGA-05-4395-0 ... 10/10\n"
     ]
    }
   ],
   "source": [
    "# for layer in model.layers:\n",
    "#     print(layer.name)\n",
    "# Apply GradCAM analysis to CNN on LUAD data\n",
    "\n",
    "# Apply GradCam on layer 1\n",
    "gradcam_on_dataset(\n",
    "    data_dir=[featurized_luad_dir, featurized_lusc_dir],\n",
    "    csv_path=csv_path_luad_feat,\n",
    "    model_path=join(result_dir, 'checkpoint.h5'),\n",
    "    partitions=0,\n",
    "    layer_number=1,\n",
    "    custom_objects=None,\n",
    "    cache_dir=cache_dir,\n",
    "    images_dir=dir_luad_wsi,\n",
    "    vectorized_dir=vectorized_luad_dir,\n",
    "    output_dir=gradcam_dir,\n",
    "    predict_two_output = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_gradcam(gradcam_images):\n",
    "    %matplotlib inline\n",
    "    rows = 3; columns = 5;\n",
    "    fig, axs = plt.subplots(rows,columns,figsize=(20,8))\n",
    "    axs = axs.ravel()\n",
    "    n_images = rows * columns\n",
    "\n",
    "    for idx in range(n_images):\n",
    "        img = plt.imread(gradcam_images[idx])\n",
    "        if idx == 0: print(f'Images shape: {img.shape}')\n",
    "        axs[idx].imshow(img)\n",
    "        prefix = os.path.basename(gradcam_images[idx]).split('_')[0]\n",
    "        subfix = os.path.basename(gradcam_images[idx]).split('_')[-1]\n",
    "        axs[idx].set_title(prefix + '_' + subfix)\n",
    "        axs[idx].set_xlabel(prefix + subfix)\n",
    "        axs[idx].get_xaxis().set_visible(False)\n",
    "        axs[idx].get_yaxis().set_visible(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images shape: (400, 400, 4)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABGMAAAHUCAYAAACeWuVuAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nOzdeZhcR3n4+291zz7SaLdkSZZkW95XjMEGjE2CAxizBMySgANmiQj8EsgN+S33sjkB57IlOIRwwcTBgG0w+xIDAQO2I2ObyBvebdnWbu27NGt33T/qjNRq9cy0pFF3a+b7eZ5+ZrrP0nV6zttV856qOiHGiCRJkiRJkmojV+8CSJIkSZIkjScmYyRJkiRJkmrIZIwkSZIkSVINmYyRJEmSJEmqIZMxkiRJkiRJNWQyRpIkSZIkqYZMxqgqIYQrQwjX17sc0pEkhLAshHBxvcshqbasM6WDY70pNSZj8/AYMRkTQthZ8iiGELpLnr81W+fEEMJ3QggbQwjbQgi/DyH8TQghny1vCSF8NITweAhhVwhhdQjhZyGEl1V4v1tDCFtCCK1VlO2lIYTHQgi7Qwi/CSHML1l2XQihr6z8+Sr2eUIIoae0ERVCuDSEsDiEsDWEsDaE8G8hhIkVtp0aQtgQQlg8xL4/GkKII53IIYS3hBCWZ5/VD0MIU0cqt8YX43J8x2UI4Yqhjkf1ZWyO79hU4zI2x3dsWm82LmPT2BzPsTliMibGOGHwAawAXl3y2g0hhOOBu4GVwBkxxknAG4FzgcGT6LvAa4G3AVOAY4F/Bi4tfa8QwgLgxUAEXjNcuUII04HvAx8BpgJLgJvKVvt0afljjIWRjhf4V+C/y16bBHwCmA2cAswBPlNh208Bjw5R3uNJn8uzw715COE04MvAnwEzgd3AF6sod9VCCE2juT/VnnEJjLG41NhgbAJjLDatM8cGYxMYY7GpscHYBIzN8SvGWPUDWAZcXPba9cDNw2xzMdANzK1i/x8F7gD+CfiPEdZdBPy25Hln9j4nZ8+vAz5xgMf3J8C3gSuB64dZ7/XAg2WvvRC4E3gHsLjCNj8HXlnpMyxb7x+AG0ueHw/0ARNHKPs5wH3ADuA7pC+LT2TLXgKsAv43sBb4BumL6j+ADcCW7Pe5Jfs7Frgt298vgS+UfibABcBvga2kL8crstcvzcqxPXv9ypJtFpC+/N6RLdsC/AXwPOD32b6+MMwxXgd8KSvPjqx880uWx2x/T2b7+lcgZMvywD8CG4FngL/M1m86kHOkER/GZUPH5TLgb7PzexspLttKlr8KuD87X38LnFmy7P8AT2Xn+iPA67LXTwF6gAKwE9ha8tl+EfhZ9vodwCzg6izWHgOeM9L+s2VXZNt/ISv3Y8BLhznOCLwfeDqLsc8AuZJ9LQY+m5XjGeCSkm2PBW7PynELKW6H/DsfSQ9js6Fj0zpznNaZ2fEZm7FhY3MZ1ptXYL1pbBqb4yI2R2POmItJ2cjhlt8dY1xVxb7eBtyQPV4eQpg5zLqnAQ8MPokx7iL9EU4rWed9IYTNIYR7QgiXDffGIYQu4O+Bv6minBcCD5dsmyf9gQcbK+X7fiPQG2P8aRX7Lj+up0gBcuIwZW8BfkA6cacC3wReV7barGzZfNKXSw74avZ8HunL5Qsl698I3ANMBz4OvL3k/eaTguNfgBnA2aTgA9hF+jtOJjUy3xtC+OOyspwHnAC8mRRUHyKdJ6cBbwohXDTUsQJvzcozPXvPG8qWv4rUUD0TeBPw8uz1Pwcuycp6DlBeprHGuKxzXJZ4E/AK0hf0maQvckIIzwH+HXgPMI10leLHJd1mnyJdvZkE/B1wfQjh6Bjjo6R/oO6M6SrM5LL3+jApPnpJlfa92fPvkhofDLf/kuXnZetMBz4GfH+EbqyvI12lOod0deqdZft6PNvXp4FrQwghW3Yj8LvsM7iSdKVmLDM2rTOtMxuTsWm9ab3ZmIxNY3PMxuZoJGOmMXx3qOmkK0vAnrFuW0Ma79dT8voFpEbOt2OM95A+sLcMs98JpOxWqW3s7a72eVLj5ShS97LrQggvGmZ/HweuHSmQQwh/RGpkfbTk5feTvgTuqbD+RFIG8gPD7bfESMdVyflAE/D5GGN/jPH7pBOhVBH4WIyxN8bYHWPcFGP8Xoxxd4xxB3AVcFFW5nmkxtlHsvVvB35Ssq+3ALfEGL+Zvd+mGOP9ADHGW2OMD8YYizHG35MaueUNxY/HGHtijL8gNUS/GWNcH2NcDfwX8JxhjvXmGOPtMcZeUoP0BSGEY0qWfzLGuDXGuAL4DakhCSmg/znGuCrGuAX45DDvMRYYl/WPy0GfjzGuiTFuJsXR4Dm5CPhyjPHuGGMhxvg1UmVzPkCM8TvZdsUY402kq9fPH+G9fhBjvCfG2EP6Z7Mnxvj1mLrN3kRJbFWx//XA1VmM30SqePbp7lvmUzHGzVnsXQ38acmy5THGr2Tl+BpwNDCz5LvmozHGvhjjYuDHIxzjkc7YrH9sWmfuZZ25l7FZ/9gcZL1pvVnK2DQ2x2xsjkYyZlNWiKqWZwc2GXguUDpx0tuBX8QYN2bPb8xeI4QwL5RMjpQt3wl0lb1XF6lbEDHGe7MGz0BMWcIbSF2+CGlCpz0TQ4UQziZlVT833IGGEM7PyvWGGOMT2WuzSQHyoSE2uxL4RoxxWYX9vbikHIPZz2GPawizgdUxxtJM6cqydTZkJ/Pge3eEEL4c0uRN20ldqiZnmdfZwJaYMsCDlpf8fgzpC2w/IYTzQprgakMIYRsp2zm9bLV1Jb93V3g+YcgjLTmuGONOYHNW3kFrS37fXbKv2ez7mZR/PmONcVn/uBw01Dk5H/hg1mDYGkLYSoqt2Vk53hZCuL9k2ensH0vlqo6tKvZf/p2ynH1jrVxpTJWvu+cziDHuzn6dkK2zueS18v2MRcZm/WPTOnMv68y9jM36x+Yg603rzVLGprE5ZmNzNCaluwW4jNR9t5JfAX8VQpg7VCYwhNBOugqTDyEMHmArqaFzVozxAfZvbDzMvt2AO0lj3h6msggEgBjjJWXv/9eksdkrQuplNCEry6kxxnOydZ5Dym69M8b4q5LNn0/6Angk27YdaM+OYw7wUmBuCOF92fozgG+HED4VY/zUEMd1VknZjss+iyeGOC5I2eI5IYRQcqKVN/7Ku7R9EDgJOC/GuDb7krgv+4yeBaaEEDpLGpfzSvaxkqGzmTeSutFdEmPsCSFczcjBdiD2XNELIUwgdSNfU8V2zwJzK+1njDIu6x+XI1kJXBVjvKp8QUjDGr6SlfPOGGMhhHA/2WdFhS6qB6KK/cP+3ynzGD7Dfwx7/87zqD4up4YQOkoqL2PT2LTOHD3WmdUzNusfmyOx3rTerMTYNDaP3NiMhz6p0vGkKy2fAWZlry0kTbY0OXt+M2kG6vOAFqAZuDy9fYTU9WdzdrCzSh63A/84RFlmkLpUXQa0kWaXvqtk+RtIJ18OeBkp2/eSIfbVUfa+nyWNRZuRLT+dlI17c4VtW8u2/QBpxu/Bz2Ja2fKVpJmuJwxRltNIE/m9mDRR1PXAt0b4u7SQZh//K1KC7bWksX/7TEZYts2nSWPY20iNsx9QMjkfcFf2ObSQJh7cTjYBUfZ32kH6UmvKjvHsbNl64O3Z78/Png9ut6D0PbLXVpX+XbLj/fAQx3ldVo4LsnJ9DrijZHkEFpatP/gZvJcUVHNIY/N/WV6WI/WBcdmQcVnpb0PJhG2ksagrs88/ZPu9lNRN9FTShGYnkSbSfAcwALw72/YV2b5bKp3v2fN3A7eWPF8IDGS/j7T/K7LnH8jOizdmxz9tiOOMpMbQFFLF8xiwqGRfiyusv7Dku+bTpHPwBdn5M5YnIjQ2rTOtM41NY7PKvw3Wm/vFK9abg38bY9PYpIr9X0EDx+YhD1OKadKfF5AaDQ+H1M32e6SAGOzu9DrSnQeuJ82w/AxpUrnBieLeDnw1xrgixrh28EG6WvTWUOG2kjHGDaTguIo0m/F5pBmqB30AWJ2932eAP48x3jrEMewue9+dpHFpG7JVPkgKyGvLu3rFND68dNttQH/2OzF1XytdXiB1Z965X0HS+g+TuinfQGqUTQTeV2ndkm36SN3i3pUd7+Wkz7t3mM2uJmVWN5JOnJ+XLX8L6TPdTJro6Osl77eCNFv3B7Pl97M3w/o+4O9DCDtIYx2/PVzZhzPYta7s5Ruz8mwmdT+8vMrdfQX4BWkG8PuAn5ICs5pb0B1xjMv6x+VIYoxLSJNkfoH0WS0lmwgtxvgI6U4md5Iq5zNIM8EP+jXpH6W1IYSNHKAq9g+poj+B9B1xFanL7CaAEMKXQghfKlv/R6QJTO8nNYqurbI4byWdq5tIt3W8ieG/u45oxmb9Y9M6syrjqs4EY7MRYnMk1pt7WG8am8bm3vc+omNz8BaGGmNCCHcDX4oxfrXeZRktIYTrSFcrPzwK+7qE9PnMP+SCSWNMCOEK0hWFC6pcPwInxBiXjsJ73wQ8FmP82KHuS6qWdeaI+7LOlIZhvSk1pkaPzdGYwFcNIIRwUQhhVgihKYTwdtLtxsqv3I1bIYT2EMIrs89nDulK4Q/qXS5pvAshPC+EcHwIIRdCeAVpyMgP610ujW3WmcOzzpQal/Wm1JgOJjZHYwJf1UBIt8t6ZIjFp5LGyX2bNEbvaVL3q+FuAzfeBNJ9528izcB9M/veMk46YCPFZTY8QcObBXyfNOZ5FfDeGON99S2SjnTWmYfMOlOHhfXmqLDe1KgzNkfFAcemw5QkSZIkSZJqyGFKkiRJkiRJNdRww5RamjpiW+vkehdDdbJj97MbY4wz6l0O7W/ChMlx2rTZ9S6G6mTFikeNzQbV0tQR25sn1bsYqpPtPWuNzQZlvTm+WW82rrbOjtg52f83x6vNaxrn/82GS8a0tU7m/NPeU+9iqE5++d9XLq93GVTZtGmz+dCHvj7yihqT3vOe5xmbDaq9eRIvOP6d9S6G6uQ/H/4HY7NBWW+Ob9abjatz8mQu/YtF9S6G6uQbH/27holNhylJkiRJkiTVkMkYSZIkSZKkGjIZI0mSJEmSVEMmYyRJkiRJkmrIZIwkSZIkSVINmYyRJEmSJEmqIZMxkiRJkiRJNWQyRpIkSZIkqYZMxkiSJEmSJNWQyRhJkiRJkqQaMhkjSZIkSZJUQyZjJEmSJEmSashkjCRJkiRJUg2ZjJEkSZIkSaohkzGSJEmSJEk1ZDJGkiRJkiSphkzGSJIkSZIk1ZDJGEmSJEmSpBoyGSNJkiRJklRDJmMkSZIkSZJqyGSMJEmSJElSDZmMkSRJkiRJqiGTMZIkSZIkSTVkMkaSJEmSJKmGTMZIkiRJkiTVkMkYSZIkSZKkGjIZI0mSJEmSVEMmYyRJkiRJkmrIZIwkSZIkSVINmYyRJEmSJEmqIZMxkiRJkiRJNWQyRpIkSZIkqYZMxkiSJEmSJNWQyRhJkiRJkqQaMhkjSZIkSZJUQyZjJEmSJEmSashkjCRJkiRJUg2ZjJEkSZIkSaohkzGSJEmSJEk1ZDJGkiRJkiSphkzGSJIkSZIk1ZDJGEmSJEmSpBoyGSNJkiRJklRDTfUugCQ1ukWLzt3z+zXXLKljSSRJkqSDc8E5C/f8vvjepXUsicCeMZI0rNJETKXnkiRJUqMrTcRUeq7as2eMJFVg0kWSJElHOpMujctkjCSVMAkjSZKkI51JmMZnMkaSRuA8MZIkSTrSOU9MYzEZI0mZSr1irrlmyX6vm5yRJElSo6rUK2bxvUv3e93kTH2ZjJE07g01NGmopMuiRefut8w7LkmStC8vZki1NdTQpPKky6JLL89+wrXfW8xtj9xScR8maw4v76YkSWWuuWbJiA3GRYvOHbInjSRJ49Vwc685L5tUW4vvXbonoXLRqRdXXOddl13A1z9yZcVtdXjZM0bSuFapYXgoV/Iq9ZqRJGm8KB3eW6k+HG6ZpINXqVdM6WsFlpHvWQDA2z5+5X7rDiZrCizbs60JmcPLZIykcanaq3MH01g0ISNJGs+GqwMrzcUm6eBVe9eklFgZOrly2yO37Nd7xoTM4eUwJUnjzlA9X0obj/sPVcpR6StzqAalDU1JkirzgoU0OoaakLc0gVI6VCkJ2WP/fZXOHTPUe2j02DOmkYQAMda7FNK4Ut4grNxAbAPagT6gFxgAnJhQkqThlf6rMbDfUocsSaOnvAdLxR4tIZcexOz/zvSzPOEyOJypUnJGo8dkTKMIAYpFYnOeMFCsd2kkAdACdEL+eDgGWA7EtcAqYP/Go8kZqcYGL2KEdIUvhkAoWodK9ddCuogxCciTLmTsAPqBnj1rWU9KNTKYhGlrp6m1mYFYhEIf9PVCIbL4/qeguLdTQKFtGbC3V4xDlQ4Phyk1iGJTjtyOHrae0EnoL+xpWEoaPeV3QBq+EdgJLWfCK47nNe/6Phf9wffpe94u+ge6KBT2jU+HJEn1EfOBsLuHga42ih0t9M/ogELROlSqgcp1XxMwETiT/vlz6Lugk/6XtVM4fxocfRJwOilBM/S/INap0sguOGfhkLegHrxt9R4hT2jvpH36FI49eQYLTpzKjHmTmTJnKl1HTaR1agd0tUBTbtghSUPdjUkHz54x9RYCxeYcTU89y2P/z3Ec++O+fa/0OWxJGhUH3ribAufDC+bdzvTfreSXTxfY3l7gkcVbeNGLptNfWEdzy97GpFf3pNqKzXly23bxzJ/NpXkn7D46cvx3drL99Gl0PbgRmvL1LqI0plWu91qB6RSO3809Tz3FuSd3snTJes57zSw2zphF88o2uH8macjS3mG/kqo30hwu19x8/b4v5PO0drQyZWo7Mye28cTvN9M6axLrnupjwcld7Nq5m5aWJnb0FyGfY/GSJ/0ftEZMxtRTCMR8YMeCdnrOWchJ126m2NFCsa2J/LZuChPbCMaBNOoGG5BD95LJQX4WJ578CCevvI+fP7SeGzdcxuyZ93LRizbyy2fOZdKKwNkXFWhuzo+YiPHuStLoCj19rLx0Ns07JtM9r5+p/5kj15un56odrH1gAj2Tj2LGkq2Enn7I2wlYOhz2r9tagDn0T2vi0RX3MqNvKQ/9ZhZH75rIQzc8TNfcx5l30Yls230sPDEBWANspDwhY30pVW+wR0xpgibN9zLYUyZASysTp7UzfVorqx8vsru7mV2rdjO/uYP1TxbJ5fNMm9dMsVBk8ePLoDkH/cX9EjK3PXKLd1caZbZQ6ilGct39NO8uMvOObcR8uoo30NnM0o92kN+Rjam1u7VUE3uTMy1wNHT39/PJW6dx6/o/p+nJKbzjvp+w8ct3ceLJDzNAFz++dhvLHlhNf393tt3w3a4H918+XEpS9WIuR2HaRLpnFtnynAE6nmmmfW0vM+/cRsdft9CyLdAzI/D0myYzMH2Cw5akmplM/7FN/H7373j/1J9yQcvjzJ+4jWUxx5qBWeTp4bFrf0f7lJ/T/+oeOHYuMJ2h7lRoPSkdvD3JmRDItzXT2tnMM4/2MnvqFGZMmc3Zx0xi8uQWQh5oyrPq3sDEgSamTu+kfWpnSshUsOjSy/n6R67cs//y4VI6MCZj6m2wgZgD8un3YnOOY/6ticKk9v2HKtmglGqgCFvh+18LPFt8AYV1rZx/4lR2nRw55w9aeKp4PN3rdtPStooH79sNhRz9vRHoJHU4rG4svA1N6cCFQoFNp09g4glbmTp7G1MuXMuaF3fQPaeTbadNYcLKyK4T+pj4DGw6rZ3dx0+Bvv56F1saBzq5/6GlvGjmcgqPtnNey1SO2/YQJ8xcxtzOlbSt287c1vvovu/3LJiylP4TdgOzSD1qKnfWt56UDl0xRJY/uIEpE9ppb5/EWSfPomlgAm1TOmhuLpLb2cLE9h52rW9hSlsH7W1N0N6cepYO8b/noksv3ycJY0Lm4JiMqbPYlKNtXe+eEz0UIi1be2na0UcoxH0TMYO/Fxy7JB2oA+v23Ac7H2fSk5vZeO3jzJ+/jPu+eyf/65Nv5pft7+WC/mbau56hPT+B579gDj/+2mRuuR04/yRgPjC16neyoSkdoFyO7qMC7z7hDv7+lB/z6jkPcsorn2D+hx5j3R/30fKn62hb3kJ87SY2P3eAlq197F44jZizySONhsFeK/sN76WVSX/YRMf6R9nRNoEffHEL629ew+unPsJfvmETJ3Q9xfwtkde2F+m+5ut0//qLsLCJNM+MMydI1RpqmNCiSy9n0aWX73s76lgk9u2maXIvPet2MndKO+vv2cWjT3YTm5s547SpTO2ITG2dwfNPP46tT06iZ00LU2bPguZWyFcfmyZkDpwtkwaQ6y/sfRIjYaBIKMb9xukVOlqgWGTbKROJOXvISAfqmmuW7NN4HC5BUyzuoGPCAMecCnd/ayVds7bT1fIIx8zfxIpH13DyeS0sPDnP0w90Mue9XfztjTs598y7gCmkHjKSDosYadsc+ZeHXsKmgQn8+48uZvm/n8Cdt51G/uk2Nvz3TD781pv4/06/gQlPNTPrH5+h86Fn0y2v7V0qHSZFisV+Ovpm0nrqaaz51lpOmVNg4rRm5p42m/sfnUzuvLNpf/Ecnl65jVkntHPxn50ChbRteuzP+WOkyhbfu3SfpMyw87gMFAixmdYpgSfv3khzZw9NfbuY1JVnzfIdtB3dQ+vUnaxZ3cOsYyfx4lcuZEpXlogJldMF+00SrINiGvpIEiNPXj6Rk/51HcXJnd5tSRoF11yzpGLvlFwOCiu2wc48J18wkV19OZ5zzlx2rF/HvFMm0Nw8i65pA8w5+xRa/mw3Xc157tz9XGAtsOOA3l/SgWnfVGTLmk7uPX4B/XP72Dg1DznomLGLBf9zFx+ecRlzfxH4q6t+yPdOOYrw3GPI9QxYZ0qjrLSHTC7XTeGOPp4+ax5vet1ytq7Pcd4r5rKtdwtLj30r+Tu6KNBL8XWRWCjS8rsOeGYTsIuhkjGSqnft9xbzrssuAFIvmcX3XpkWFCPda7azrauJM0/KM1Bs5nlHz2HT1o3satvKjm09xFikfUakc1In/eub2bB2B/T2QrEw9BuWcWLfA2cyphFVSrLESPfMVk760kYK0yfuP4RJ0qgoTcz0XL6Q91z6K5Zu2MyFFy+gP0QmTZhCczapWT7fRD7fTbxnOncuuBDuAtgCVDc/hYkY6cCFnj66p+YIM3p4bNvM9GI+csyCjUx8Vx/FyRM59ao17Dr9aH508dnkzppE2N1nrxjpsBtg9nFH8eTajdz7+82cccYc+mfsYvvsE8nf1QUrdpNngPzKLogAfaS7KZmIkQ6HPcOGWvLkO+GWn6xk+cqdnHb6LDb3baOQL7BrYx/du3ogQm/cya6+SFOA3i3dUCiQBeuITMQcHJMxDSjmA2Gg7MQPgc7V3RQntJqIkQ6zwSRJX38357/+aFbfu53mqScSpnXSvLUDCg8B2d3OeBYe6oWHmoGtpCt8kg6X2N7KzF8/y5bTZvEHZz7BiV3reXjr0bS+v43Y1UyIkTihnfbVO4hdnYQBhydJtdFN3AAnveIMznh2AtOnRp49bQG3xVfBo9uBVcAAxMF/PwZICZnKvGAhHbrF9y6FphxxQuDoUydzVC5P6Gpmx87Aqq1Fdm3rge4BiBB7dtG3tTdFZWEAYuVeMQ5RGj0mYxpJCITefjafNoVpD2wjNu07Ri8UokOTpFFSzcS5Lc3t9Pf3cvRzj2XrWS28/ZzvcX/zhay5ZjqwhnQ1ryf7vfJ7DNWYtJEpHaQYibnA5McCk16+m+a2Ak9dPpXiUR17L1aEsDcJY50p1Ug3LYVu+u/oZM3/uJD1m9dz52N/TOtdbcAT7E28DJ2AGWQdKVVvsAfMuy69oPIKhUjozbFlx07Wz9/Iji2Bnuad9PX3pnAsAsTUE6ZQOQFzwTkLWXzv0oqJGHvFHDyTMY0iBGJIk/nunBuYdl+R/eZXtkEp1Vxzcyv9fTlmTJpEd/MsdjIB6MZu1VIdtTQz7cHdfOt/vpJQgPZp21PyRVIdFYGtNG+dyD3LX0jz9A5a7wPielIvGEl1ESP0Fyn05Vi1ZRtdTa3Q3cfA7n4oFql2KJJGn8mYRhEjIUKxs5W5t+4mtvinkRpFc8suuH0tv7n9j4CdwOqqt63UA8crftKha9rWQ357b3rixQqpZoaa+D4lY7YBu2i+dQLpouJOSi6976N0H9aL0qG75ubrWXTp5ZUXDhRhZz9be7ayde1OCM0wMFBxgt6LTr14z++lt8mudOtqe8UcGv/jbzQhkOvpd3y71FAGSEOR1pMalHuv8FUz3GmQjU1pFMVIMAkj1cXQ9VmRlHzZPOS2g/WmdaI0+oadzyVG6B+A/gKEbLhg3Jso/fpHrtxvH5USMGASZrSYjGk02Vh3SYdX+ZW9kZMqgw3M/fczlANJ1EiSdKQZrEsPJLEyuK5JGWl0LL536T5JkwvOWbinl8ye21vvo/LNYN728bTuYM+YkXrF6NCZjJE0bpU3CAeNRm+X8n3Y2JQkjUVDD1uqvO7BbCdpeIM9VUqTJtfcfP2e3i4juebm6/fs47ZHbtlnqFJ5IsZeMaMnN/IqkqRqLVp0rokYSdK4Uk09V2kd60fp8KrmNtSV1rntkVu44JyFJmIOM3vGSBr3hrs6N1JDcaSrejY0JUnjgfWdVH/lQ5Zgb7JlpETKSEORTMSMPnvGSBKpEVmpITlUsqVSD5hK+5QkSZJqZfG9SysmToZKtlTqAVNpnxp99oyRpBKVeskczJh2EzGSJEmql0q9ZA5mIl4TMYePPWMkqcyhJFKG6mEjSZIk1dKhJFKG6mGj0WPPGEmqQnmCpVJvGZMwkiRJamTlCZZKvWVMwtSGyRhJqqD8ttcmXyRJknSkKb/ttcmXxmEyRpKGUTqHjMkXSZIkHYlK55Ax+dIYTMZI0ghMwkiSJOlIZxKmsTiBryRJkiRJUg2ZjJEkSZIkSaohkzGSJEmSJEk1ZDJGkiRJkiSphkzGSJIkSZIk1ZDJGEmSJEmSpBoyGSNJkiRJklRDJmMkSZIkSZJqyGSMJEmSJElSDZmMkSRJkiRJqiGTMZIkSZIkSTVkMkaSJEmSJKmGTMntn6EAACAASURBVMZIkiRJkiTVkMkYSZIkSZKkGjIZI0mSJEmSVEMmYyRJkiRJkmrIZIwkSZIkSVINmYyRJEmSJEmqIZMxkiRJkiRJNWQyRpIkSZIkqYZMxkiSJEmSJNWQyRhJkiRJkqQaMhkjSZIkSZJUQyZjJEmSJEmSashkjCRJkiRJUg2ZjJEkSZIkSaohkzGSJEmSJEk1ZDJGkiRJkiSphkzGSJIkSZIk1ZDJGEmSJEmSpBoyGSNJkiRJklRDJmMkSZIkSZJqyGSMJEmSJElSDZmMkSRJkiRJqiGTMZIkSZIkSTVkMkaSJEmSJKmGTMZIkiRJkiTVkMkYSZIkSZKkGjIZI0mSJEmSVEMmYyRJkiRJkmrIZIwkSZIkSVINmYyRJEmSJEmqIZMxkiRJkiRJNWQyRpIkSZIkqYZMxkiSJEmSJNVQiDHWuwz7CCFsAJbXuxyqm/kxxhn1LoT2Z2yOe8ZmgzI2xz1js0EZm+OesdmgjM1xr2Fis+GSMZIkSZIkSWOZw5QkSZIkSZJqyGSMJEmSJElSDZmMkSRJkiRJqiGTMZIkSZIkSTVkMkaSJEmSJKmGTMZIkiRJkiTVkMkYSZIkSZKkGjIZI0mSJEmSVEMmYyRJkiRJkmrIZMw4EEJ4OITwknqXQ9LoCiFcGUK4vt7lkI40IYRlIYSL610OSbVlvSkdHOvNw+OQkjEhhJ0lj2IIobvk+VuzdU4MIXwnhLAxhLAthPD7EMLfhBDy2fKWEMJHQwiPhxB2hRBWhxB+FkJ4WYX3uzWEsCWE0FpF2V4aQngshLA7hPCbEML8kmXXhRD6ysqfr2KfJ4QQekq/xEMIl4YQFocQtoYQ1oYQ/i2EMLHCtlNDCBtCCIuH2PdHQwhxpJM8hPCWEMLy7LP6YQhh6kjljjGeFmO8daT1dOQw9g4t9kIIC7J4Ky3HR0YowwHHnsYfY3N8x2YI4YowRD2v+jI2x3dsqnEZm+M7Nsd7vXlIyZgY44TBB7ACeHXJazeEEI4H7gZWAmfEGCcBbwTOBQZPsO8CrwXeBkwBjgX+Gbi09L1CCAuAFwMReM1w5QohTAe+D3wEmAosAW4qW+3TpeWPMRaqOOR/Bf677LVJwCeA2cApwBzgMxW2/RTw6BDlPZ70uTw73JuHEE4Dvgz8GTAT2A18sYpya4wx9oBRiD1gckk5Pj7Um9ci9kIITaO5P9WHsQmMsdjU2GBsAmMsNq03xwZjExhjsakDEGMclQewDLi47LXrgZuH2eZioBuYW8X+PwrcAfwT8B8jrLsI+G3J887sfU7Onl8HfOIAj+9PgG8DVwLXD7Pe64EHy157IXAn8A5gcYVtfg68stJnWLbePwA3ljw/HugDJlb7t8nK/53sb7MDeBA4Efi/gfWkL7qXlWz7DlLQ7wCeBt5Ttu//RUoirQHeTfpyW5gtawU+S/piXQd8CWgfooxXkr5Ib8re617grLJj+Fvg98C2bL22asox1h/G3oHHHrAgO0eaqizDwcbeOcB92Tn9ney8/US27CXAKuB/A2uBb5AaEP8BbAC2ZL/PLdnfscBt2f5+CXyh9DMBLgB+C2wlxfIV2euXZuXYnr1+ZYXP4h3Zsi3AXwDPy+JtK/CFYY7xOlJs/zIr123A/JLlMdvfk9m+/hUI2bI88I/ARuAZ4C8P5O/S6A9js6FjcxnD1ymvAu7PztnfAmeWLPs/wFPZ+f4I8Lrs9VOAHqAA7AS2lny2XwR+lr1+BzALuDqLt8eA54y0/2zZFdn2X8jK/Rjw0mGOMwLvJ9XfG0mN+1zJvhaT6uktWQxeUrLtscDtWTluIcXukH/nI+lhbDZ0bFpvWm8am40Zm8uw3ryCUa43D/ecMReT/sEebvndMcZVVezrbcAN2ePlIYSZw6x7GvDA4JMY4y7SH+i0knXeF0LYHEK4J4Rw2XBvHELoAv4e+Jsqynkh8HDJtnnSH3/wy7J8328EemOMP61i3+XH9RQpeE6sYttSr2ZvBXYf8J+kXlJzSMf55ZJ115OCq4sU/J8LIZyTlf0VpM/kYmAhqZIs9cmsbGdny+eQvgSH8lpSxTsVuBH4YQihuWT5m4BXkE70M0kBUU05xiNjb4TYyywPIawKIXw1uwIylAOOvRBCC/ADUoUyFfgm8Lqy1WZly+aTKv0c8NXs+TxSpf+FkvVvBO4BpgMfB95e8n7zSZXWvwAzSHF3f7Z4F+nvOJnUwHxvCOGPy8pyHnAC8GZSZfch0nlyGvCmEMJFQx0r8NasPNOz97yhbPmrSI3UM0lx/PLs9T8HLsnKeg5QXqaxyNisc2yWGKpOeQ7w78B7gGmkOvHHJV3anyJdWZ0E/B1wfQjh6Bjjo6R/oO6M6crk5LL3+jApRnpJDep7s+ffJf1jwHD7L1l+XrbOdOBjwPdH6GL+OtIV5HNI9ew7y/b1eLavTwPXhhBCtuxG4HfZZ3Al6SrqWGZsWm9abzYmY9N6c8zWm4c7GTON4YfeTCdltoE94+C2hjQWsKfk9QtIX7LfjjHeQ/ow3zLMfieQMl+ltrG3K9vnSV+eR5G6nl0XQnjRMPv7OHDtSEEeQvgj0pd8acLh/aQviHsqrD+RlJ38wHD7LTHScVXrv2KM/xljHCAlP2YAn4wx9gPfAhaEECYDxBhvjjE+FZPbgF+QTnZIQfLVGOPDMcbdpJNu8NgCqZL8v2KMm2OMO7Jj/ZNhynVPjPG7WTn+CWgDzi9Z/vkY45oY42bgJ6SKaNhyjGPG3jCxR8p0P490bM/NylfeECp1MLF3PtBEOm/7Y4zfJ31BlyoCH4sx9sYYu2OMm2KM34sx7s5i5irgouwY52Vl/ki2/u2kOBj0FuCWGOM3s/fbFGO8HyDGeGuM8cEYYzHG+HtSA7e8kfjxGGNPjPEXpEboN2OM62OMq4H/Ap4zzLHeHGO8PcbYS2qMviCEcEzJ8k/GGLfGGFcAv2Hf2P3nGOOqGOMWUgJ3rDM26x+bg4aqUxYBX44x3h1jLMQYv0ZqCJ4PEGP8TrZdMcZ4E+nq9fNHeK8fxBjviTH2kP7Z7Ikxfj2mLu03URJfVex/PXB1Fuc3kRqF+3TFL/OprB5eQfqH8U9Lli2PMX4lK8fXgKOBmSXfNx+NMfbFGBcDPx7hGI90xmb9Y9N6cy/rzb2MzfrH5iDrzVGuNw93MmZTVsCqlmcHPZl0IpVOqvR24Bcxxo3Z8xuz1wghzAslExZly3eSenKU6iJ1GSLGeG/2hTsQU4+UG0jdwQhpsqc9k0aFEM4mZVw/N9yBhhDOz8r1hhjjE9lrs0nB86EhNrsS+EaMcVmF/b24pByDmdFhj+sArCv5vRvYGPeOcezOfk7IynFJCOGuLOu7lTScajDbOpvUPXNQ6e8zgA7gnuwLcStpONaMYcq1Z/sYY5HUFXV2yfK1Jb/vHizjCOUYr4y9YWIvxrgzxrgkK8c60pWGl4UQJo5i7M0GVscYS69glJ+bG7JKZvBYOkIIXw5pUrXtpK6Ok7MrIrOBLTFdmRm0vOT3Y0gNi/2EEM4LaeK5DSGEbaSrEOVXTcq/F8qfT2BopbG7E9iMsTsUY7P+sTloqPNyPvDBwborq7+OITunQwhvCyHcX7LsdPaPp3JVx1cV+y//XlnOvvFWrjSuytfd8xnEdDGDrCyzgc0lr5XvZywyNusfm9abe1lv7mVs1j82B1lvjnK9ebgnvroFuIzUfbCSXwF/FUKYO1SWMITQTsoC50MIgwffSvqiPSvG+AD7f9k9zL7dEDtJ4+EeprIIBIAY4yVl7//XpLF4K0LqgTQhK8upMcbB4TrPIWW+3hlj/FXJ5s8nfTk8km3bDrRnxzEHeCkwN4Twvmz9GcC3QwifijF+aojjOqukbMdln8UTQxzXIQmpa9n3SF36fhRj7A8h/JDssyJlqeeWbFKa0d9ICpTTsisE1dizfQghl+17TRXbDVeO8crYGyb24v4TrA1+QedijP81xHEdaOw9C8wJIYSSCqC84Vfe1fSDwEnAeTHGtVnlfR/pM3oWmBJC6CxpWM4r2cdKhr7KcCOpe+slMcaeEMLVjFwJHojS2J1A6kJu7FZmbNY/NkeyErgqxnhV+YKQhjV8hVR/3xljLIQQ7mdvvThU9/GqVLF/2P97ZR7DX307hr1/53lUH5tTQwgdJQ3LsR6fxmb9Y9N6c2TWm/szNvcvB1hvHhn1Zjy8Ey4dT8r0fgaYlb22kDQR0+Ts+c2k2anPA1qAZuDyVLQIqVvQ5uyDmFXyuB34xyHKMoPU3eoy0lCXTwF3lSx/A+nEzAEvI2UCXzLEvjrK3vezpHFqM7Llp5MydW+usG1r2bYfIM0GPvhZTCtbvpI0O/iEIcpyGmkisReTJpG6HvjWgfxtKJswipSlXVbyvIkUFHNJ3dUKpG6ZgTRGdTd7J1K7hHTinZJ9Tl9j3wl8/5k0SdVR2fM5wMuHKOOVQD8po9xEGk+5DGiudH6VHsdI5Rjrj/LPxtirKvbOIzXecqQ4vAn4zTCf8QHHXvaZrgD+KjunX0sak7vPRIRl23yaNH69jdQw+wElk7IBd2WfQwtp0sHtJXEwL/s835S93zTg7GzZeuDt2e/Pz54Pbreg9D2y11aV/l2y4/3wEMd5XVaOC7JyfQ64o2T5PrFIyYR3wHtJld0c0rj8X5aX5Uh+YGw2ZGxW+tuwb51yLqk+Po9U93WSujNPBE4lTTZ4EmkizXcAA8C7s21fke27pdI5nz1/N3BryfOFwED2+0j7vyJ7/oHsvHhjdvzThjjOSPpHZQqpUfgYsKhkX4srrD9Yh99F+k5qAV6QnT9jeQJfY9N603rT2DQ2q/zbYL25X7xyEPXmYR2mFNOEQC8gfWk9nHXz+x4pWAa7Qr2ONPP59aTZl58hTWo1OFHV20nzgayIMa4dfJCy1W8NFW5rF2PcQAqcq0gzHZ/HvnOVfABYnb3fZ4A/jzHeOsQx7C57352kMWsbslU+SArWa8u7gcU0PrV0221Af/Y7MXVtK11eIHWn3LlfQdL6D5O6Sd5AqhQmAu+rtO5oiGns7ftJCZUtpHGVPy5Z/jPSeMnfAEtJJyCkMYKQZrtfCtwVUtfRW0iBUtodcF7JW/6INAnaFtKER6+Paf6Ykco5UjnGHWNv+NgDjiMNm9sBPEQ6V0rHg5aX5YBjL8bYR0ouvis73stJn/dw5+XVpCseG0nn8c/Llr+F9JluJk1A9vWS91tBGkb4wWz5/ey98vE+4O9DCDtIY5C/PVzZhzPY5bXs5Ruz8mwmdQu+vMrdfYU0D9XvSVcyf0qqMKu5NeQRydisf2yOJMa4hDRJ5hdIn9VSskkKY4yPkO5kciep4XwG6S4Ng35N+kdpbQhhIweoiv1DaoSfQPqeuIrUnX0TQAjhSyGEL5Wt/yPSBKb3k/5hubbK4ryVdK5uIt1y9SbGcL1qbNY/Nq03q2K9aWxab+773kd0vTl4mzTpkIUQTiF9CbTGNDnwgWx7JSmrWG1ldFjKIR1OIYS7gS/FGL9a77KMlhDCdaQrlR8ehX1dQvp85h9ywaQxKIRwBelq3wVVrh+BE2KMS0fhvW8CHosxfuxQ9yVVy3pzxH1Zb0rDaPR683BP4KsxLoTwuhBCawhhCqn73k/qkQBplHJIpUIIF4UQZoUQmkIIbyfdBrD8qt24FUJoDyG8Mvt85pCuEv6g3uWSBCGE54UQjg8h5EIIryANGflhvculsc16c3jWm1LjOph602TMGBDKZgAve8wbeQ+H5D2kLm5PkbpIvvcwv1+jl0PjSBWxdxLwAKkL6wdJ3SKHuz3jeBOAvyN1ab0PeJR9b+UoHZQ614tjxSzgVlJ3+s8D740x3lfXEumIZ715yKw3dVhYb46KA643HaYkSZIkSZJUQ/aMkSRJkiRJqqH9Zo6ut+nTp8cFCxbUuxiqk3vuuWdjjHFGvcuh/bU0d8a21sn1LobqZMeuNcZmg5owYXKcNm12vYuhOlmx4lFjs0G15Npje1NXvYuhOtnev97YbFDWm+NbI9WbDZeMWbBgAUuWLKl3MVQnIYTl9S6DKmtrncx5p7+n3sVQndxy98eMzQY1bdpsPvShr4+8osak97znecZmg2pv6uKFM/9k5BU1Jv181eeNzQZlvTm+NVK96TAlSZIkSZKkGjIZI0mSJEmSVEMmYyRJkiRJkmrIZIwkSZIkSVINmYyRJEmSJEmqIZMxkiRJkiRJNWQyRpIkSZIkqYZMxkiSJEmSJNWQyRhJkiRJkqQaMhkjSZIkSZJUQyZjJEmSJEmSashkjCRJkiRJUg2ZjJEkSZIkSaohkzGSJEmSJEk1ZDJGkiRJkiSphkzGSJIkSZIk1ZDJGEmSJEmSpBoyGSNJkiRJklRDJmMkSZIkSZJqyGSMJEmSJElSDZmMkSRJkiRJqiGTMZIkSZIkSTVkMkaSJEmSJKmGTMZIkiRJkiTVkMkYSZIkSZKkGjIZI0mSJEmSVEMmYyRJkiRJkmrIZIwkSZIkSVINmYyRJEmSJEmqIZMxkiRJkiRJNWQyRpIkHfEWLTqXRYvOrXcxJEmSqmIyRpIkHdFKkzAmZCRJ0pHAZIwkSTpiVUq+mJCRJEmNzmSMJEk6Ig2XdHHYkiRJamQmYyRJ0phlQkaSJDUikzGSJGlMMyEjSZIajckYSZI05pmQkSRJjcRkjCRJGhdMyEiSpEZhMkaSJI1J11yzZL/XTMhIkqRG0FTvAkiSJA2nUgKlUqLlQPZ3KNtLkiQdKpMxkiSpIZUnYUoTKNUkVErXsUeMJElqJA5TkiRJDWe0kyfliRuTM5Kk8cI6rzGZjJEkSQ3lwBuNncB0YAoH0unXxqkkaaw7kLrOerG2TMZIUjVyAXKB/M5eYt6vTulwGW5oEgDF7GcBigNQoImB/hNg6gIKbQuALkzISA0kZ50p1cuiRefurTeLg/UmDPR3QGESBVoxJVA/fvKSNJJcgGIk193PE++cStPW3Xtfl1RThdjHPb/YwtIHN7D0wc1seHQdueYiP/n6f/HQfWsoFPrqXURJJWKfMSnV00BxF9/97ErWr96Z1ZsbyTXDT669k4d+t856s45MxkjSSIoRcoFiezMnXruJgckdexI0kkbXSHO75PMtPPdlU1h49gxOfM5UZp0ygxyrefWrzuKsU9rI5wfYexlQUt2EAM1N7HjRsVAo1Ls00rjV1NTJG/72GI46ZkJWbx5FjjyvXnQhZz3/GPL5lnoXcdwyGSNJ1ShGKEYKk9oJhaKJGOkwOrDbTheBTcBSYCXQw4EkY7zFtXSYxAj9A3TduRzy+XqXRtIeRWAXsDX76QWMejEZI0mSGk6lJMnw87sUOdAGpYkYSdJYNnQ9VwTsSVpvJmMk6UDYI0aqq4OZcHfRonNHnhhY0uHhBL5SXVnfNa7qbzcgSZLUIKptXFZK3tgwlSSNJ4P13kgXNKwfa8tUtSRJajhDNRgPtaFoQ1OSpP1ZP9aePWMkSdIR42CGKUmSpL1MvDQGkzGSJKlhHEyypdLtsMu7ZNvwlCQpsW5sDCZjJElSQxitXi+ljUsbmpIkqRGZjJEkSQ3pmmuW7NPLZSiHa34ZSZKOZOU9YCrVi6V1qPVmbZmMkSRJdXcot54ernFZTTJHkqSxqJr6b7ihvjq8vJuSJEmqqwNLxLQBs4HjgSlU05RZtOhcJ/6VJI0Lleu7HKkfRkf2aGK4+tM6szZMxjSQgb5unn1oNd/+3K/ZtmwTA/3d9S6SNH7lAjGfI+ZzkAv1Lo2kPbpgwmw4dgpwDNCSvV59k8ZGplQDwbpTagw5oB2YDMzJHl3Za0MPlLGuPPxMxjSAgf5uegZ28eufreDZTQO0TTiKJb/exi3XreWOW5bVu3jS+JMLFJvzbD69gy0nd1Bszte7RNKYVn136ByFwkwGXtHDrD98Eua2kBqTLZRf5Rtqn6XDlySNomKR2NtLcfokCrOnsfnFxxB7eyGXg2Kx3qWTxq1CIc/AwDwKM4+G10yCSyfB0cdBOAWYSqpDTQvUg3PGNIBCMbL6me3knxrg4b7VdE1oZ1f3VjauKnD6MXPYumUn7RObaW1qrXdRpfGhGGna0UvL9lYmPbyV2N5MzAdidpUvxAjFWOdCSmNL6WS9w08muINwVwf39R/N7sVrmBhXkettZlcxx/yzJgB9QPrHr3zcu7fylA6jpiZ2Pn8eK18VCb05mnYEWrcdR9PuAmGgSMuyDRCtO6XDZeg6bjrhuYFpR93Hc3/+CyYO5Nl43lH8bt4p9K2+AFY1AZuBnj3be8GiNkyBNYAH71vJmod3cMycVqZ0zaC5uZWOuTM55rkTefy3q1m/ZhuP37WefoctSTVTbGui6+ldFCe0EPMBipFQyK7smYiRDouRkyRFYCM7H+mm744+dm1ZS2gP7Ig5iqELmIDDlaT6iH199E3Mke/s5+qXf4MTX7CM5X8Mqy9qo2X5RigU6l1EaRxKQ5R2Th/gqIGneWZxM8uXt9D+6HpODw/CfEh1Z/M+W11zzRIvXNSAyZgG8NyzjqOro4mNfZ20Tuuka1In00/p4fw3H8Ml7z6HlfcNsH1bgZ9+/hkGBnrqXVxp3Ihlw91DhN5prQSTMdJhNdgIrHR1bt3vVnD/z37LlIlPMmXiDrZsCjxwb2Dp8k76BmYBnVTT8dfhStLo65mSo9Cb5/9deglP3LmA5ol9zHjhs+w8a3a9iyaNW+t+1839v9rK9K5WFnQ10bGlyAMr1/LgwwP0TeqBpi5gYsVtrSMPL5Mxddbbu4vF/7GWnZOL5Of2sXvLRnYNDDA/3057Ls+UmT1s2zLAuqfzXPTnR+NUaFKNFGOauLeYhiSFmJIzwS7W0mE1UsOveWorx53QyZ2/Wc223fPZXTyRU5+/gDNeOJV8dyD1nhl5fgqv+EmjK3S0M/O/dzLrl81Ma9/N9AciXbd0MPGKbnon+S+HVB85mmd0cvq5RX77m5X0zBygb24fR/3BSUw99wzyAyHN60snpgZqz0+8znJFeGrFU0xs62DF3c+y8Lij2NK3m3U5IEAMgdNOhuln9DKhrY18U1u9iyyNfblAbM7vGY4U+ouE3n5ic562dd3EJr86pXpZuXI92wYCz3neGZzwrrVc+cav8so/uZEdJy6heHQfhUKk2ttdSxolxSJx+w6e/T/99HcGciGy5bJd7DomECdPZOPZgdjT6x2WpMNo/x6lOaCVlWEDk/sf54Ln5cmfH5nz2mZ29UWe+P16il09FAq99Sz2uOYEvnXW3N7Jqy47lYEQWPCnC+kdGOBYOll40hQIkaaWDk76o+M5qd4FlcaTYiQUC4QIhY4m1l7Yzs6T+zjlb55g+f84nXk3b6bY1ry354ykUVU+8W6poztmsDlMZN3W6cx97Fcs+UUkbl7Fa9+7nps3ncCx+Q4GJyEcbv+SRlE+T9+ZC+jpLrDjuQXar57P5PbAuhcW2LVwCsW2IqGj3Ql8pTo4un0G23PbWLJpIcuWFzkqtLDp6VU0HdXJqrt2cOz2ScAmqulVqtFlMqYBTJ47iWce3EHx6By//WkPr3n3bJrsASPVX4x0z2hh7i82U/zsY3x71V28+XkdFObOSMtNxEijovQOEINX9Ya6K8SzA7tpbW1m8qQ8T84/lcl/8FM23rWZXT3HM+/YGfDMupqXXxJ0T29mwu2tzLptE/QP8Nj7Z3Dy1evZcOEsTvq3rfUunjQOFYECzy7dTes9k9jZeSKrHt/MXUuKbJrQybxNM/nDGTOgsBbYN0a9+2BtmIxpAE1NreR37WLNY9u58CUd5Pz/TmoIsSnHxKU7KHa0EM49nde/+Wy2vqydaQ9sI7bk6108acwob+yVT9xb2lPmnAsHJ+ntoffBs3k2dx4rZu+i74luFk4F8t2MdHVvcF/2kJFGSYxMvms1k7q7CW3pguIpVy2D1haO+tUq6OuHnEN8pdrr4ZwLtwGd0L2Vo47eTtOcTlbcO5++DdugYynk+4GBehd0XDIZ0yCOu2Aq8/raaWppr3dRJA0qRgrtzYRCkdiUI9dXYOpD2ym2NdkrRqqbItANFGjKR4hF5s2cBKGdfH4D0MtwyZhKiR9Jo2BgICViBoci5fNQKKbnJmKkw27o3izdQD8ATfleiAPMO6cbAuTzA5QnYrxQUTt+MzYQEzFS49lz96RiJAaI+ZyJGKkGhk+SDAC7yee7yTf1km9aTz6/ElgP9FW9TxMx0ijK5fafE8Y5YqSaGbpOK5Lqxj7y+UC+qUi+qYd8voehesQMDhvW4WUyRpKGY+JFqpvBhmB1DcLqbmktSdJYNRrDcE3C1I7DlCRJUsMbqmFpo1GSpH2V1o2l9edwdeZwdzLU4WEyRpIkNbzySX2r3UaSJCXD1aPWmbXnMCVJknREsKEoSdKBKa07K82d5vww9WPPGEmSdMSo1GCsdKXPhqUkSclwCRnVjz1jJEnSmGJDU5IkNTp7xkiSpCNSeY8YkzCSJOlIYTJGkiQd0UzCSJKkI43DlCRJ0hFpMAmzaNG5B3ynJUmSpHqyZ4wkSTpi2StGkiQdiewZI0mSJEmSVEMmYyRJkiRJkmrIZIwkSZIkSVINmYyRJEmSJEmqIZMxkiRJkiRJNWQyRpIkSZIkqYZMxkiS/v/27jxMrqu88/j3rd7Vau2LZcuyvMkrxjbBC7ExBAdDGCYDIUzYHEiIIZmE7JmZZAARhwRIMksCmWDCkBBD2NeYLWYXGAfLrN6wvEiydln70lvVmT/ObanU6q5uLX2r1f39PE8/6q6699a5pXrr3vrVOedKkiRJKpFhjCRJkiRJUokMYyRJkiRJkkpkGCNJkiRJklQiwxhJkiRJkqQSGcZIkiRJkiSVyDBGkiRJkiSpRIYxkiRJkiRJJTKMkSRJkiRJKpFhjCRJkiRJUokMYyRJkiRJkkpkGCNJkiRJklQiwxhJkiRJkqQSGcZIkiRJkiSVyDBGtoaUZQAAIABJREFUkiRJkiSpRIYxkiRJkiRJJTKMkSRJkiRJKpFhjCRJkiRJUokMYyRJkiRJkkpkGCNJkiRJklQiwxhJkiRJkqQSGcZIkiRJkiSVyDBGkiRJkiSpRIYxkiRJkiRJJTKMkSRJkiRJKpFhjCRJkiRJUokMYyRJkiRJkkpkGCNJkiRJklQiwxhJkiRJkqQSGcZIkiRJkiSVyDBGkiRJkiSpRIYxkiRJkiRJJTKMkSRJkiRJKpFhjCRJkiRJUokMYyRJkiRJkkpkGCNJkiRJklQiwxhJkiRJkqQSGcZIkiRJkiSVyDBGkiRJkiSpRIYxkiRJkiRJJTKMkSRJkiRJKlGklJrdhiNExDZgbbPboaY5K6W0sNmN0NGszWnP2pykrM1pz9qcpKzNac/anKSszWlv0tTmpAtjJEmSJEmSpjKHKUmSJEmSJJXIMEaSJEmSJKlEhjGSJEmSJEklMoyRJEmSJEkqkWGMJEmSJElSiQxjJEmSJEmSSmQYI0mSJEmSVCLDGEmSJEmSpBIZxkwBEfF4RNzY7HZIOjYRcV9EPKvZ7ZB0ckXEqyNiVbPbIZ1qIuJrEfHaZrdDUrmm63GzYRgTEfvqfmoRcbDu71cUy6yIiI9GxPaI2B0RP4yI34uIluL+9oh4U0Q8FBH7I2JDRHw+Ip47wuN9LSJ2RkTHWA2PiOdExIMRcSAivhoRZ9Xd948R0T+s/S3j2Ob5EdEbEbfX3faCiFgVEbsiYnNE/ENE9Iyw7ryI2Fb/IoqI5RGRhrXjjWO04eURsbZ4rj4VEfPGavdEma5FMRVYu6dG7aaULkkpfW2s5XTqsPZOrPaK218bEWuKNnwhIk4/3v2Shlib07s2I+JZEfFEsx5fo7M2p3dtTncNw5iU0syhH2Ad8MK62z4QEecCdwPrgaeklGYDvwj8FDD0AvoY8PPAzcBc4Gzg/wAvqH+siFgOXA8k4D82aldELAA+AbwRmAfcA3x42GLvqG9/SqnaaJuFdwHfHXbbbODPgNOBi4AzgL8cYd23Aw+Mst05de24dbQHj4hLgHcDrwIWAweAvxtHu6UjWLuAtasmsPaAE6i9yD3F/py8//OAx4B/OcH9OiER0Xoyt6fmsDaBKVabmhqsTWCK1abHzWOQUhrXD/A4cOOw224H7miwzo3AQWDpOLb/JuBbwP8E/nWMZW8Bvl33d3fxOBcWf/8j8Gfj3bdinV8CPgKsBG5vsNyLgR8Nu+0ZwF3Aa4BVdbcvJxd76zjb8OfAB+v+PhfoB3rG8X/zB8APgd3kguqsu/8/AN8HdgHfBi6ru++/AY8Ae4H7gRcVt18E9AJVYB+wq+65/Tvg88Xt3wJOA/43sBN4ELhirO0X9726WP+dRbsfBJ7TYD8T8AbgUWA7+U2qUretVcBfFe14DHh+3bpnA98o2nEn+Y1w1P/nqfRj7U762r2x+H0l8NHi/2Yv8CNgBfDfga3kk5Dn1q37GvIBeW9RE68btu0/AjYBG4HXFvtzXnFfR1Er64AtwN8DXaO0cSX5JOfDxWPdCzx12D40ev8ZtR1T/cfaO67a+yvgXXV/n168Zs49nv1q0KZRjwkcrv9fLWrkG8XtHwU2F6/zbwCX1G1vPvAZYA/w78Ctw/brEuDfgB1Fzf1xcftVxfOwq6iTdwLtdesl4DeAh4u23kp+f/l28VgfqV9+2D6uxNq1Nk+92vxa8Tr/VvG6/RKwoO7+a4rX/y7gB8Cz6u4b8bhY99g18rnrvqL9KzlJx13gWcATwB+Tz1EfB14xxmvwv5PPjXcC7xuqv7pt/X7Rjk3Aa+rWnQ98lvwe8F3yh/hVjZ7XU+UHa3My16bHzQk4bp7onDE3Fg1udP/dKaXxdAu8GfhA8XNTRCxusOwl5DdgAFJK+8kf+C+pW+Y3ImJHRKyOiF9o9MARMQv4U+D3xtHOZwL31a3bQn4R/Cb5CR/J2oh4IiLeV6SRoxm+X4+QP9CtGEe7Xgo8j1wol5HDCSLiCuD/Aa8jv+jfDXymrmveI+SEeDbwFuD2iFiSUnoAeD1wV8pJ75xhj/U/gAVAH7kg7i3+/hj5DY5G26+7/+pimQXAm4FPROPhHS8iJ+FXkhPgXxm2rYeKbb0DeG9ERHHfB8mFPp9caK9q8BjTgbU7eWq33guBfyZ/q/M94IvkHoxnkPfz3XXLbiUHrbPIB+b/FRFXFvv2PPJzciNwHvnErt7birZdXtx/BvkEZTQ/Tz6gziPX0qcioq3u/tHef8Zqx3Rk7Y1dezHC75eOsu3x7NdIxnNMuIH8xcRNxd+fB84HFpGPeR+oW/Zd5C8wlpCPS4eOTUVX8zuBL5BPks8DvlzcXQV+l3zcuhZ4Dvkkst5NwNPIH0L/CLgNeCVwJvl5eVmD/bR2x8/anBy1CfBy8nFtEdBO/vBDRJwB3EEOH+YVt388IhYW6414XCwe+/nAxnS4B8PGYp2TctwtnEau5TOAXwZui4gLGuznK8j1fS75mPw/hm1rdrGtXwXeFRFzi/veBewvlvnl4mcqszYnR2163MxO6nHzRMOY+eT0ZzQLyGkYcGic267IY/16626/DjgL+EhKaTX5BfHyBtudSU6j6u3mcFe1v+Hwf/wbgX+MiJ9usL1bgfeOVcQR8bPkN7z6Dy1vIL8BrB5hle3A08n79rSifR8YYbkhY+1XI3+TUtqYUtpBTssvL26/BXh3SunulFI1pfRP5ADlGoCU0keL9WoppQ+TU8SrxnisT6aUVqeUeoFPAr0ppfen3DXvw8AVQwuOY/tbgf+dUhoo7n+IYV0Kh3l7SmlHSmkduTdOfTGtTSm9p2jHP5GLe3FELCP/P7wppdSfUlpFTmKnM2t38tRuvW+mlL6YUhokHwgWAm9LKQ0AHwKWR8QcgJTSHSmlR1L2dfK3h9cX23kp8L6U0n0ppQPkgyYARUB5C/C7RS3tJffs+aUG7VqdUvpY0Y7/CXRSvIcURnv/GbUd05i117j2vgC8NCIui4iuYr0EzBjlIY659o7hmLAypbQ/pXQQIKX0/1JKe1NKfeTX8lMjYnZxkvwLxfb2p5R+TD4GDfkPwOaU0l+nlHqLbdxdbHN1Suk7KaXBlNLj5A9+NwxrxztSSntSSvcBPwa+lFJ6NKW0m3yiewWjs3bHz9pscm3WeV9K6SdF7X2Ew6/LVwKfSyl9rjiv/DfyEIufgzGPi6M5WcfdIW9MKfUV999BrqXRvDOltL6ov7dy5DntAPCnxfnx58i9eS6oe795c0rpQErpfo58v5mKrE2Pm1P2uHmiYcyT5A+847q/OPGfQ/5wUz9p0i+Tn6Ttxd8fLG4jIpZF3cRIxf37yKl0vVnk7kSklO5NKT1Z/Cd9jvwh6sXF9j5ft71XRMTl5ATrfzXa0Yi4pmjXS1JKPyluO51cHH8y0joppX0ppXuKdmwhp5nPjYieiLi+rh1DyWfD/RrD5rrfD5ALDfKbzu8Xb0q7ImIXORU8vdiHmyPi+3X3XUp+U2tkS93vB0f4e+ixx7P9DSml+oR37VDbRrG+wbKHnoOiCCjacjqwo+624duZjqzdyVO79YbX0vZ0ePzxweLfmcU+PD8ivlN8I7OLfDI6VFunc+RrvP73heQD9Oq6uvxCcftoDq2fUqqRu0+PWHsc+f7TqB3TlbXXuPbuJPeS/Di5O/DjRRufOJ79GsV4jwmHbouIloh4W0Q8EhF7inZBrrmFQCtHH5+GnEk+6T9K5Ekp/zXyhI17yMHo8GPwuI+5jfbB2h2Ttdn82hzS6Jz2F4ed015H8f8yxnFxNCfruAuwM+VeBkNO5Jz2ySIgGjL0PIz0fjPV69PabH5tetw87KQeN090cp07yanW+0a5/8vAb0XE0tFSwCLBeynQEhFDO9cBzImIp6aUfsDRT9h91HXJi4huche/+xhZouiylVJ6/rDH/x3yOLd1kUe0zCzacnFKaajL/xXk9O9XUkpfrlv9KnLx31+s2wV0FftxRjp6Eqeh0KGSUvrmKPv11Lq2nVM8Fz8ZZb/GYz3w1pTSW4ffEXnm7PeQu3fdlVKqRsT3Ody9bbShG+Myju0DnBERURfILKNxr5UzOfz/vIw8Jm8sm4B5ETGj7k3kzPHuxxRl7U7+2h1V5GGGHyd3t/10SmkgIj7F4draBCytW6X+9b6dfCC6JKW0YZwPeWj9iKgU2x5v7Y3WjunK2huj9lJK7yJ3XyYihrru/ziltPMk7BeM/5hQfwx8Obnr8o3kE8rZ5HkeAtgGDBbbeLBYflnduusZvefZ/yUPjXhZSmlv8dy+pEHbj5W1O37WZvNrcyzrgX9OKf3a8DvGcVw80XPasbYPMDciuusCmWXkb+VHU19X4z2nHXq/Wcrhc4ypXp/WZvNr0+Pm2I7ruHmiPWPeDDwjIv4yIk4DiIjzIuL2iJiTUvoS8FXyWKurI192rI0ju/r8J/LYr4vJ3XwuJ481+yb5DW8knwQujYhfiIhOcnesH6aUHiza8JKImBkRlciXNHslo3/Av438Ahx67L8ndyu8qdjWpeRvjX8rpfTZYet+nlxYQ+u+ifziuLwIHq6OiAuKdswnd2f7WspdpEbyAeCFkb957yaPK/xEysMIjtd7gNcXbYmI6I58+bQe8oRNiVwQRMRrOHJ84RZgaUS0H+djj7V9yF373hARbRHxi+T/+8812OYfRsTciDgT+G3GMft3SmktuRvryuI1eC15jPB0Zu1O/tptpJ18ErENGIyI5wP1l2/8CPCaiLgoImaQu88Ch1L+95DHui+CPA4/Im5idE+LiBdHnh3/d8hDHb8zjnaO2o5pzNprXHudEXFpcbxaVjzW/ylOKI95v0ZynMeEHvLr/klyz7I/r9telXxlipURMSMiLubIORz+FVgSEb8TER2Re9hdXbfdPcC+iLgQ+PUx2nGsrN3xszabXJvjcDv5WHtT5G/dOyNfsnopYx8XtwDzI2L2cT72WNsf8pbitXE9eajFRxts879ExNLIcyX+CeM7px3+fnMho7+2pgpr0+PmlD1unlAYk/IkldeSXyD3RcRucmp8D4e7Or2I/ITeTp71+DEOT1gF+Yl/X0ppXUpp89APeZKiV8QIl8ZKKW0jJ6RvJSdsV3NkevbbwIbi8f4S+LWU0tdG2YcDwx53H3kOlG3FIr9P7kr13hg2NCHlMaH16+4GBorfAc4hF9ZecjLeR4MJg1Ie1/Z68ge7reQX2/AJiY5JSuke4NfIz+dOYA3FREMpjzP9a/IEvFuAp5BnGB/yFXJKujkitnOMxrF9yJeqO5/8bf1byd3yngSIiL+PiL8ftvyngdXkq0PdAbx3nM15Bfm1+iR54rcPk/8/piVrd/LXbiNFyPMG8hv/TvK3D5+pu//z5ADpq+SaHzqIDL3m/+vQ7ZG7eN4JXABHdNWt/4bi08B/Lh7rVcCLUx5LO1Y7x2rHtGPtjVl7neQu2vvIEwXeRYMTmnHs12iO9ZjwfnIX6g3kq58MPzH7TfK3j5vJV9g49A1uUa8/Sz5x3UyeO+3Zxd1/QK7fveSQ9LgvL2rtnhhrc9LU5qhSSuvJ37T/MTkUWQ/8IbnX6ljHxQfJl/t9NPIQp0bDh0Z67IbbL2wu7ttIPh94fd0H9z+OiM8PW/6D5HlnHiUPyfizcTbnN8m9DDaTJx/+F6xNa9Pj5jGbDMfNSEdM1yGVJyJeDbw2pXTdOJdPwPkppTUn4bE/DDyYUnrziW5Lmuwi4iJyqNSRjhyDPp51V5Ivy/fKZrZDmkhT8Zhg7UrliYhnkS/zu3SsZYvlHyefA995Eh777cBpKaWpflUlTSIeN8fc1riOmyc6TEk6JUTE0yPi3KIr4fPI36x8qtntkiZKRLyo6No5F3g78NlmfIiaLO2Q6nlMGJu1K01OEXFh5CvnRERcRb709Seb3S5NbR43x3Y8x03DmFNADJsJe9jPsrG3IOA04GvkLnx/A/x6Sul7TW2Rprwm1+7ryEOmHiGPkz7ZY2pPtXZommlQe9fjMWE8rF1NiDFqU2PrIc+3sZ88ROOvyUMrpBPicfOEHfNx02FKkiRJkiRJJbJnjCRJkiRJUomOmjm62Tq7Z6TuOXOa3Qw1yY6Nm7anlBY2ux062oIFC9Ly5cub3Qw1yerVq63NSaq9dUbqajveq7XqVLend7O1OUnNnDknzZ9/TBft0RSybt0D1uYk1V7pSl2tPc1uhppkz8C2SVObky6M6Z4zhxe8/pZmN0NN8s9vesvaZrdBI1u+fDn33HNPs5uhJokIa3OS6mqbzbXn/kqzm6Em+eJ9f25tTlLz55/On/zJ+5vdDDXJ6173dGtzkupq7eEZC/9zs5uhJvnCxndOmtp0mJIkSZIkSVKJDGMkSZIkSZJKZBgjSZIkSZJUIsMYSZIkSZKkEhnGSJIkSZIklcgwRpIkSZIkqUSGMZIkSZIkSSUyjJEkSZIkSSqRYYwkSZIkSVKJDGMkSZIkSZJKZBgjSZIkSZJUIsMYSZIkSZKkEhnGSJIkSZIklcgwRpIkSZIkqUSGMZIkSZIkSSUyjJEkSZIkSSqRYYwkSZIkSVKJDGMkSZIkSZJKZBgjSZIkSZJUIsMYSZIkSZKkEhnGSJIkSZIklcgwRpIkSZIkqUSGMZIkSZIkSSUyjJEkSZIkSSqRYYwkSZIkSVKJDGMkSZIkSZJKZBgjSZIkSZJUIsMYSZIkSZKkEhnGSJIkSZIklcgwRpIkSZIkqUSGMZPUdVeex3VXntfsZkiSJEmSpJPMMGYSqg9hDGQkSZIkSZpaDGMmmZHCFwMZSZIkSZKmDsOYSaRR6OKwJUmSJEmSpgbDmFOMgYwkSZIkSac2w5hTkIGMJEmSJEmnLsOYU5SBjCRJkiRJpybDmFOYgYwkSZIkSacew5hTyKp71xx1m4GMJEmSJEmnltZmN2A6GilAGSloOZbtncj6kiRJkiSpPIYxJRoewtQHKOMJVOqXsUeMJEmSJEmnJocplaRReHLDxTce8/aGBzeGM5IkSZIknRoMY0pwzEFMtEClDSqtEIf/i255wSuP+3EkSZIkSdLkYBgzwRoNTbrh4hshFX/U8k8tKtRaO2mZ2Q1dXVCpHBHIHOvjSZIkSZKkycUwpsmqtX5Wf2knWzfsY+uGA+zbtIdoq/HDbz/CxnW7qdUGm91EaVpavXoL31u1nh/ctZnqQB//8EdfosYA//i2+/jqHQ82u3mSJEmSTmFO4DvBVt275ojeKsN7rrS0tPO057ZT7dzNom0zgIDBQS656kyo1aCvH1JCUrme9rTFh35PtT5e/RfPpDowyCv/4FxaWzub2DJJkiaHW275KW677Z4j/q5Xf58k6UiGMSUYHsg0lqB/AAYGiyFMxxbEeIlr6eSLSkd+s2xpdkskSWq++tBleABzrNswsJE0XTlMqSQjhSTVzsdHXyElDGIkSZJ0qmoU1BjCSJru7BnTZNXOx2npXX5M64zUy8YgRpIkSRNlPMHKSMvU3zbSckNDnUZaTpKmMsOYSeDr998JjHKZ6zq33XG7QYwkSZJKNdZQpKFAZXiIMny90bYz0nIGMpKmOsOYkow2Z8x4g5Sv33+nQYwkSZJKdbxzwsDRPVzGs6363jMGMpKmMsOYJqsPWH71BdcBuQdMo+UkSZKksjUKR44laJEkGcZMuOMJUYbmkBkavnTdlecd6gEztD17xEiSJGkiNXMel/p5ZAxxJE1FXk1pAp2s3iz1wcuqe9cYxEiSJGlC1QchzQpDGk0MLEmnOnvGlGjVvWuO6OUyNGHvUA+YVfeuBA6HONddeR63vOCVh9a/+daV5TVWkiRJ09JYV0UayXgCm2MJVUaab8YeMpKmEsOYCTK8V8xIvVmGQpjhjuwJs/KI7b3/jSsNZSRJkjQhRhoadLKCkGPZxmiBkIGMpKnCYUoToFEQU9/TBYCoQEs7tHVCaxtUKhDRcPvvf+NKJ/SVJEnSSVUfxIw9X0yF/L1u/ceJdqAbmF38PpJ2oLPB/eNroySd6gxjmq3SQnR10dozA2Z2QVcrtAa0NA5l6kMdgxlJ0nSTKp7CSCfTaEHMyFrJgcoccvjSTv5Y0QUsApYUv4+03jzgDGABx9tJ30BGGoeUGv891rrHsryOi2cyE2D8E+wGtbZWuhZ0sODMWZx21mksWDKfjnndxKx2aDscyIy2zfr5ZSSdPIODBxkc6GVwoLfZTZGmtVSpQP/AkV9QDFbZ9ZQ5R98Oh/+u1mBgsLyGSlPA+IYAdQJnQ8vFsHw5cAE5lKkAs6F1PsydCfTUrVMp1uuBpUvh2XPhvNPJQU5n8e9cxgpnmjmZsHTKSAlaWkiDg6TBav69VqO2dx+DZy2iesYCBs5eTOruOipwSYNVUq2W163WDm9PE8I5YyZI/WS99RPxHjXfS2uis72DGWkWy9oX0DFjgC2D29hY282eeQfo3bkfBqpQS1x35XncfOvKQxP/eplraQKlxMM/2U7nYB9d7V3sr3XQRT/7dvey4hnnNLt10tQXQRzoJc2awY6rFzPv7i3Q0Z5PCttamfvdur/rpJYAgsH53Rxc1E7Pw7uJwVoOafr6R1xHUjb2nCydwKX03LKDJdxPL+088P6lfP8Ta1mwcC+Llu9n96Mb6TpjId3VJ/jUv9zHVT+/jBVnLeBgawtBC8zeR+vpwY8/s4G5j+zimx9P3PCH57DwZ7rovKcHeAKoNWyngYw0gqEQpq+PtHgem244i84dNWZsHqB3QRs7Lg76Th9g1o/aOXjNfnq+ehqduxKzv/wTorMTKhUGly9m/9JOOncMkgJaBmq0PbiBGGMaDR0fw5gJNHZIkoAq/YMDVPprtAzOYGYP7OsfYH6llf5Uo3fvwfztXu3wiePQxL/De8PUX6lJ0ol5+DM7WHhxN/t7EoPRRdveQZ7cUWXuuYub3TRpaouAlIg9+3n418/k/H/YxLzv144MUVJqGKrEYI227fto25rysN+UYLDK+hctYdmH1pF6Zhx6HEnZ2MOTKkAbLIIVPEwHvfyQp/Dl96zhyqfOZNa5Nbq7g7s+9QT9d2/gtIV9rLigi53rN/P4QDDjzB7mdFaoPlxh/30HefRv97P0pw9yze8sZdvsJzlzxXy4Z0bxOI3DGEkjaGmhtms3/VdfyIYbOuhbNMjuBAvP2kO1FtR+NJ+2rW0cvGY/Zy7cyYEX7aOtpcqe6vlsfBZ0bGshLttD7f4Knds72Lesxqw1wZI1rVCzJieCYUwJVt27hpbeVcDRgcnex/azd2ML510zl662Kvv2JR5Zv4u+CsTSdqKzLXcRGzy6AG55wSu57Y7bD213pO1LOj6zV/Swfe0ulpy9iGpXjU99di+d7Tu5vq2DgdMqtLWNNBZe0glLCSKoLp7D+e9+gtrs7tyzZaTlRhDV4vYIaCm+yatUoFJh2UefoDZ7JlGrGcRIIxgKZIZ6nhx9ZaUqbIW77l3B3R/awJwf7Wb5ioc57fzTePTxXaz73j5SX2Lbtu08+1WX8+N/X8PlzziXwUoLa761nk/f/UOe+ozFzO2ey9UvepIP/e3D3PKrT2Ngxy4OPtJJF7swiJGOU7XKxtc+lf650L+gygUXbGDtk/M4Z86T3H3/ubSds5+ZM/rou2s+j13QSqWtxu9ecSdffMMlbFq3hNqiKtW+NlqB3RcP0rajhcXf2W0QM4EMYyZYw3AkgpbZ7SyaN4NHH9rBzAvOpFqpMHtJJ/0tA+wdCNpaW+ivjN0tbGg4lKSTY7BvkDVbBumbt5X7vnqAucv6mNfZxUFq+BFOmmApUTnQT61nlCBmjHVHvK1ag0olBzGSjkMN6AUegm+3cH7XAapP28yWx3rZsXcrTzx8kF07E+ddPoNnX/EUfvCZPew+2M6mh3rZtHkPnbO7Oe+ixVx09c/wla+u43zO5tfecgOPb/kyHVu30HrZy4CDDIUxIw1FGvsKT9I01trKnEcH2XVOK7WLDvLEF8+i/dqd7OrrorV7gOqmGexe2MItL/833vfANfQ92cUH1z2dzfcvojZnkK7vdtH9c5vZuK+Vc87dwvrvnpGPn5WKgcwEcQLfknz9/jv5+v13Hnlp60pw8EAf7e0tnHPBfFpnJS69sI0zFs+k/2ALlRlBLVXHvNQ1OIGvdLL1te7n8ms6WNTdyrIL57Bg0QJ6d1S4818fZ9OPdje7edK0ECfSe2WwSvT2A5DaWxlY1MOmm5aQ2lpOUuuk6agG7KW9fRennVHhjGVzWHbhPA7srtAyOIMVl81gz5bED1bvZtOWJ7nqBfPobTtI+7wODmw9yGCaz5XXvZuP3PRl3vaOj/KZr6zl/Oc9k95Ln8Xg2gAGmr2D0qmrWqX7rkdY+pkN8HA3Lf1Q+/Zc1j45j/OXbCUW9dE9s5f3/+QqatUKL73m39n84CJeeMM9dK5rp/N5W9nb28G8e1vZ9NWleUaNh9dCtdrsPZuy7BlTgka9Y2a3zaQ/Vdiwu8ae3VvoaO1h3/YDzO+u8uMt+0m1yN/mjbF9SSfXhjV7+c43trDkjBnM6+zhwmd2s7U9uHbJLPZ2OERJKsXxhDEpUevuYM+5M3nysuDsj+2hcqCPtr4BTrtzN7R56iM1MrzHyVg9UGbO72LW3E5e/ezFtK7optYzyAf/9hEGtle598sH6T6zndbeDi64aD6f+OSj7PjCo9zbcxbVd27lvIvm8/A7Buk5fTZdHZ1A/wTumTT1RVsb9PZxzl/8kLRiObsu7mHrshk88tBMqksGSN+fy8FLe6m01fjEv13LJVc/xqe/fzlnXLOZTQ8sYua6PM/awbP7Of+9A0TPzHF1DNDx8YxkAtRf5Who+NDQbe/9+KrDC6bEloP76N81yMz+4InoZ933O2ipDtDW1UnLzAoDTw7CwJFhzNDVlIbmi5F0stW44qdOZ8nSRTz00Gb2bO2npdLD3Z/dyex58KrntDW7gZKGi8jdqCOo7O9eyYsMAAAHDElEQVRjzur9zP1WP2lWd9HNugXaPKGUjsXwuWPqbxvyht945qHfe3dt4x/+6QEWnN7Cqi1VFpzfzbYH4KabL+dbn3iY1//BVdxz7U9z8b6vsH/OtWy5fTfPeMoC5vR2w+DDQOPL0Ts0SRqfSs9M2LaLeXduY+4n97H7P17G5jktPO9ld/GpB5/KU5Zu4LFvn8/jK+Zy0TkbWXP3Wcx9BKptcP3rvsvXnziPlv0QFQfSTCTDmAkwvBfM8PlcDvWUqSXOXNwFbS2QdtMyWKW/rZc9O2CQXcyb10alfwCqjb8ZHHo8e8hIJ8fgQB8zlnZy1pLE2U85h61rDpJmwBU/s4irrptFpcMDkzSpRMDAIAfOm8eMtXvybe1tpLZWGKyy6WcXc/rnN1Kb2Xnsc9BIOkKjy193zllIe9daAF7y6z3099aoPWsO+7cGl72wm/UPPEbt3h5WtT2Hhdd38cyXPUFXpZu2jTPhieqY25c0ThFQrRKVCjGrh7lfe4y532zhvr09nLP3B+x+9pXMrfTRdccB1r94OQMrBti7vJWWA/C5n1zCoo91Utm54dCk+poYhjElGZor5uZbVx4ZmlRreTweNSqpBv39zJrdClGhMlAtLml9OIwZ6hUzZKTgR9KJaS2ulNTWCnTAaZdUCIIly2dAVGht7WxuAyUdKSVoa2XGIzvzpayHbm5rgZYWFn5vP7UZBjHS8RoejgzvKTPaJbHbO9uBoGXePlKCRRfP5tP/vJ7Lr13E9764nacv2kV3P7AdxuoVI+k4DYUp1SrRM5PW2bNouW99/pzZ2kL3phodO1rZ/tMDvP2ZH+XNt7+C2f++DgYHDWImmGFMSW6+dSXvf+PKke8sZqc+dPrYPwgMvfCP7hXz9fvvHHEzBjHSxGhtdY4YadJL6YgghgjiQB+7r1jEnNVbSJ3tzWubNG0NArtp66yQJ/9t5edfvYLe6iyee3UnLa1n0f74QWArQ2HM8HBn9MtsSzomQ8N5a7U8/Kg4ZM794k9I/QPMWruCf3rL9Szf9SOYPau5bZ0mDGNKdPOtKwFo6V0OjBWcjDw0abQgRpIk1UkJOtqZ/YPtpK6O45sMWNIRRgpEhoYVjdY7JqvrlVap0lnZCXt6YE8rsPnI+yWVKjo7ic5OOu5bD21tVGb12CumJIYxTfD1++88NFSp/lLXt91x+6i9W264+EaqPF5G8yRJmhpS7oJtECOdHI0m9B07kBlSAw5y+DLWR15BaaQ5Y8a3XUnHpRilEZXK4ctYG8SUwjCmSYZP6gs5mGnpXTXi8vaIkSRJ0mRTH56MfwjRIOOZI6bRVZwk6VRnGNNEuRfM7Yd6x9x2x+20sPzQ/QYwkiRJmmxG6iFzMtkTRtJ0YBjTZKvuXcOqe1fW3XK4x0x9zxkn55UkSdJk0qi3ymiBylhXZhppuJO9YiRNRZWxF1GzGcRIkiTpVHIyApShcEaSpiJ7xkwiw+eQMYSRJEnSqW741Zca3T/S35I0FRnGTEKGMJIkSTrVjSdUMXiRNF0ZxkwiQ1dYGuohYygjSZKkU12jqyI5P4yk6cowZpIxgJEkSdJUVX8p7OEMYiRNJ4YxkiRJkibM8DljvHS1JHk1JUmSJElNZq8YSdONPWMkSZIklWIodBnqHWMII2m6MoyRJEmSVCpDGEnTncOUJEmSJEmSSmQYI0mSJEmSVCLDGEmSJEmSpBIZxkiSJEmSJJXIMEaSJEmSJKlEhjGSJEmSJEklMoyRJEmSJEkqkWGMJEmSJElSiQxjJEmSJEmSSmQYI0mSJEmSVCLDGEmSJEmSpBIZxkiSJEmSJJXIMEaSJEmSJKlEhjGSJEmSJEklMoyRJEmSJEkqkWGMJEmSJElSiQxjJEmSJEmSSmQYI0mSJEmSVCLDGEmSJEmSpBIZxkiSJEmSJJXIMEaSJEmSJKlEhjGSJEmSJEklMoyRJEmSJEkqkWGMJEmSJElSiQxjJEmSJEmSSmQYI0mSJEmSVCLDGEmSJEmSpBIZxkiSJEmSJJXIMEaSJEmSJKlEhjGSJEmSJEklMoyRJEmSJEkqkWGMJEmSJElSiQxjJEmSJEmSSmQYI0mSJEmSVCLDGEmSJEmSpBIZxkiSJEmSJJXIMEaSJEmSJKlEhjGSJEmSJEklMoyRJEmSJEkqkWGMJEmSJElSiQxjJEmSJEmSSmQYI0mSJEmSVCLDGEmSJEmSpBJFSqnZbThCRGwD1ja7HWqas1JKC5vdCB3N2pz2rM1Jytqc9qzNScranPaszUnK2pz2Jk1tTrowRpIkSZIkaSpzmJIkSZIkSVKJDGMkSZIkSZJKZBgjSZIkSZJUIsMYSZIkSZKkEhnGSJIkSZIklcgwRpIkSZIkqUSGMZIkSZIkSSUyjJEkSZIkSSqRYYwkSZIkSVKJ/j/rEECtKu1omwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 1440x576 with 15 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get gradcam images\n",
    "gradcam_images = sorted([os.path.join(gradcam_dir, f) for f in os.listdir(gradcam_dir) if f.endswith('.png')])\n",
    "\n",
    "# Plot images\n",
    "plot_gradcam(gradcam_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
