{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Neural Image Compression # \n",
    "\n",
    "Using local Data to test functionality with a few WSIs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Imports ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from os.path import join, dirname, basename, splitext, exists\n",
    "import os\n",
    "from preprocessing import create_csv\n",
    "from glob import glob\n",
    "import sys\n",
    "import shutil\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "\n",
    "import multiresolutionimageinterface as mri\n",
    "import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Data ##\n",
    "\n",
    "To demonstrate the functionality of NIC, we will need a set of whole-slide images (WSIs) with their respective slide-level labels. In this case, we will use the WSIs that can be found using the following pattern:\n",
    "\n",
    "These data was already reorganized, it is, all the tiff files are contained in one folder for each class. \n",
    "\n",
    "These are a small version of the TCGA dataset:\n",
    "\n",
    "`E:\\pathology-weakly-supervised-lung-cancer-growth-pattern-prediction\\data\\tcga_luad\\images_diagnostic`\n",
    "\n",
    "`E:\\pathology-weakly-supervised-lung-cancer-growth-pattern-prediction\\data\\tcga_lusc\\images_diagnostic`\n",
    "\n",
    "The data we are going to use is only the **diagnostic** data an no the **tissue** data. The mask are already given, but we will have to implementa script to create this masks that filter out the background.\n",
    "\n",
    "\n",
    "Because there is no slide-level csv file, we have to create one, this will be created after once we get the featurized wsi. FIle should be located at  from:\n",
    "\n",
    "`E:\\pathology-weakly-supervised-lung-cancer-growth-pattern-prediction\\data\\slide_original_list_tcga.csv`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessing import create_csv\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates csv from original data\n",
    "root_dir=  r'E:\\pathology-weakly-supervised-lung-cancer-growth-pattern-prediction'\n",
    "\n",
    "dir_luad =  r'E:\\pathology-weakly-supervised-lung-cancer-growth-pattern-prediction\\data\\tcga_luad\\wsi_diagnostic_tif'\n",
    "dir_lusc =  r'E:\\pathology-weakly-supervised-lung-cancer-growth-pattern-prediction\\data\\tcga_lusc\\wsi_diagnostic_tif'\n",
    "csv_path =  os.path.join(root_dir,'data/slide_original_list_tcga.csv')\n",
    "cache_dir = None  # used to store local copies of files during I/O operations (useful in cluster\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Preprocessing\n",
    "\n",
    "We need to create a csv file to point out the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_class_1 = sorted([(os.path.basename(file)).split('.')[0] for file in tqdm(os.listdir(dir_class1)) if file.endswith(ext)])\n",
    "files_class_0 = sorted([(os.path.basename(file)).split('.')[0] for file in tqdm(os.listdir(ddir_class0)) if file.endswith(ext)])\n",
    "labels1 = np.ones(len(files_class_1), dtype=np.int8)\n",
    "labels0 = np.zeros(len(files_class_0), dtype=np.int8)\n",
    "\n",
    "df1 = pd.DataFrame(list(zip(files_class_1, labels1)), columns=['slide_id', 'label'])\n",
    "df0 = pd.DataFrame(list(zip(files_class_0, labels0)), columns=['slide_id', 'label'])\n",
    "\n",
    "# conacatenate dataframes\n",
    "data = pd.concat([df1, df0], ignore_index=True, )\n",
    "data.to_csv(csv_path, index=None, header=True)\n",
    "print('Csv file sucessfully exported!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating main csv data files from original data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 10027.02it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 4996.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Csv file sucessfully exported!\n",
      "Files were read with shapes: (20, 2)\n"
     ]
    }
   ],
   "source": [
    "print('Creating main csv data files from original data...')\n",
    "create_csv(dir_luad, dir_lusc, csv_path, '.tif')\n",
    "\n",
    "# read files to check shapes\n",
    "df = pd.read_csv(csv_path)\n",
    "print(f'Files were read with shapes: {df.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Encoder network ##\n",
    "\n",
    "To perform NIC, we will need an encoder network to transform small image patches into embedding vectors. According to the paper, BiGAN produces the best unsupervised encoder and it is the one we will train here.\n",
    "\n",
    "Alternatively, a collection of pretrained encoders (the one used in the NIC paper) can be found in \n",
    "\n",
    "`./models/encoders_patches_pathology/*.h5`\n",
    "\n",
    "Remember that these pretrained encoders accept 128x128x3 patches taken at 0.5 um/px resolution (often level 1), except for the BiGAN model that takes 64x64x3 at 1 um/px (often level 2).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to train the BiGAN model, we will first extract patches from the slides in the `encoder` partition. We will sample 10K patches per slide, producing ~260K patches in total. We select 96x96 patches to perform crop augmentation during training later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%% \n"
    }
   },
   "outputs": [],
   "source": [
    "# Dont run this we, will train later the encoder but not now. \n",
    "\n",
    "from source.extract_patches import create_patch_dataset\n",
    "\n",
    "patches_npy_path = join(root_dir, 'results', 'patches', 'training.npy')\n",
    "\n",
    "# Extracts patches from whole-slide images and store them in a numpy array file\n",
    "create_patch_dataset(\n",
    "    input_dir=slide_dir,\n",
    "    csv_path=csv_path,\n",
    "    partition_tag='encoder',\n",
    "    output_path=patches_npy_path,\n",
    "    image_level=2,\n",
    "    patch_size=96,\n",
    "    n_patches_per_image=10000,\n",
    "    cache_dir=join(cache_dir, 'patches')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have extracted the patches, we can proceed to train the BiGAN model. We will use the hyper-parameters described in the NIC paper. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from source.train_bigan_model import BiganModel\n",
    "\n",
    "model_bigan_dir = join(root_dir, 'results', 'encoders', 'bigan', 'rotterdam1_96_noaug', '0.0001')\n",
    "\n",
    "# Trains BiGAN\n",
    "bigan = BiganModel(\n",
    "    latent_dim=128,\n",
    "    n_filters=128,\n",
    "    lr=0.0001,\n",
    "    patch_size=64,\n",
    ")\n",
    "bigan.train(\n",
    "    x_path=patches_npy_path,\n",
    "    output_dir=model_bigan_dir,\n",
    "    epochs=400000,\n",
    "    batch_size=64,\n",
    "    sample_interval=1000,\n",
    "    save_models_on_epoch=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beware that training this model is highly unstable, thus it can fail or collapse with ease. If this happens, restart the training. Selecting a checkpoint model is a manual procedure: check the generated images and loss values and avoid abnormal results. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Compress images ##\n",
    "\n",
    "Once we have a trained encoder, we can proceed with the WSI compression. I recommend running several `IDLE` instances of the following code in the cluster to speed up the lenghty process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before the actual compression, we need to vectorize the WSIs. This process extracts all non-background patches from the slide and store them in numpy array format for quick access. In this case, we will read 64x64 patches at 1 um/px resolution (level 2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vectorize_wsi import vectorize_images\n",
    "import os\n",
    "from os.path import join\n",
    "\n",
    "root_dir=  r'E:\\pathology-weakly-supervised-lung-cancer-growth-pattern-prediction'\n",
    "data_dir = r'E:\\pathology-weakly-supervised-lung-cancer-growth-pattern-prediction\\data'\n",
    "\n",
    "data_dir_luad = os.path.join(data_dir, 'tcga_luad', 'wsi_diagnostic_tif')\n",
    "data_dir_lusc = os.path.join(data_dir, 'tcga_lusc', 'wsi_diagnostic_tif')\n",
    "mask_dir_luad = os.path.join(data_dir, 'tcga_luad', 'tissue_masks_diagnostic')\n",
    "mask_dir_lusc = os.path.join(data_dir, 'tcga_lusc', 'tissue_masks_diagnostic')\n",
    "\n",
    "csv_path =  os.path.join(root_dir,'data', 'slide_original_list_tcga.csv')\n",
    "cache_dir = None  # used to store local copies of files during I/O operations (useful in cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already existing file TCGA-05-4244-01Z-00-DX1 - 9 images left\n",
      "Already existing file TCGA-05-4245-01Z-00-DX1 - 8 images left\n",
      "Already existing file TCGA-05-4249-01Z-00-DX1 - 7 images left\n",
      "Already existing file TCGA-05-4250-01Z-00-DX1 - 6 images left\n",
      "Already existing file TCGA-05-4382-01Z-00-DX1 - 5 images left\n",
      "Already existing file TCGA-05-4395-01Z-00-DX1 - 4 images left\n",
      "Already existing file TCGA-05-4396-01Z-00-DX1 - 3 images left\n",
      "Already existing file TCGA-05-4397-01Z-00-DX1 - 2 images left\n",
      "Already existing file TCGA-05-4398-01Z-00-DX1 - 1 images left\n",
      "Already existing file TCGA-4B-A93V-01Z-00-DX1 - 0 images left\n",
      "Finish Processing All images!\n"
     ]
    }
   ],
   "source": [
    "# Vectorize LUAD WSIs\n",
    "\n",
    "vectorized_luad_dir = join(root_dir, 'results', 'tcga_luad', 'vectorized')\n",
    "\n",
    "vectorize_images(\n",
    "    input_dir=data_dir_luad,\n",
    "    mask_dir=mask_dir_luad, \n",
    "    output_dir=vectorized_luad_dir, \n",
    "    cache_dir=cache_dir, \n",
    "    image_level=2, \n",
    "    patch_size=128\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already existing file TCGA-33-4538-01Z-00-DX3 - 9 images left\n",
      "Already existing file TCGA-52-7812-01Z-00-DX1 - 8 images left\n",
      "Already existing file TCGA-60-2721-01Z-00-DX1 - 7 images left\n",
      "Already existing file TCGA-77-8007-01Z-00-DX1 - 6 images left\n",
      "Already existing file TCGA-77-8009-01Z-00-DX1 - 5 images left\n",
      "Already existing file TCGA-77-8139-01Z-00-DX1 - 4 images left\n",
      "Already existing file TCGA-77-8143-01Z-00-DX1 - 3 images left\n",
      "Already existing file TCGA-77-A5G1-01Z-00-DX1 - 2 images left\n",
      "Already existing file TCGA-NK-A5CR-01Z-00-DX1 - 1 images left\n",
      "Already existing file TCGA-NK-A5D1-01Z-00-DX1 - 0 images left\n",
      "Finish Processing All images!\n"
     ]
    }
   ],
   "source": [
    "# Vectorize LUSC WSIs\n",
    "\n",
    "vectorized_lusc_dir = join(root_dir, 'results', 'tcga_lusc', 'vectorized')\n",
    "\n",
    "vectorize_images(\n",
    "    input_dir=data_dir_lusc,\n",
    "    mask_dir=mask_dir_lusc, \n",
    "    output_dir=vectorized_lusc_dir, \n",
    "    cache_dir=cache_dir, \n",
    "    image_level=2, \n",
    "    patch_size=128\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can compress the WSIs. Each WSI (vectorized file) will be processed 8 times due to WSI-level augmentation (rotation and flip). We will use an existing pretrained encoder from the NIC paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already existing file TCGA-05-4244-01Z-00-DX1_{item} - 9 images left\n",
      "Already existing file TCGA-05-4245-01Z-00-DX1_{item} - 8 images left\n",
      "Already existing file TCGA-05-4249-01Z-00-DX1_{item} - 7 images left\n",
      "Already existing file TCGA-05-4250-01Z-00-DX1_{item} - 6 images left\n",
      "Already existing file TCGA-05-4382-01Z-00-DX1_{item} - 5 images left\n",
      "Already existing file TCGA-05-4395-01Z-00-DX1_{item} - 4 images left\n",
      "Already existing file TCGA-05-4396-01Z-00-DX1_{item} - 3 images left\n",
      "Already existing file TCGA-05-4397-01Z-00-DX1_{item} - 2 images left\n",
      "Already existing file TCGA-05-4398-01Z-00-DX1_{item} - 1 images left\n",
      "Already existing file TCGA-4B-A93V-01Z-00-DX1_{item} - 0 images left\n",
      "Finish Processing All images!\n",
      "Already existing file TCGA-33-4538-01Z-00-DX3_{item} - 9 images left\n",
      "Already existing file TCGA-52-7812-01Z-00-DX1_{item} - 8 images left\n",
      "Already existing file TCGA-60-2721-01Z-00-DX1_{item} - 7 images left\n",
      "Already existing file TCGA-77-8007-01Z-00-DX1_{item} - 6 images left\n",
      "Already existing file TCGA-77-8009-01Z-00-DX1_{item} - 5 images left\n",
      "Already existing file TCGA-77-8139-01Z-00-DX1_{item} - 4 images left\n",
      "Already existing file TCGA-77-8143-01Z-00-DX1_{item} - 3 images left\n",
      "Already existing file TCGA-77-A5G1-01Z-00-DX1_{item} - 2 images left\n",
      "Already existing file TCGA-NK-A5CR-01Z-00-DX1_{item} - 1 images left\n",
      "Already existing file TCGA-NK-A5D1-01Z-00-DX1_{item} - 0 images left\n",
      "Finish Processing All images!\n"
     ]
    }
   ],
   "source": [
    "# Featurize images\n",
    "\n",
    "from featurize_wsi import featurize_images\n",
    "\n",
    "# Set paths\n",
    "model_path = './neural-image-compression-private/models/encoders_patches_pathology/encoder_bigan.h5'\n",
    "featurized_luad_dir = join(root_dir, 'results', 'tcga_luad', 'featurized')\n",
    "featurized_lusc_dir = join(root_dir, 'results', 'tcga_lusc', 'featurized')\n",
    "\n",
    "# Featurize LUAD data\n",
    "featurize_images(\n",
    "    input_dir=vectorized_luad_dir,\n",
    "    model_path=model_path, \n",
    "    output_dir=featurized_luad_dir, \n",
    "    batch_size=32\n",
    "    )\n",
    "\n",
    "# Featurize LUSC data\n",
    "featurize_images(\n",
    "    input_dir=vectorized_lusc_dir,\n",
    "    model_path=model_path, \n",
    "    output_dir=featurized_lusc_dir, \n",
    "    batch_size=32\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train CNN on compressed images ##\n",
    "\n",
    "Once we have compressed the WSIs, we can proceed with the CNN classifier. In this example, we will train a classifier targeting the binary label `HGP_SL` found in the CSV file. We will be training 4 models using cross-validation: in each fold, we will use 2 data partitions for training, 1 for validation and 1 for testing. At the end of model training, we perform inference on the test set, compute metrics, and run GradCAM on the images.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading training set ...\n",
      "FeaturizedWsiGenerator data config: {'data_dir_luad': 'E:/pathology-weakly-supervised-lung-cancer-growth-pattern-prediction/results/tcga_luad/featurized', 'data_dir_lusc': 'E:/pathology-weakly-supervised-lung-cancer-growth-pattern-prediction/results/tcga_lusc/featurized', 'csv_path': 'E:/pathology-weakly-supervised-lung-cancer-growth-pattern-prediction/data/train_slide_list_tcga.csv'}\n",
      "FeaturizedWsiGenerator using 11 samples and 6 batches, distributed in 4 positive and 7 negative samples.\n",
      "Loading validation set ...\n",
      "FeaturizedWsiSequence data config: {'data_dir_luad': 'E:/pathology-weakly-supervised-lung-cancer-growth-pattern-prediction/results/tcga_luad/featurized', 'data_dir_lusc': 'E:/pathology-weakly-supervised-lung-cancer-growth-pattern-prediction/results/tcga_lusc/featurized', 'csv_path': 'E:/pathology-weakly-supervised-lung-cancer-growth-pattern-prediction/data/validation_slide_list_tcga.csv'}\n",
      "FeaturizedWsiSequence using 5 samples and 4 batches, distributed in 4 positive and 1 negative samples.\n",
      "Building model ...\n",
      "Training model ...\n",
      "Training model in directory: E:/pathology-weakly-supervised-lung-cancer-growth-pattern-prediction/results/model2 with content 0\n",
      "Training model from scratch False False...\n",
      "WARNING:tensorflow:From D:\\Users\\Gabriel\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Model: \"model_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_6 (InputLayer)         (None, 400, 400, 128)     0         \n",
      "_________________________________________________________________\n",
      "separable_conv2d_9 (Separabl (None, 199, 199, 128)     17664     \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 199, 199, 128)     512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_10 (LeakyReLU)   (None, 199, 199, 128)     0         \n",
      "_________________________________________________________________\n",
      "spatial_dropout2d_9 (Spatial (None, 199, 199, 128)     0         \n",
      "_________________________________________________________________\n",
      "separable_conv2d_10 (Separab (None, 99, 99, 128)       17664     \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 99, 99, 128)       512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_11 (LeakyReLU)   (None, 99, 99, 128)       0         \n",
      "_________________________________________________________________\n",
      "spatial_dropout2d_10 (Spatia (None, 99, 99, 128)       0         \n",
      "_________________________________________________________________\n",
      "separable_conv2d_11 (Separab (None, 49, 49, 128)       17664     \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 49, 49, 128)       512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_12 (LeakyReLU)   (None, 49, 49, 128)       0         \n",
      "_________________________________________________________________\n",
      "spatial_dropout2d_11 (Spatia (None, 49, 49, 128)       0         \n",
      "_________________________________________________________________\n",
      "separable_conv2d_12 (Separab (None, 24, 24, 128)       17664     \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 24, 24, 128)       512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_13 (LeakyReLU)   (None, 24, 24, 128)       0         \n",
      "_________________________________________________________________\n",
      "spatial_dropout2d_12 (Spatia (None, 24, 24, 128)       0         \n",
      "_________________________________________________________________\n",
      "separable_conv2d_13 (Separab (None, 11, 11, 128)       17664     \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 11, 11, 128)       512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_14 (LeakyReLU)   (None, 11, 11, 128)       0         \n",
      "_________________________________________________________________\n",
      "spatial_dropout2d_13 (Spatia (None, 11, 11, 128)       0         \n",
      "_________________________________________________________________\n",
      "separable_conv2d_14 (Separab (None, 5, 5, 128)         17664     \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 5, 5, 128)         512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_15 (LeakyReLU)   (None, 5, 5, 128)         0         \n",
      "_________________________________________________________________\n",
      "spatial_dropout2d_14 (Spatia (None, 5, 5, 128)         0         \n",
      "_________________________________________________________________\n",
      "separable_conv2d_15 (Separab (None, 3, 3, 128)         17664     \n",
      "_________________________________________________________________\n",
      "batch_normalization_16 (Batc (None, 3, 3, 128)         512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_16 (LeakyReLU)   (None, 3, 3, 128)         0         \n",
      "_________________________________________________________________\n",
      "spatial_dropout2d_15 (Spatia (None, 3, 3, 128)         0         \n",
      "_________________________________________________________________\n",
      "separable_conv2d_16 (Separab (None, 1, 1, 128)         17664     \n",
      "_________________________________________________________________\n",
      "batch_normalization_17 (Batc (None, 1, 1, 128)         512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_17 (LeakyReLU)   (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "spatial_dropout2d_16 (Spatia (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "batch_normalization_18 (Batc (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_18 (LeakyReLU)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 2)                 258       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 162,690\n",
      "Trainable params: 160,386\n",
      "Non-trainable params: 2,304\n",
      "_________________________________________________________________\n",
      "Epoch 1/1\n",
      "6/6 [==============================] - ETA: 35s - loss: 0.3835 - categorical_accuracy: 1.000 - ETA: 20s - loss: 0.2435 - categorical_accuracy: 1.000 - ETA: 12s - loss: 0.3668 - categorical_accuracy: 1.000 - ETA: 7s - loss: 0.4037 - categorical_accuracy: 1.000 - ETA: 3s - loss: 0.3466 - categorical_accuracy: 1.00 - 22s 4s/step - loss: 0.2925 - categorical_accuracy: 1.0000 - val_loss: 0.7125 - val_categorical_accuracy: 0.5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Documents\\Github\\libraries\\neural-image-compression-private\\source\\nic\\callbacks.py:368: FutureWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#ix-indexer-is-deprecated\n",
      "  current = df.ix[len(df) - 1, self.monitor]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00000: val_loss improved from inf to 0.71246, saving model to E:/pathology-weakly-supervised-lung-cancer-growth-pattern-prediction/results/model2\\checkpoint.h5\n",
      "Epoch 00000: saving model to E:/pathology-weakly-supervised-lung-cancer-growth-pattern-prediction/results/model2\\last_epoch.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Documents\\Github\\libraries\\neural-image-compression-private\\source\\nic\\callbacks.py:233: FutureWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#ix-indexer-is-deprecated\n",
      "  current = df.ix[len(df) - 1, self.monitor]\n"
     ]
    }
   ],
   "source": [
    "from train_wsi_test_on_cluster import run_train_model\n",
    "\n",
    "\n",
    "csv_path = 'E:/pathology-weakly-supervised-lung-cancer-growth-pattern-prediction/data/slide_list_tcga.csv'\n",
    "csv_train = 'E:/pathology-weakly-supervised-lung-cancer-growth-pattern-prediction/data/train_slide_list_tcga.csv'\n",
    "csv_val = 'E:/pathology-weakly-supervised-lung-cancer-growth-pattern-prediction/data/validation_slide_list_tcga.csv'\n",
    "csv_test = 'E:/pathology-weakly-supervised-lung-cancer-growth-pattern-prediction/data/test_slide_list_tcga.csv'\n",
    "root_dir = r'E:/pathology-weakly-supervised-lung-cancer-growth-pattern-prediction'\n",
    "data_dir_luad = root_dir + r'/results/tcga_luad/featurized'\n",
    "data_dir_lusc = root_dir + r'/results/tcga_lusc/featurized'\n",
    "model_dir = root_dir + '/results/model2'  # change this everytime a new model is run\n",
    "\n",
    "# paths = {'csv_path': csv_path, 'csv_train': csv_train, 'csv_val': csv_val, 'csv_test': csv_test}\n",
    "# generate_csv_files(paths, test_size=0.2, validation_size = 0.3)\n",
    "\n",
    "cache_path = None\n",
    "\n",
    "# Training\n",
    "multiple_paths = {'data_dir_luad': data_dir_luad, 'data_dir_lusc': data_dir_lusc, 'output_dir': model_dir,\n",
    "              'csv_train': csv_train, 'csv_val': csv_val, 'csv_test': csv_test, 'cache_path': cache_path}\n",
    "#run_train_model(multiple_paths, epochs=200, size_of_batch=12)\n",
    "run_train_model(multiple_paths, epochs=1, size_of_batch=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from source.gradcam_wsi import gradcam_on_dataset\n",
    "from source.train_compressed_wsi import train_wsi_classifier, eval_model, compute_metrics\n",
    "\n",
    "def train_model(featurized_dir, csv_path, fold_n, output_dir, cache_dir, batch_size=16,\n",
    "                images_dir=None, vectorized_dir=None, lr=1e-2, patience=4,\n",
    "                occlusion_augmentation=False, elastic_augmentation=False, shuffle_augmentation=None):\n",
    "    \"\"\"\n",
    "    Trains a CNN using compressed whole-slide images.\n",
    "\n",
    "    :param featurized_dir: folder containing the compressed (featurized) images.\n",
    "    :param csv_path: list of slides with labels.\n",
    "    :param fold_n: fold determining which data partitions to use for training, validation and testing.\n",
    "    :param output_dir: destination folder to store results.\n",
    "    :param cache_dir: folder to store compressed images temporarily for fast access.\n",
    "    :param batch_size: number of samples to train with in one-go.\n",
    "    :return: nothing.\n",
    "    \"\"\"\n",
    "\n",
    "    # Params\n",
    "    folds = [\n",
    "        {'training': ['partition_0', 'partition_1'], 'validation': ['partition_2'], 'test': ['partition_3']},\n",
    "        {'training': ['partition_1', 'partition_2'], 'validation': ['partition_3'], 'test': ['partition_0']},\n",
    "        {'training': ['partition_2', 'partition_3'], 'validation': ['partition_0'], 'test': ['partition_1']},\n",
    "        {'training': ['partition_3', 'partition_0'], 'validation': ['partition_1'], 'test': ['partition_2']},\n",
    "    ]\n",
    "    result_dir = join(output_dir, 'fold_{n}'.format(n=fold_n))\n",
    "\n",
    "    # Train CNN\n",
    "    train_wsi_classifier(\n",
    "        data_dir=featurized_dir,\n",
    "        csv_path=csv_path,\n",
    "        partitions=folds[fold_n],\n",
    "        crop_size=400,\n",
    "        output_dir=result_dir,\n",
    "        output_units=2,\n",
    "        cache_dir=cache_dir,\n",
    "        n_epochs=200,\n",
    "        batch_size=batch_size,\n",
    "        lr=lr,\n",
    "        code_size=128,\n",
    "        workers=1,\n",
    "        train_step_multiplier=1,\n",
    "        val_step_multiplier=0.5,\n",
    "        keep_data_training=1,\n",
    "        keep_data_validation=1,\n",
    "        patience=patience,\n",
    "        occlusion_augmentation=occlusion_augmentation,\n",
    "        elastic_augmentation=elastic_augmentation,\n",
    "        shuffle_augmentation=shuffle_augmentation\n",
    "    )\n",
    "\n",
    "    # Evaluate CNN\n",
    "    eval_model(\n",
    "        model_path=join(result_dir, 'checkpoint.h5'),\n",
    "        data_dir=featurized_dir,\n",
    "        csv_path=csv_path,\n",
    "        partitions=folds[fold_n],\n",
    "        crop_size=400,\n",
    "        output_path=join(result_dir, 'eval', 'preds.csv'),\n",
    "        cache_dir=cache_dir,\n",
    "        batch_size=batch_size,\n",
    "        keep_data=1\n",
    "    )\n",
    "\n",
    "    # Metrics\n",
    "    try:\n",
    "        compute_metrics(\n",
    "            input_path=join(result_dir, 'eval', 'preds.csv'),\n",
    "            output_dir=join(result_dir, 'eval')\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print('Failed to compute metrics. Exception: {e}'.format(e=e), flush=True)\n",
    "\n",
    "    # Apply GradCAM analysis to CNN\n",
    "    gradcam_on_dataset(\n",
    "        featurized_dir=featurized_dir,\n",
    "        csv_path=csv_path,\n",
    "        model_path=join(result_dir, 'checkpoint.h5'),\n",
    "        partitions=folds[fold_n]['test'],\n",
    "        layer_name='separable_conv2d_1',\n",
    "        output_unit=1,\n",
    "        custom_objects=None,\n",
    "        cache_dir=cache_dir,\n",
    "        images_dir=images_dir,\n",
    "        vectorized_dir=vectorized_dir\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train CNN\n",
    "\n",
    "selected_fold = 0\n",
    "model_dir = join(root_dir, 'results', 'models', 'rotterdam1', 'bigan', 'nic', 'hgp_bin')\n",
    "\n",
    "train_model(\n",
    "    featurized_dir=featurized_dir,\n",
    "    csv_path=csv_path,\n",
    "    fold_n=selected_fold, \n",
    "    output_dir=model_dir,\n",
    "    cache_dir=join(cache_dir, 'cnn'),\n",
    "    occlusion_augmentation=False,\n",
    "    lr=1e-2,\n",
    "    patience=4,\n",
    "    elastic_augmentation=False,\n",
    "    images_dir=slide_dir,  # required for GradCAM\n",
    "    vectorized_dir=vectorized_dir,  # required for GradCAM\n",
    "    shuffle_augmentation=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
